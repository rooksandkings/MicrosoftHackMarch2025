Article ID,Title,URL,Authors,Full Content,Article Metadata,Scraped At
500,"“Having developers who understand how that business works, who can go in and analyze the data coming out of their systems and put in new capabilities or fixes, just pays for itself tenfold.”",https://www.mckinsey.com/featured-insights/quote-of-the-day/february-7-2023,,"## McKinsey quote of the day

## “Having developers who understand how that business works, who can go in and analyze the data coming out of their systems and put in new capabilities or fixes, just pays for itself tenfold.”

Casey Santos, the CIO of Asurion, on hiring good developers in “Focusing on developer experience and embedded security for cloud”","{""word_count"": 60, ""reading_time_minutes"": 1}",2025-03-14 11:43:13.639718
10,On the cusp of change: North American wealth management in 2030,https://www.mckinsey.com/industries/financial-services/our-insights/banking-matters/on-the-cusp-of-change-north-american-wealth-management-in-2030,,"## On the cusp of change: North American wealth management in 2030

Brings a unique perspective to help clients anticipate the changing needs of consumers in financial services and adjacent markets

Works with global asset and wealth managers, banks, and insurers on strategic and operational challenges and organizational opportunities

Advises wealth managers, asset managers, and insurers, focusing on strategy, distribution, and productivity improvements

Leads McKinsey’s strategy work for North America and coleads it globally, offering advisory support to a wide range of financial institutions

Provides counsel to global leaders in leading global financial institutions with a focus on using data analytics to drive decision making

Guides clients to drive sustainable, long-term growth at the intersection of Insurance, Retirement, and Wealth & Asset Management

January 3, 2020Recent decades have witnessed meaningful changes to the North American wealth management industry’s structure and dynamics. The first decade of the 2000s saw the further democratization of trading due to increased access through technology, and the current decade has seen the convergence of banking and investing and the rise of fee-based managed accounts. These seismic shifts raise the question of what the next decade will bring—and how we might describe the 2020s from the perspective of 2030.","{""word_count"": 202, ""reading_time_minutes"": 1}",2025-03-14 11:45:19.591335
1,Navigating network modernization: Change management best practices,https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/tech-forward/navigating-network-modernization-change-management-best-practices,,"## Navigating network modernization: Change management best practices

Partner in McKinsey’s New York office

Senior expert in the Mumbai office

Solution leader for cloud delivery in the Atlanta office

March 12, 2024Updating network architecture to best meet a company’s current needs can have dramatic effects. Modern network practices offer benefits and competitive advantages, such as accelerated time to market and enhanced customer experience through seamless and reliable interactions with cloud-native applications.

Consider one global technology conglomerate that undertook a network transformation, shifting from a legacy networking model to a microservices-based architecture. By embracing microservices and modern network principles, the conglomerate achieved a substantial reduction in deployment times for new services. This acceleration empowered the conglomerate to swiftly roll out innovations to the market and seize new business opportunities.

In a recent blog post, we wrote about how companies can make this delicate shift to cloud-native networks to ensure their networks are serving them in today’s business landscape, which is marked by cybersecurity concerns, data expansion, and cloud migration, among other trends. In this post, we dig into some of the challenges of aligning network architectures with cloud-native principles and the change management practices that can help ensure that challenges don’t get in the way of modernization efforts.

## Understanding what can thwart modernization efforts

Companies often initiate programs to move to cloud-native networks, but they don’t always complete them. In our experience, several hurdles can cause momentum to slow or stall:

Security concerns about the new network architecture. Many teams assume that being able to physically connect and disconnect devices allows for higher security. This is false. Internet-based connections offer more resilience compared with physical connections, and security protocols and network monitoring can allow companies to achieve, at the minimum, the same level of control as they have on a physical network.

Slow progress on network design. The transition phase of integrating existing firewalls and network configurations with the cloud-native network and its more agile development principles can be challenging. Sometimes this redesign can cause organizations to lose momentum; however, if they can overcome this one-time push, less effort will be required in the long term.

Insufficient talent to configure and integrate new network principles. Integrating new network principles often requires drastically different skill sets than what organizations typically have available. To address this, companies will want to consider reskilling their current workforce, as opposed to relying on a purely external workforce, for the integration effort.

## Five best practices that can guide a successful transition

By taking the following steps, companies can increase the chances that the transition gains traction and sticks, allowing them to achieve agility, innovation, and resilience in cloud-native applications.

## Conduct an assessment and develop a strategy

Companies should commence with a thorough assessment of their existing network infrastructure, gaining a deep understanding of its strengths, weaknesses, and alignment with cloud-native objectives. In undertaking this assessment, companies often discover that their existing network infrastructure is not adequately aligned with cloud-native objectives, lacking the scalability, agility, and security required for modern applications. With this knowledge in hand, they can develop a robust modernization strategy that resonates with their overarching organizational goals and seamlessly integrates with their application landscape. To ensure successful capacity allocation, the assessment should also take stock of available talent and skills as well as the effort required to change the underlying network infrastructure.

## Empower talent through training and mindset change

Companies should invest in enhancing their network engineering team’s expertise in cloud-native concepts and tools, offering comprehensive training that encompasses cloud networking, microservices communication, container orchestration, and the implementation of security best practices. The extent of training required will depend on the specific needs of the network engineering team and the organization’s overall modernization goals, but organizations should expect to invest in significant training to bridge the gap between their existing expertise and the required cloud-native knowledge. Factors to consider include the team’s experience, project complexity, cloud strategy, and internal training resources. Implementing training may require a phased approach, starting with foundational concepts and progressing to deeper training as the project progresses. The training should also include programs to change the underlying mindset of the network organization, including workshops dedicated to understanding the reservations of the existing organization and highlighting the benefits of the new technology setup.

## Run small-scale pilot projects

Modernization journeys can begin with modest pilot projects. These focused initiatives allow organizations to test and validate network modernization approaches in a controlled environment. Pilot projects yield invaluable insights, shedding light on challenges, successes, and optimization strategies. The lessons learned from these pilots serve as a guide for the broader modernization landscape and the effort required to ensure successful planning.

Organizations will likely want to avoid using pilots for mission-critical projects with a high risk of failure that could significantly affect business operations, complex projects with a long timeline that may not be suitable for a pilot-first approach, and nonessential projects that do not directly contribute to the overall modernization goals and may divert resources from initiatives that are more vital. Instead, they could focus on conducting pilot projects to evaluate new technologies or approaches in a controlled environment, testing complex multiteam or multisystem projects to identify potential challenges, and validating critical aspects of the overall modernization strategy to ensure alignment with organizational goals.

## Cultivate collaboration

Organizations should strive to foster a culture of collaboration in a holistic approach that unites network engineers, application developers, and security teams. Regular communication and collaborative decision making are instrumental in producing an elevated outcome. To make the required mindset change, the collaboration exercise—which should extend into the compliance and risk functions—should consider the journey of the organization and learning journey of the individual employees. The company may need to update and adopt policies and security guidelines to reflect that physical control of the entire network is neither required nor advisable. By taking this approach, organizations ensure that network modernization seamlessly harmonizes with other facets of application development and security protocols.

## Evolve continuously

Network modernization is an ongoing evolution, demanding continuing evaluation and enhancement. Organizations should establish a robust feedback loop that encompasses vigilant monitoring, input from stakeholders, and periodic reviews. These reviews can include annual comprehensive assessments of performance, security, and alignment with evolving needs as well as monthly or quarterly check-ins to monitor key metrics, identify issues, and make proactive adjustments. Organizations will also inevitably need to conduct spontaneous reviews in reaction to security incidents or major network changes. Continuous improvement can help organizations ensure the network remains attuned to ever-evolving business demands and the rapid pace of technological advancements.

Applications drive business innovation, and the network enables this transformation. Embracing the shift toward microservices, containerization, and cloud-native architectures is not just a technical decision but also a strategic imperative. Network modernization paves the way for accelerated business outcomes, and strong change management in this effort is essential in positioning organizations to thrive in the dynamic landscape of the digital age.

Ritesh Agarwal is a partner in McKinsey’s New York office, Ashish Gupta is a senior expert in the Mumbai office, Pankaj Sachdeva is a senior partner in the Philadelphia office, and Jill Sharabura is a solution leader for cloud delivery in the Atlanta office.","{""word_count"": 1205, ""reading_time_minutes"": 6}",2025-03-14 11:52:11.452973
2,Changing change management,https://www.mckinsey.com/featured-insights/leadership/changing-change-management,,"## Changing change management

Change management as it is traditionally applied is outdated. We know, for example, that 70 percent of change programs fail to achieve their goals, largely due to employee resistance and lack of management support. We also know that when people are truly invested in change it is 30 percent more likely to stick. While companies have been obsessing about how to use digital to improve their customer-facing businesses, the application of digital tools to promote and accelerate internal change has received far less scrutiny. However, applying new digital tools can make change more meaningful—and durable—both for the individuals who are experiencing it and for those who are implementing it.

The advent of digital change tools comes at just the right time. Organizations today must simultaneously deliver rapid results and sustainable growth in an increasingly competitive environment. They are being forced to adapt and change to an unprecedented degree: leaders have to make decisions more quickly; managers have to react more rapidly to opportunities and threats; employees on the front line have to be more flexible and collaborative. Mastering the art of changing quickly is now a critical competitive advantage.

For many organizations, a five-year strategic plan—or even a three-year one—is a thing of the past. Organizations that once enjoyed the luxury of time to test and roll out new initiatives must now do so in a compressed period while competing with tens or hundreds of existing (and often incomplete) initiatives. In this dynamic and fast-paced environment, competitive advantage will accrue to companies with the ability to set new priorities and implement new processes quicker than their rivals.

## The power of digital to drive change

Large companies are increasingly engaged in multiple simultaneous change programs, often involving scores of people across numerous geographies. While traditional workshops and training courses have their place, they are not effective at scale and are slow moving.

B2C companies have unlocked powerful digital tools to enhance the customer journey and shift consumer behavior. Wearable technology, adaptive interfaces, and integration into social platforms are all areas where B2C companies have innovated to make change more personal and responsive. Some of these same digital tools and techniques can be applied with great effectiveness to change-management techniques within an organization. Digital dashboards and personalized messages, for example, can build faster, more effective support for new behaviors or processes in environments where management capacity to engage deeply and frequently with every employee is constrained by time and geography.

Digitizing five areas in particular can help make internal change efforts more effective and enduring.

## 1. Provide just-in-time feedback

The best feedback processes are designed to offer the right information when the recipient can actually act on it. Just-in-time feedback gives recipients the opportunity to make adjustments to their behavior and to witness the effects of these adjustments on performance.

Consider the experience of a beverage company experiencing sustained share losses and stagnant market growth in a highly competitive market in Africa. The challenge was to motivate 1,000-plus sales representatives to sell with greater urgency and effectiveness. A simple SMS message system was implemented to keep the widely distributed sales reps, often on the road for weeks at a time, plugged into the organization. Each rep received two to three daily SMS messages with personalized performance information, along with customer and market insights. For example, one message might offer feedback on which outlets had placed orders below target; another would alert the rep to a situation that indicated a need for increased orders, such as special events or popular brands that were trending in the area. Within days of implementing the system, cross-selling and upselling rates increased to more than 50 percent
from 4 percent, and within the first year, the solution delivered a $25 million increase in gross margin, which helped to swing a 1.5 percent market-share loss into a 1 percent gain.

## 2. Personalize the experience

Personalization is about filtering information in a way that is uniquely relevant to the user and showing each individual’s role in and contribution to a greater group goal. An easy-to-use system can be an effective motivator and engender positive peer pressure.

This worked brilliantly for a rail yard looking to reduce the idle time of its engines and cars by up to 10 percent. It implemented a system that presented only the most relevant information to each worker at that moment, such as details on the status of a train under that worker’s supervision, the precise whereabouts of each of the trains in the yard, or alerts indicating which train to work on. Providing such specific and relevant information helped workers clarify priorities, increase accountability, and reduce delays.

## 3. Sidestep hierarchy

Creating direct connections among people across the organization allows them to sidestep cumbersome hierarchal protocols and shorten the time it takes to get things done. It also fosters more direct and instant connections that allow employees to share important information, find answers quickly, and get help and advice from people they trust.

In the rail-yard example, a new digital communications platform was introduced to connect relevant parties right away, bypassing middlemen and ensuring that issues get resolved quickly and efficiently. For example, if the person in charge of the rail yard has a question about the status of an incoming train, he or she need only log into the system and tap the train icon to pose the question directly to the individuals working on that train. Previously, all calls and queries had to be routed through a central source. This ability to bridge organizational divides is a core advantage in increasing agility, collaboration, and effectiveness.

## 4. Build empathy, community, and shared purpose

In increasingly global organizations, communities involved in change efforts are often physically distant from one another. Providing an outlet for colleagues to share and see all the information related to a task, including progress updates and informal commentary, can create an important esprit de corps.

Specific tools are necessary to achieve this level of connectivity and commitment. Those that we have seen work well include shared dashboards, visualizations of activity across the team, “gamification” to bolster competition, and online forums where people can easily speak to one another (for example, linking a Twitter-like feed to a work flow or creating forums tied to leaderboards so people can easily discuss how to move up in the rankings).

This approach worked particularly well with a leading global bank aiming to reduce critical job vacancies. The sourcing team made the HR process a shared experience, showing all stakeholders the end-to-end view—dashboards identifying vacancies; hiring requisitions made and approved; candidates identified, tested, and interviewed; offers made and accepted; and hire letters issued. This transparency and openness built a shared commitment to getting results, a greater willingness to deliver on one’s own step in the process, and a greater willingness to help one another beyond functional boundaries.

## 5. Demonstrate progress

Organizational change is like turning a ship: the people at the front can see the change but the people at the back may not notice for a while. Digital change tools are helpful in this case to communicate progress so that people can see what is happening in real time. More sophisticated tools can also show individual contributions toward the common goal. We have seen how this type of communication makes the change feel more urgent and real, which in turn creates momentum that can help push an organization to a tipping point where a new way of doing things becomes the way things are done.

Digital tools and platforms, if correctly applied, offer a powerful new way to accelerate and amplify the ability of an organization to change. However, let’s be clear: the tool should not drive the solution. Each company should have a clear view of the new behavior it wants to reinforce and find a digital solution to support it. The best solutions are tightly focused on a specific task and are rolled out only after successful pilots are completed. The chances of success increase
when management actively encourages feedback from users and incorporates it to give them a sense of ownership in the process.

## How relevant and useful is this article for you?

## About the author(s)

Boris Ewenstein is a principal in McKinsey’s Johannesburg office, where Wesley Smith is a consultant and Ashvin Sologar is an associate principal.

## Explore a career with us

## Related Articles

## Putting digital process innovation at the center of organizational change

## What ‘digital’ really means

## Raising your Digital Quotient","{""publication_date"": ""July 1, 2015"", ""word_count"": 1429, ""reading_time_minutes"": 7}",2025-03-14 11:52:17.668704
3,Change management: lessons from Japan,https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-organization-blog/change-management-lessons-from-japan,,"## Change management: lessons from Japan

Advises leading companies on a broad range of strategic, operations, and organizational topics

Supports large Japanese companies in the consumer goods, retail, energy, manufacturing, and services sectors by driving growth through globalization, strategic planning, performance transformation, new business development, sales and marketing, and organizational and talent development.

Co-leads McKinsey's Asia Life Sciences practice, coordinating the firm's activity in the pharmaceutical, medical technology, payor, and provider sectors

August 6, 2018When it comes to evolution, “it is not the strongest or the most intelligent who will survive but those who can best manage change,” maintained naturalist Charles Darwin.

So it is with modernizing and changing operating models within organizations. This can often be met with resistance by employees and exasperated further by cultural influences. In Japan, consensus building is a strong part of the culture and change management programs fail primarily from employee resistance at the second level beneath the CEO and teams.

To combat this, one newly installed CEO – brought in to make changes at a Japanese consumer products company – immediately formed a team that would reach Level 2 employees. He handpicked younger people more likely to change and adapt and did not include disinterested veteran leaders.

Two significant things happened. First, the CEO spent considerable time educating the new team on the journey ahead, explaining how the organization would function so they could envision the company’s future. Second, by handpicking a younger team, the message to company veterans was that something important was happening, and leaders who accepted these new changes would be part of the company’s success.

A few core elements helped this organization achieve the right results:

• Inspirational and effective change leaders.

• A “change story” with real meaning to convince leaders and employees to be open to new ways of working.

• The chance to change mindsets and behaviors.

• The need to orchestrate change via an expanding and self-sustaining wave throughout the organization.

Our experience supporting change efforts in Japanese organizations suggests we find success when more attention is paid to culturally attuned principles, as in the above example. For similarly consensus-oriented organizations, here are four practical ways to drive change.

• Define the end state in detail and provide a roadmap much earlier. While a western company would launch a transformation based on a vision and engage the broader organization to define it, leaders at consensus-oriented organizations need a detailed description of the new model on which to engage and establish a fresh consensus early on. “Building a plane as we fly” is never an easy mission, but it is a nonstarter in these organizations.

• Engage the front line very early and create opportunities to endorse change. Spend time in the field – on the factory floor, with the sales force, etc. – to define the details of the new model; anticipate issues; and permit the sharing of frustrations, aspirations, and other emotional reactions. Identify and support champions of change in the front line from the start. Do not assume that “immediate followers” in the second level of the organization will spontaneously follow the guidance from the top.

• Map the organizational network and tackle change blockers. Organizational network mapping, which analyzes the networks that employees rely on in their work, is used frequently to identify and empower change agents. Identifying and mapping potential “blockers” is not difficult and even more important for a successful change. Actions can be taken to convert or neutralize change blockers early in the process.

• Expose top management extensively, broadly and directly. Town hall meetings, Q&A sessions and other opportunities that expose top management to large audiences prove the most effective ways to sell change to employees. These events sacrifice intimacy, but they also break through an organization’s vertical walls, override internal factions and convey a call to action that directly engages each member of the organization.

Establishing a purposeful team upfront helps sustain change and embeds the new procedural and cultural elements in the new model. In this context, the so-called “third generation” of leaders – those roughly 35-45 years in age who realize they have a future to build, not a legacy to protect – is becoming an important source of change energy because they’re more risk-seeking.

Staying culturally attuned promises to make a big difference in whether organizations in Japan or elsewhere succeed in their change management mission.

## Learn more about our People & Organizational Performance Practice","{""word_count"": 742, ""reading_time_minutes"": 4}",2025-03-14 11:52:23.087409
4,The psychology of change management,https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-psychology-of-change-management,,"## The psychology of change management

Over the past 15 or so years, programs to improve corporate organizational performance have become increasingly common. Yet they are notoriously difficult to carry out. Success depends on persuading hundreds or thousands of groups and individuals to change the way they work, a transformation people will accept only if they can be persuaded to think differently about their jobs. In effect, CEOs must alter the mind-sets of their employees—no easy task.

CEOs could make things easier for themselves if, before embarking on complex performance-improvement programs, they determined the extent of the change required to achieve the business outcomes they seek. Broadly speaking, they can choose among three levels of change. On the most straightforward level, companies act directly to achieve outcomes, without having to change the way people work; one example would be divesting noncore assets to focus on the core business. On the next level of complexity, employees may need to adjust their practices or to adopt new ones in line with their existing mind-sets in order to reach, say, a new bottom-line target. An already ""lean"" company might, for instance, encourage its staff to look for new ways to reduce waste, or a company committed to innovation might form relationships with academics to increase the flow of ideas into the organization and hence the flow of new products into the market.

But what if the only way a business can reach its higher performance goals is to change the way its people behave across the board? Suppose that it can become more competitive only by changing its culture fundamentally—from being reactive to proactive, hierarchical to collegial, or introspective to externally focused, for instance. Since the collective culture of an organization, strictly speaking, is an aggregate of what is common to all of its group and individual mind-sets, such a transformation entails changing the minds of hundreds or thousands of people. This is the third and deepest level: cultural change.

In such cases, CEOs will likely turn for help to psychology. Although breakthroughs have been made in explaining why people think and behave as they do, these insights have in general been applied to business only piecemeal and haven’t had a widespread effect. Recently, however, several companies have found that linking all of the major discoveries together in programs to improve performance has brought about startling changes in the behavior of employees—changes rooted in new mind-sets. Performance-improvement programs that apply all of these ideas in combination can be just as chaotic and hard to lead as those that don’t. But they have a stronger chance of effecting long-term changes in business practice and thus of sustaining better outcomes.

## Four conditions for changing mind-sets

Employees will alter their mind-sets only if they see the point of the change and agree with it—at least enough to give it a try. The surrounding structures (reward and recognition systems, for example) must be in tune with the new behavior. Employees must have the skills to do what it requires. Finally, they must see people they respect modeling it actively. Each of these conditions is realized independently; together they add up to a way of changing the behavior of people in organizations by changing attitudes about what can and should happen at work.

## A purpose to believe in

In 1957 the Stanford social psychologist Leon Festinger published his theory of cognitive dissonance, the distressing mental state that arises when people find that their beliefs are inconsistent with their actions—agnostic priests would be an extreme example. Festinger observed in the subjects of his experimentation a deep-seated need to eliminate cognitive dissonance by changing either their actions or their beliefs.

The implication of this finding for an organization is that if its people believe in its overall purpose, they will be happy to change their individual behavior to serve that purpose—indeed, they will suffer from cognitive dissonance if they don’t. But to feel comfortable about change and to carry it out with enthusiasm, people must understand the role of their actions in the unfolding drama of the company’s fortunes and believe that it is worthwhile for them to play a part. It isn’t enough to tell employees that they will have to do things differently. Anyone leading a major change program must take the time to think through its ""story""—what makes it worth undertaking—and to explain that story to all of the people involved in making change happen, so that their contributions make sense to them as individuals.

## Reinforcement systems

B. F. Skinner is best known for his experiments with rats during the late 1920s and the 1930s. He found that he could motivate a rat to complete the boring task of negotiating a maze by providing the right incentive—corn at the maze’s center—and by punishing the rat with an electric shock each time it took a wrong turn.

Skinner’s theories of conditioning and positive reinforcement were taken up by psychologists interested in what motivates people in organizations. Organizational designers broadly agree that reporting structures, management and operational processes, and measurement procedures—setting targets, measuring performance, and granting financial and nonfinancial rewards—must be consistent with the behavior that people are asked to embrace. When a company’s goals for new behavior are not reinforced, employees are less likely to adopt it consistently; if managers are urged to spend more time coaching junior staff, for instance, but coaching doesn’t figure in the performance scorecards of managers, they are not likely to bother.

Some disciples of Skinner suggest that positive-reinforcement ""loops"" have a constant effect: once established, you can leave them be. Over time, however, Skinner’s rats became bored with corn and began to ignore the electric shocks. In our experience, a similar phenomenon often prevents organizations from sustaining higher performance: structures and processes that initially reinforce or condition the new behavior do not guarantee that it will endure. They need to be supported by changes that complement the other three conditions for changing mind-sets.

## The skills required for change

Many change programs make the error of exhorting employees to behave differently without teaching them how to adapt general instructions to their individual situation. The company may urge them to be ""customer-centric,"" for example, but if it paid little attention to customers in the past, they will have no idea how to interpret this principle or won’t know what a successful outcome would look like.

How can adults best be equipped with the skills they need to make relevant changes in behavior? First, give them time. During the 1980s, David Kolb, a specialist in adult learning, developed his four-phase adult-learning cycle. Kolb showed that adults can’t learn merely by listening to instructions; they must also absorb the new information, use it experimentally, and integrate it with their existing knowledge. In practice, this means that you can’t teach everything there is to know about a subject in one session. Much better to break down the formal teaching into chunks, with time in between for the learners to reflect, experiment, and apply the new principles. Large-scale change happens only in steps.

Second, as the organizational psychologist Chris Argyris showed, people assimilate information more thoroughly if they go on to describe to others how they will apply what they have learned to their own circumstances. The reason, in part, is that human beings use different areas of the brain for learning and for teaching.11.These insights into what Argyris called 'double-loop learning' were further developed by Noel Tichy into the 'teachable point of view' used at GE’s Crotonville training center and at Ford Motor. In double-loop learning, the 'framing system' (mind-set) that underlies an individual’s actions can be altered through examination and questioning. In 'single-loop learning,' goals, values, frameworks, and mind-sets are taken for granted and learning occurs within the system.

## Consistent role models

Most clinical work confirms the idea that consistent role models, whom the famous pediatrician Benjamin Spock regarded as decisive for the development of children, are as important in changing the behavior of adults as the three other conditions combined. In any organization, people model their behavior on ""significant others"": those they see in positions of influence. Within a single organization, people in different functions or levels choose different role models—a founding partner, perhaps, or a trade union representative, or the highest-earning sales rep. So to change behavior consistently throughout an organization, it isn’t enough to ensure that people at the top are in line with the new ways of working; role models at every level must ""walk the talk.""

The way role models deal with their tasks can vary, but the underlying values informing their behavior must be consistent. In a company that encourages entrepreneurial decision making at low levels, one middle manager might try to coach junior employees to know how to spot a promising new venture; another might leave this up to them. Both, however, would be acting in line with the entrepreneurial principle, whereas a boss who demanded a lengthy business case to justify each $50 expenditure would not be. But organizations trying to change their value systems can’t tolerate as much variance in their role models’ behavior. If entrepreneurial decision making were a new value, both of these middle managers might have to act in roughly the same way in order to encourage their subordinates to make bold decisions.

Behavior in organizations is deeply affected not only by role models but also by the groups with which people identify. Role modeling by individuals must therefore be confirmed by the groups that surround them if it is to have a permanent or deep influence. (Most teenagers could tell you a lot about this.) Say that a well-respected senior leader is waxing lyrical about making the culture less bureaucratic and even conforming to the new regime by making fewer requests for information. If the sales reps in the company canteen spend every lunchtime complaining that ""we’ve heard this a thousand times before and nothing happened,"" individuals will feel less pressure to change their behavior. Change must be meaningful to key groups at each level of the organization.

## Putting the approach into practice

The case of a retail bank shows how these four conditions can coalesce to change mind-sets and behavior and thereby improve performance. But though we have grouped the actions of the bank under the four conditions, it didn’t apply them in a neat sequence. As in any change program, there was much disruption and risk. Nonetheless, basing the program on four proven principles gave the CEO confidence that it would eventually succeed.

A few years ago, this CEO took the helm of a large European retail bank that employed more than 30,000 people. He set several targets: doubling the economic profit of the bank, reducing its cost-to-income ratio to 49 percent (from 56), and increasing its annual revenue growth from the current 1 to 2 percent to 5 to 7 percent—all within four years. But retail banking is almost a commodity business. No financial-engineering shortcuts or superficial changes in practice could win a competitive edge for the bank. It could meet these performance goals, the CEO realized, only by galvanizing its people to deliver far better customer outcomes at a much lower cost. That meant changing the culture of the bank by transforming it from a bureaucracy into a federation of entrepreneurs: managers would be rewarded for taking charge of problems and deciding, quickly, how to fix them.

## People want to develop

Workshops that draw on transpersonal psychology, a progressive branch of the discipline, can speed up cultural change and make it more enduring.11.Transpersonal psychology developed in the 1960s, when Abraham Maslow, Stanislav Grof, and others began integrating the classical Asian traditions of Zen Buddhism, Taoism, and yoga into their theories and the practice of humanistic psychology. To develop the workshops described here, the authors have also drawn on ideas from cognitive, behavioral, and gestalt psychology; neuroscience and quantum physics; emotional intelligence; and adult learning.   Transpersonal psychology suggests that the innate desire to develop and grow infuses human beings with energy. Employees will not put sustained effort into a new kind of behavior if they have only a rational understanding of why it matters to the company; it must mean something much deeper to them, something that they know will have an effect on their personal growth.

Giving them an emotional connection to the new behavior can trigger that shift in perspective. The workshops help to change behavior by establishing these connections and thus giving change a personal meaning for participants. When large numbers of managers go through such transformational workshops within a brief time frame, small group by small group, the graduates create a critical mass of individuals who willingly embrace the new behavior and culture so that both are more likely to be sustained.

The format and off-site setting of such workshops generally resemble those of other corporate get-togethers, but their content is unusual. Facilitators experienced in applying the principles of adult learning and transpersonal psychology to business use conversations, role-playing, and reflection to help participants tap into their rational and subconscious hopes for the future. These hopes may contrast uncomfortably with the current work of the participants—both what they do and how they do it. The contrast can unlock a deeply felt need for change.

An international energy company, for example, had tried for years to make ""people development"" a core value and discipline. It was succeeding only among the few managers who already believed that they should serve as coaches and counselors. Many managers saw themselves as bosses rather than teachers. To get the 1,000 most senior managers to adopt a ""coaching"" mind-set (and some other positive cultural attributes), the company put them all, 30 at a time, through a three-day transformational workshop, starting with the executive team.

The rational case for the importance of people development to the company’s strategy and operations was easily stated. Creating an emotional connection between the managers and the new behavior was harder. The workshop leaders asked people to discuss, in pairs, the following question: ""When were you mentored in your career?"" Participants had good memories of the defining moments of mentoring that had helped them achieve their current positions. They remembered the people who had the courage and interest to give them the hard feedback or encouragement they needed. Then the facilitators asked, ""Whom have you mentored? How does it feel to help others develop?"" These questions too prompted memories that evoked strong positive emotions.

But transpersonal psychologists think that getting individuals to have an emotional response to a required new form of behavior isn’t enough to persuade them to adopt it permanently. It must also help to satisfy their innate appetite to grow. When they view the new behavior’s meaning from this completely different perspective—not as the fulfillment of an external requirement but rather as a way of satisfying a personal need—they are unlikely ever to give it up.

The facilitators stepped up to this level of meaning when they asked the energy company’s managers, ""When you leave this company, what do you want people to say about you?"" Given the opportunity to think about this question, few were content to answer, ""I made the company richer."" Many hoped to be remembered for the difference they had made to other people’s lives, for caring enough to help their colleagues grow. Many also realized that a big gap separated what they would like to hear, on the one hand, and what their coworkers would actually say, on the other. Often those closest to retirement, with the most to offer as mentors, felt this gap the hardest. They realized that developing other employees would satisfy their own personal aspirations, not just the company’s.

After every manager had been through the workshop, the group ranked leadership development as the second most powerfully experienced value at work (exhibit). Eighteen months previously, leadership development had received no votes. The proportion of employees who said that they had received good feedback and coaching rose to 80 percent, from 30, while 75 percent said that the behavior of their managers had changed significantly. The new values would have failed to take hold if in addition to giving employees an emotional connection to behavioral change the company hadn’t implanted the other three conditions necessary to achieve it: appropriate skills, supporting structures, and role models. The workshops helped to promote all of these conditions as well.

## The story of change

First, the CEO developed these insights into a story that would make sense to all of the bank’s employees, top to bottom, and would persuade them to change their behavior in line with the new principles. His principal technique was dialogue-based planning, a refinement of double-loop learning (see sidebar, ""People want to develop,"" for a different technique). First, he drafted a top-level story of the way he perceived the bank’s position and refined the story with the help of his executive directors. Each of them in turn developed a chapter of the story relevant to his or her direct reports; the human-resources director, for example, explained how she would improve the system for identifying potential highfliers and redraw their career paths so that they would spend less time in low-impact jobs. Every director assigned responsibility for each ""deliverable"" in the story to one member of his or her team. Each team member then had to develop a performance scorecard setting out what he or she would do differently to meet the new goals.

The directors and the CEO then met again to retell their chapters and to get feedback from one another. Each director shared the amended version with his or her subordinates, who in turn retold the relevant part of the story to their own direct reports, and so on down five levels of the organization to the branch managers. At each retelling, the emphasis was on making the story meaningful to the people listening to it and to the groups to which they belonged.

At every level, information flowed upstream as well as down. Part of the story told by the director of retail operations, for example, was the customers’ desire for faster banking processes. One thing slowing them down, according to the staff of the branches, was the document imagers, which broke down, on average, every three days. Ordering a new imager thus became a detail in each branch manager’s story, and the branch staff could translate the top-level story—""our customers want faster operations""—into a practical result that also made their lives easier. At each level of the organization, an employee heard the relevant version of the proposed changes from his or her immediate boss, the person widely regarded as the most effective communications channel.22.For example, an individual’s boss was consistently rated as the most effective communications channel in a UK survey of HR professionals (Internal Communication, The Work Foundation, December 2002).

How could the CEO know that people really bought into his story? The secret, he felt, was to ensure that it described how life would be better for all of the bank’s stakeholders, not just investors and analysts.

## Reinforcing systems

The most dramatic structural change at the bank was eliminating 20 percent of its managerial jobs. The hypothesis, later proved correct, was that doing so would remove a swath of useless activity, without any falloff in performance. All of the bank’s managerial jobs were terminated, and managers were invited to apply for the remaining 80 percent. Applicants knew that they had succeeded if they were invited to a dialogue-based planning session—another way of signaling the importance of the process. Unsuccessful candidates left the bank. The goal was not, primarily, to improve the bank’s cost-to-income ratio; on the contrary, the cost of laying them off was quite high. Rather, since fewer managers now had to make the same number of decisions, this move was intended to force the survivors to make them more quickly.

Simultaneously, the bank’s performance-management process was sharpened. Under the old system, managers were rated from 1 to 5 each year and remunerated accordingly. On average, 84 percent of them got a rating of 3 or more, though the performance of the bank was hardly as good as those results would imply. It injected reality into the process by introducing rankings within cohorts. To reveal the true relative performance of the bank’s employees, a manager assessing ten people, say, could rank no more than three as top performers and had to put at least one person in the lowest level. The ten directors evaluated the top 50 managers in meetings chaired by the CEO. The bonus for gaining the first rank was increased to 20 percent, from 10. Managers in the lowest rank, who would formerly have received a bonus of 5 percent, got none at all. Those who consistently ranked in the lowest level were asked to leave.

## Skills for change

There was more drama to come. After four months of developing the new strategy with the ten directors, the CEO realized that only five of them were committed to change and equipped to see it through. To ensure that his bank had the right skills to change its practices and culture, he replaced the other five with new directors, three of them outsiders.

Meanwhile, the top 50 managers spent two days at a skill-development center where their leadership abilities—in coaching and decision making, for example—were assessed, and each drew up a personal plan to develop those talents. The company began to assess the performance of its people not just on whether they ""made the numbers"" but also on the leadership dimension. One manager who had consistently won high bonuses was known to be hell to work for, a fact acknowledged by the new measurement scheme: he was paid the lowest sum appropriate to his post. This news, which traveled fast on the grapevine, underlined the message that leadership really counted.

## Consistent role models

Dialogue-based planning ensured that leaders at each level of the organization were ""singing from the same song sheet."" Their planning sessions were high-profile events where they themselves started modeling the new type of behavior that the bank wanted its staff to adopt. The CEO’s enthusiasm also inspired employees to behave differently. He convinced them that although change would take a long time and would be very hard to achieve, his passion for improving the life of everyone involved with the bank was heartfelt.

Both messages came through strongly in the way he reshaped his executive team. The five departing directors left just as the most disruptive changes were starting, and the work of the remaining five became even more intense during the six months it took to find replacements. It would have caused far less chaos to search for them while leaving the old team in place—and in the dark—but the CEO’s conscience told him not to do so. Besides showing other managers that there was nothing soft about the change program, his approach demonstrated his integrity and his respect for the needs of all of the bank’s people, even those he didn’t want to keep in the long term. In such a large-scale change in behavior, the leader’s character and integrity matter enormously.

## The outcome

The bank, which is now two years into its four-year improvement timetable, is about halfway toward meeting its targets for reducing its cost-to-income ratio and increasing its revenue and economic profit. This achievement is a sure sign that behavior is heading in the intended direction throughout the bank. Does it prove that mind-sets too are changing? No numerical evidence is available, but from close observation we can see that the culture really has evolved. The bank isn’t a comfortable place to work, but the focus on performance is far stronger, functional silos are being broken down, and people treat every task with far more urgency. A small but indicative example: average queuing times in branches have dropped by over 30 percent, largely because branch managers can count on their employees to work a more flexible shift system by making the most of part-time work and temporary cover. The imagers are working as well.

It is neither easy nor straightforward to improve a company’s performance through a comprehensive program to change the behavior of employees by changing their mind-sets. No company should try to do so without first exhausting less disruptive alternatives for attaining the business outcome it desires. Sometimes tactical moves will be enough; sometimes new practices can be introduced without completely rethinking the corporate culture. But if the only way for a company to reach a higher plane of performance is to alter the way its people think and act, it will need to create the four conditions for achieving sustained change.

## How relevant and useful is this article for you?

## About the author(s)

Emily Lawson is an associate principal and Colin Price is a director in McKinsey’s London office.

## Explore a career with us","{""publication_date"": ""June 1, 2003"", ""word_count"": 4162, ""reading_time_minutes"": 21}",2025-03-14 11:52:28.207067
5,The irrational side of change management,https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-irrational-side-of-change-management,,"## The irrational side of change management

In 1996, John Kotter published Leading Change. Considered by many to be the seminal work in the field of change management, Kotter’s research revealed that only 30 percent of change programs succeed. Since the book’s release, literally thousands of books and journal articles have been published on the topic, and courses dedicated to managing change are now part of many major MBA programs. Yet in 2008, a McKinsey survey of 3,199 executives around the world found, as Kotter did, that only one transformation in three succeeds. Other studies over the past ten years reveal remarkably similar results. It seems that, despite prolific output, the field of change management hasn’t led to more successful change programs.

It also hasn’t helped that most academics and practitioners now agree on the building blocks for influencing employee attitudes and management behavior. McKinsey’s Emily Lawson and Colin Price provided a holistic perspective in “The psychology of change management,” which suggests that four basic conditions are necessary before employees will change their behavior: a) a compelling story, because employees must see the point of the change and agree with it; b) role modeling, because they must also see the CEO and colleagues they admire behaving in the new way; c) reinforcing mechanisms, because systems, processes, and incentives must be in line with the new behavior; and d) capability building, because employees must have the skills required to make the desired changes.

This prescription is well grounded in the field of psychology and is entirely rational. One of its merits is its intuitive appeal: many managers feel that, once revealed, it is simply good common sense. And this, we believe, is precisely where things go wrong. The prescription is right, but rational managers who attempt to put the four conditions in place by applying “common sense” typically misdirect time and energy, create messages that miss the mark, and experience frustrating unintended consequences from their efforts to influence change. Why? Because when they implement the prescription, they disregard certain, sometimes irrational—but predictable—elements of human nature.

In our research and by working with companies attempting change, we have identified nine insights into how human nature gets in the way of successfully applying the four conditions required for behavioral change. As we describe these insights, we’ll show how various companies have, either by conscious awareness or simple luck, overcome or leveraged counterintuitive sides of human behavior in making change happen.

## Creating a compelling story

Change-management thinking extols the virtues of creating a compelling change story, communicating it to employees, and following it up with ongoing communications and involvement. This is good advice, but in practice there are three pitfalls to achieving the desired impact.

1. What motivates you doesn’t motivate most of your employees. We see two types of change stories consistently told in organizations. The first is the “good to great” story: something along the lines of, “Our historical advantage has been eroded by intense competition and changing customer needs; if we change, we can regain our leadership position.” The second is the turnaround story: “We’re performing below industry standard and must change dramatically to survive. We can become a top-quartile performer in our industry by exploiting our current assets and earning the right to grow.”

These stories both seem intuitively rational, yet they too often fail to have the impact that change leaders desire. Research by a number of leading thinkers in the social sciences, such as Danah Zohar, has shown that when managers and employees are asked what motivates them the most in their work they are equally split among five forms of impact—impact on society (for instance, building the community and stewarding resources), impact on the customer (for example, providing superior service), impact on the company and its shareholders, impact on the working team (for example, creating a caring environment), and impact on “me” personally (my development, paycheck, and bonus).

This finding has profound implications for leaders. What the leader cares about (and typically bases at least 80 percent of his or her message to others on) does not tap into roughly 80 percent of the workforce’s primary motivators for putting extra energy into the change program. Change leaders need to be able to tell a change story that covers all five things that motivate employees. In doing so, they can unleash tremendous amounts of energy that would otherwise remain latent in the organization.

Consider a cost reduction program at a large US financial-services company. The program started with a change story that ticked the conventional boxes related to the company’s competitive position and future. Three months into the program, management was frustrated with employee resistance. The change team worked together to recast the story to include an element related to society (to deliver affordable housing, for example), customers (fewer errors, more competitive prices), the company (expenses are growing faster than revenues, which is not sustainable), working teams (less duplication, more delegation), and individuals (more attractive jobs).

This relatively simple shift in approach lifted employee motivation measures from 35.4 percent to 57.1 percent in a month, and the program went on to achieve 10 percent efficiency improvements in the first year—a run rate far above initial expectations.

2. You’re better off letting them write their own story.  Well-intentioned leaders invest significant time in communicating their change story. Road shows, town halls, and Web sites are but a few of the many approaches typically used. Certainly the story (told in five ways) needs to get out there, but the insight we are offering is that much of the energy invested in communicating it would be better spent listening, not telling.

In a famous behavioral experiment, half the participants are randomly assigned a lottery ticket number while the others are asked to write down any number they would like on a blank ticket. Just before drawing the winning number, the researchers offer to buy back the tickets from their holders. The result: no matter what geography or demographic environment the experiment has taken place in, researchers have always found that they have to pay at least five times more to those who came up with their own number.

This reveals something about human nature: when we choose for ourselves, we are far more committed to the outcome (almost by a factor of five to one). Conventional approaches to change management underestimate this impact. The rational thinker sees it as a waste of time to let others discover for themselves what he or she already knows—why not just tell them and be done with it? Unfortunately this approach steals from others the energy needed to drive change that comes through a sense of ownership of the answer.

At BP, to develop a comprehensive training program for frontline leaders, a decision was made to involve every key constituency in the design of the program, giving them a sense of “writing their own lottery ticket.” It took a year and a half to complete the design using this model but was well worth it: now in implementation, the program is the highest rated of its kind at BP. More than 250 active senior managers from across the business willingly teach the course, and, most important, managers who have been through the training program are consistently ranked higher in perfor-mance than those who haven’t, both by their bosses and by the employees who report to them.

3. It takes a story with both + and – to create real energy. The “deficit based” approach—which identifies the problem, analyzes what’s wrong and how to fix it, plans, and then takes action—has become the model predominantly taught in business schools and is presumably the default change model in most organizations. Research has shown, however, that a story focused on what’s wrong invokes blame and creates fatigue and resistance, doing little to engage people’s passion and experience.

This has led to the rise of the “constructionist based” approach to change, where the change process is based on discovery (discovering the best of what is), dreaming (imagining what might be), designing (talking about what should be), and destiny (creating what will be). The problem with this approach is that an overemphasis on the positive can lead to watered-down aspirations and impact. The reason is that, as humans, we are more willing to take risks to avoid losing what we’ve got than we are to gain something more. Some anxiety is useful when it comes to spurring behavioral change.

We believe the field of change management has drawn an artificial divide between deficit-based and constructionist-based approaches and stories. While it is impossible to prescribe generally how the divide should be split between positive and negative messages (as it will be specific to the context of any given change program), we strongly advise managers not to swing the pendulum too far in one direction or another. Consider Jack Welch, former CEO at GE, who took questions of “what’s wrong here?” (poorly performing businesses, silo-driven behavior, and so forth) head-on, as well as “imagining what might be” (number one or two in every business, openness, and accountability).

## Role modeling

Conventional change management suggests leaders should take actions that role model the desired change and mobilize a group of influence leaders to drive change deep into the organization. Unfortunately, this does not necessarily deliver the desired impact.

4. Leaders believe mistakenly that they already “are the change.” Most senior executives understand and generally buy into Gandhi’s famous aphorism, “Be the change you want to see in the world.” They commit themselves to personally role modeling the desired behaviors. And then, in practice, nothing significant changes.

The reason for this is that most executives don’t count themselves among the ones who need to change. How many executives when asked privately will say no to the question, “Are you customer focused?” and yes to the question “Are you a bureaucrat?” Of course, none. The fact is that human beings consistently think they are better than they are—a phenomenon referred to in psychology as a self-serving bias. Consider that 94 percent of men rank themselves in the top half according to male athletic ability. Whereas conventional change-management approaches surmise that top team role modeling is a matter of will or skill, the truth is that the real bottleneck to role modeling is knowing what to change at a personal level.

Typically, insight into what to change can be created by concrete 360-degree feedback techniques, either via surveys, conversations, or both. Look at Amgen CEO Kevin Sharer’s approach of asking each of his top 75, “What should I do differently?” and then sharing his development needs and commitment publicly with them. Consider the top team of a national insurance company who routinely employed what they called the circle of fire during their change program: every participant receives feedback live—directly from their colleagues—in relation to being the change, such as “What makes you great?” and “What holds you back?”

5. “Influence leaders” aren’t a panacea for making change happen. Almost all change-management literature places importance on identifying and mobilizing those in the organization who either by role or personality (or both) have disproportionate influence over how others think and behave. We believe this is sound and timeless advice. However, we have observed that the role of influence leaders has gradually shifted—from being perceived as a helpful element of a broader set of interventions, to a panacea for making change happen.

Our experiences working with change programs suggest that success depends less on how persuasive a few selected leaders are and more on how receptive the “society” is to the idea. In practice it is often unexpected members of the rank and file who feel compelled to step up and make a difference in driving change. That’s why we warn against overinvesting in influence leaders and advocate that change leaders’ attention should be balanced across the right application of all four conditions for change, to ensure they reinforce each other in ways that maximize the probability of the change spark taking off like wildfire across the organization.

## Reinforcing mechanisms

Conventional change management emphasizes the importance of reinforcing and embedding desired changes in structures, processes, systems, target setting, and incentives. We agree. To be effective, however, these mechanisms must take into account that people don’t always behave rationally.

6. Money is the most expensive way to motivate people. Companies that try to link the objectives of change programs to the compensation of staff find that it rarely enhances their motivation for change to the extent desired. The reason for this is as practical as it is psychological in nature. The reality is that in the vast majority of companies, it is exceedingly difficult to incorporate a meaningful link to the change program within compensation systems that are based on a vast array of metrics. Moreover, many studies have found that for human beings satisfaction equals perception minus expectation (an equation often accompanied by the commentary, “reality has nothing to do with it”).

The beauty of this equation for change managers is that small, unexpected rewards can have disproportionate effects on employees’ satisfaction with a change program. Gordon M. Bethune, while turning around Continental Airlines, sent an unexpected $65 check to every employee when Continental made it to the top five for on-time airlines. John McFarlane, former CEO of ANZ Bank, sent a bottle of champagne to every employee for Christmas with a card thanking them for their work on the company’s “Perform, Grow, and Break-out” change program. Most change managers would refer to these as merely token gestures and argue that their impact is limited and shortlived. Employees on the receiving end beg to differ. Indeed, they consistently report back that the rewards have a disproportionately positive impact on change motivation that lasts for months, if not years.

7. The process and the outcome have got to be fair. Employees will go against their own self-interest if the situation violates other notions they have about fairness and justice. Consider a bank, which, as part of a major change program, created new risk-adjusted return on capital (RAROC) models and delivered the resulting new pricing schedules to the front line along with new and appropriate sales incentives. The result: customer attrition (not only of the unprofitable ones) and price overrides went through the roof and significant value was destroyed by the effort. What went wrong? Because the frontline bankers perceived the changes as unfair to the customer, a significant number of them vocally bad-mouthed the bank’s policies to customers and used price overrides to show their good faith, even though it meant they were less likely to achieve individual sales goals.

In making any changes to company structures, processes, systems, and incentives, change managers should pay what might strike them as an unreasonable amount of attention to employees’ sense of the fairness of the change process and its intended outcome. Particular care should be taken where changes affect how employees interact with one another (such as head count reductions and talent-management processes) and with customers (sales stimulation programs, call center redesigns, and pricing). Ironically, in the pricing example described above, the outcome was inherently fair (customers are being asked to pay commensurate to the risk the bank is taking on), and therefore the downward spiral described could have been avoided (and has been by other banks adopting RAROC-based pricing) by carefully tending to employees’ perceptions of fairness in the communications and training surrounding the changes.

## Recommended reading

John P. Kotter, Leading Change, Boston: Harvard Business Press, 1996.

Danah Zohar, Rewiring the Corporate Brain: Using the New Science to Rethink How We Structure and Lead Organizations, San Francisco: Berrett-Koehler, 1997.

Richard Barrett, Liberating the Corporate Soul: Building a Visionary Organization, Woburn, MA: Butterworth-Heinemann, 1998.

Don Edward Beck and Christopher C. Cowan, Spiral Dynamics: Mastering Values, Leadership, and Change, Oxford, UK: Blackwell Publishing, 1996.

Ellen J. Langer, “The illusion of control,” in Judgment under Uncertainty: Heuristics and Biases, eds. Daniel Kahneman, Paul Slovic, and Amos Tversky, Cambridge, UK: Cambridge University Press, 1982. This chapter describes the lottery ticket study mentioned previously.

Andreas Priestland and Robert Hanig, “Developing first-level leaders,” Harvard Business Review, 2005, Volume 83, Number 6, pp. 112–20.

Bernard J. Mohr and Jane Magruder Watkins, The Essentials of Appreciative Inquiry: A Roadmap for Creating Positive Futures, Waltham, MA: Pegasus, 2002. The juxtaposition of the deficit-based and constructionist-based approaches to change is described in this work.

Daniel Kahneman and Amos Tversky, “Choices, values, and frames,” American Psychologist, 1984, Volume 39, Number 4, pp. 341–50. In this article, Kahneman and Tversky propose evidence that humans are “irrational” loss avoiders.

Brad M. Barber and Terrance Odean, “Boys will be boys: Gender, overconfidence, and common stock investment,” Quarterly Journal of Economics, 2001, Volume 116, Number 1, pp. 261–92.

Michael Ross and Fiore Sicoly, “Egocentric biases and availability and attribution,” Journal of Personality and Social Psychology, 1979, Volume 37, pp. 322–36.

Dan Ariely, Predictably Irrational: The Hidden Forces that Shape Our Decisions, New York: Harper Collins, 2008.

Fred Nickols, “Change management books,” April 2, 2006. This list, compiled by Nickols, aggregates highly recommended books on change management.

## Capability building

Change-management literature emphasizes the importance of building the skills and talent needed for the desired change. Though hard to argue with, in practice there are two insights that demand attention in order to succeed.

8. Employees are what they think, feel, and believe in. As managers attempt to drive performance by changing the way employees behave, they all too often neglect the thoughts, feelings, and beliefs that, in turn, drive behavior. Consider a bank that through a benchmarking exercise discovered that its sales per banker were lagging behind those of the competition. After finding that bankers spent too little time with customers and too much time on paperwork, the bank set about reengineering the loan-origination process in order to maximize customer-facing time. Unfortunately, six months later, the levels of improvement were far lower than envisioned.

A further investigation, with an eye to the bankers’ mind-sets rather than their behaviors, revealed that they simply found customer interactions uncomfortable and therefore preferred paperwork. This feeling was driven by a combination of introverted personalities, poor interpersonal skills, and a feeling of inferiority when dealing with customers who (by and large) have more money and education than the bankers do. Finally, most bankers were loath to think of themselves as salespeople—a notion they perceived as better suited to employees on used-car lots than in bank branches.

Armed with these root-cause insights, training for bankers was expanded to include elements related to personality types, emotional intelligence, and vocational identity (recasting “sales” as the more noble pursuit of “helping customers discover and fulfill their unarticulated needs”). This enhancement not only put the program back on track within six months but also ultimately delivered sustainable sales lifts in excess of original targets.

9. Good intentions aren’t enough. Good skill-building programs usually take into account that people learn better by doing than by listening. These programs are replete with interactive simulations and role plays, and commitments are made by participants regarding what they will “practice” back in the workplace. But come Monday morning, very few keep their commitments.

This lack of follow-through is usually not due to ill intent: it is because nothing formal has been done to lower the barriers to practicing new skills. The time and energy required to do something additional, or even to do something in a new way, simply don’t exist in the busy day-to-day schedules of most employees. This failure to create the space for practice back in the workplace dooms most training programs to deliver returns that are far below their potential.

We advocate a number of enhancements to traditional training approaches in order to hardwire day-to-day practice into capability-building processes. First, training should not be a one-off event. Instead, a “field and forum” approach should be taken, in which classroom training is spread over a series of learning forums and fieldwork is assigned in between. Second, we suggest creating fieldwork assignments that link directly to the day jobs of participants, requiring them to put into practice new mind-sets and skills in ways that are hardwired into their responsibilities. These assignments should have quantifiable, outcome-based measures that indicate levels of competence gained and certification that recognizes and rewards the skills attained.

In the same way that the field of economics has been transformed by an understanding of uniquely human social, cognitive, and emotional biases, so too is the practice of change management in need of a transformation through an improved understanding of how humans interpret their environment and choose to act. While sustained impact can be measured only over numbers of years, our early results when applying these insights give us the confidence to broadly share our thinking.

## How relevant and useful is this article for you?

## About the author(s)

Carolyn Aiken (now Carolyn Dewar) is a principal in McKinsey’s Toronto office, and Scott Keller is a principal in the Chicago office.

After publication of this article, the author's name changed to Carolyn Dewar.

## Explore a career with us

## Related Articles

## The four building blocks of change

## Build a change platform, not a change program

## Changing change management","{""publication_date"": ""April 1, 2009"", ""word_count"": 3540, ""reading_time_minutes"": 18}",2025-03-14 11:52:34.952500
6,Change management will be critical to implementing generative AI,https://www.mckinsey.com/featured-insights/lifting-europes-ambition/videos-and-podcasts/change-management-will-be-critical-to-implementing-generative-ai,,"## Change management will be critical to implementing generative AI

The big conversation I wish was happening more among the organizations currently exploring gen AI is how to make the change stick and scale. At the end of the day, when you look at many of the companies right now, they're in exploration mode, which is correct, since this is new. They're throwing out some proofs of concept (POCs) to find the value, and what it will take to achieve. The big question revolves around the end intervention. What change will be needed in the organization to unlock the benefits? What do humans need to do differently to accept, adopt, and scale gen AI? I see more effort needed on that front in many organizations.

Similarly, on the technology side, one piece is about proving what the technology can do. And for those who really want to adopt and scale, another piece involves putting those foundations in place. Do you have the machine learning operations (MLOps) needed to productionize many, many, many models at scale? Do you have the data foundation necessary to really fuel the models and unlock the opportunities at that scale? I think those are the two conversations I would love to see taking place more across Europe.

## How relevant and useful is this article for you?

## About the author(s)

Louise Herring is a partner in McKinsey’s London office.

Comments and opinions expressed by interviewees are their own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement.

## Explore a career with us

## Related Articles

## Lifting Europe’s Ambition on generative AI

## Leveraging generative AI in Europe: The opportunities and challenges","{""publication_date"": ""October 17, 2023"", ""word_count"": 288, ""reading_time_minutes"": 1}",2025-03-14 11:52:41.144371
7,Personalizing change management in the smartphone era,https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/personalizing-change-management-in-the-smartphone-era,,"## Personalizing change management in the smartphone era

CEOs know that making organizational change stick requires convincing big groups of geographically dispersed people to think, act, and approach their work differently. And this is devilishly hard, as human beings are motivated by many things, have different fears and aspirations, feel varying levels of empowerment and commitment, and tend to be reluctant to change in the first place. Undifferentiated approaches that don’t carefully consider employees’ mindsets will fall flat and may even breed cynicism that saps morale and undermines progress.

The good news is that when it comes to personalization, senior executives have plenty of inspiration, courtesy of analytical pioneers such as Instagram, Netflix, and Spotify, all adept at tailoring products to meet individualized preferences via apps and other easy-to-use digital platforms. A large global manufacturer’s ongoing experiment in tech-infused mass personalization shows how this thinking can be applied to organizational change. The company’s experience suggests how smart combinations of digital technology, analytics, and behavioral science can make change more inclusive and persuasive—and help employees unleash their enthusiasm in ways not possible otherwise. The key is to use the available tools to better understand people and meet them where they are—a guiding principle that’s equally relevant for implementing long-term change and for leading a remote workforce through the current disruptions caused by the COVID-19 pandemic.

## Get focused

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

For a few years, the manufacturer had tried with limited success to implement cultural changes across a key region’s 7,000-strong workforce—for example, by promoting behaviors it hoped would break down silos, empower and motivate frontline workers, and bolster performance. Now the CEO wanted a fresh start. An assessment highlighted places where the company’s organizational health was poor or needed strengthening. From these areas, senior leaders focused on three management practices: operational discipline, inspirational forms of leadership, and the use of rewards and recognition to better motivate employees.

Undifferentiated approaches to change that don’t consider employees’ mindsets will fall flat and may even breed cynicism.

The company then formed a team to translate these broad cultural goals into specific mindsets and behaviors that would both generate the desired organizational outcomes and also help employees better understand how they personally contributed to the improvement. For example, the manufacturer wanted employees to think of operational discipline as everyone’s job. One tangible way to promote this would be to encourage shop-floor operators and supervisors to consciously review the company’s “golden rules of safety” before every shift. Likewise, the company sought to instill a mindset of valuing continuous improvement and celebrating small victories. One way of doing this would be to encourage people to speak up immediately when they saw a colleague do something positive (a motivational take on the mantra “if you see something, say something”).

## Clear the roadblocks

The team now had a discrete set of behaviors they wanted to encourage. But they knew that to do so effectively, they needed to meet people where they were—they couldn’t simply tell people to change. The team needed to address any mindsets or beliefs that could act as barriers. Lessons from organizational psychology and behavioral science helped identify a range of potential roadblocks, and an assessment survey of employees and subsequent analysis to spot patterns in the data helped the manufacturer isolate the most prevalent roadblocks to tackle. While the roadblocks themselves touched upon several factors (for example, employees’ beliefs about whether a given behavior is part of their job or conflicts with their personal values) the roadblocks broadly fell into three types (exhibit): “I’m not allowed,” “I can’t,” and “I won’t.”

Company leaders quickly saw how roadblocks could prevent employees from adopting beneficial behaviors. For example, the manufacturer had long encouraged supervisors to take “gemba walks”—visits to the shop floor that help spot production issues and encourage useful conversations with frontline workers. Yet the analysis showed that many supervisors didn’t prioritize the walks or make time for them, in part because they thought the culture didn’t truly support them using their time this way and also because they worried they’d be bombarded during the walks by new problems they couldn’t handle.

## Make it personal—at scale

To address the roadblocks most effectively—and advance the transformation’s broader goals—the team ran a pilot project involving 500 employees. The goal: serve up a rich mix of daily content (videos, text-based messages, and short quizzes) all designed to encourage employees to embrace the changes personally. The content was delivered via mobile-phone app in order to make the most of employees’ existing preferences and habits; moreover, the app’s content was tailored for both frontline operators and supervisors, as well as for different shop-floor locations inside the facility. Crucially, the app’s algorithm paired the tips, reminders, and suggestions it delivered to employees with the roadblocks they reported experiencing. Periodic web-based quizzes provided data that showed the degree to which employees experienced the roadblocks, and gauged progress overcoming them. The result was, essentially, a customized development plan that supported a range of personalized interventions and that could be optimized in real time.

A supervisor we’ll call Heloisa,1All the personal data the company used as part of the change program were anonymized to protect employees’ privacy and to help ensure their candor in responding to surveys. for instance, reported having difficulty finding the time to give feedback to her team of operators. When she opened the app, she was prompted to watch a short video of her colleagues discussing how important they felt it was to receive feedback. Then, a few days later, Heloisa received a push notification explaining practical approaches for delivering quick, effective feedback. Meanwhile, a frontline operator we’ll call Juan was resisting giving feedback because he felt that doing so would hurt his relationship with his coworkers. When he accessed the platform, among the content bits he received were messages to help him realize the importance of constructive feedback in establishing a safe and efficient workplace.

Six weeks into the change program, Ana reported a significant shift in how frequently she recognized others—a testament to the skills she developed through coaching.

In addition to clearing roadblocks, the platform helps employees reach the program’s broader cultural goals. A supervisor we’ll call Ana, for instance, wasn’t recognizing the small, daily victories of her colleagues, largely because she didn’t feel she had the skills to do so. When she engaged with the platform, she received bite-size exercises and coaching to help build this capability. Six weeks into the change program, Ana reported a significant shift in how frequently she recognized others—a testament to the skills she developed through the coaching and an improvement directly linked to a management practice (“rewards and recognition”) that the company was prioritizing.

## Manage for impact

The team manages the app in conjunction with the same centralized “transformation office” that leads the broader change effort. This gives senior executives an integrated view of where things are progressing or lagging. Dashboards show where participation rates on a module are down, or where employees aren’t retaining certain information, allowing the company to make adjustments in real time.

During the launch of the pilot, for example, the data suggested that some employees weren’t answering questions candidly; they were simply choosing the most optimistic-sounding responses to survey questions. The team updated the algorithm so that if users appeared to be answering questions in a pattern, a pop-up message reminded them that their responses were always anonymous and unlinked to the company’s HR systems (a vital message, and one that was communicated continually and in other forms). Responses to the roadblock assessment quickly became more realistic, which both confirmed the challenge ahead and gave the team confidence that employees increasingly trusted the effort and took it seriously.

Adding communal aspects to the app—the ability to post user-generated images, videos, and messages within the content feed, as well as sharing, tagging, and “like” functionality—encouraged more employees to interact with the platform and helped spur enthusiasm for the pilot. And, as more employees shared their stories, posted photos, and called out good behavior, it also reinforced the program’s goals (after all, people are more likely to follow through on behavior change when they commit to it publicly). Simple gamification, including the addition of “badges” for social posts, helped too. Indeed, as word of the platform spread and people became curious, employees who weren’t part of the pilot wanted in, and what was meant to be a test for 500 employees quickly expanded to allow all 7,000 employees to participate.

As word spread and people became curious, employees who weren’t part of the pilot wanted in.

The results of the three-month pilot have been encouraging, and the company is now rolling out the effort more broadly. Overall attainment scores suggest an average individual improvement of 10 percent against the three management practices the company is prioritizing. Improvements in some areas were rapid—with scores rising about 5 percent every two weeks over the span of the pilot. Meanwhile, the manufacturing unit involved in the effort enjoyed a 6 percent increase in production, an encouraging result that company leaders attribute to a combination of the pilot along with a focused effort to reinforce lean-management principles.

Importantly, employees inside the manufacturing unit report that the work feels different, as momentum for the program grows. Night-shift workers have demonstrated particular enthusiasm. Whereas before, change efforts might have seemed mystifying or incomplete to them—motivational posters appearing in the workspace overnight, companywide mass communications from leaders they rarely saw—now the goals of the program made sense. The platform has also improved their level of recognition in the company and their connectedness to the day shift, which is helping break down the silo mentality that worked against the company’s operational and safety goals.

Change is hard, and change is intensely personal. When we know what’s expected of us, see how our unique efforts contribute to the whole, and are encouraged to treat change as a personal journey, we are more likely to be energized by the prospect of change than fearful of it. As the manufacturer’s experience suggests, smart combinations of technology, analytics, and behavioral science can help catalyze change at scale in ways that aren’t possible otherwise.

## How relevant and useful is this article for you?

## About the author(s)

Alexander DiLeonardo is a partner in McKinsey’s London office, David Mendelsohn is a specialist in the New York office, Nikil Selvam is a consultant in the Waltham office, and Alexandra Wood is a consultant in the New Jersey office.

The authors wish to thank the many contributions that Nick Rosemarino made to this article, and also to thank Vijay Agarwal, Deepankar Agrawal, Anita Baggio, Aditya Chauhan, Adam Clover, Sourabh Gupta, Taylor Lauricella, Ursula Lehnert, Ran Li Phelps, Vikram Rajpoot, Pru Rowe, Bill Schaninger, Riddhi Shah, Iyad Sheikh, Stephanie Smallets, and Yihang Yan for their collaboration.

## Explore a career with us

## Related Articles

## Organizational health: A fast track to performance improvement

## Want a better decision? Plan a better meeting

## Getting personal about change","{""publication_date"": ""May 14, 2020"", ""word_count"": 1902, ""reading_time_minutes"": 10}",2025-03-14 11:52:47.902518
8,All I ever needed to know about change management I learned at engineering school,https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/all-i-ever-needed-to-know-about-change-management-i-learned-at-engineering-school,how things work,"## All I ever needed to know about change management I learned at engineering school

I have always been fascinated by how things work. As a child, I would follow my father around the yard, helping him with various projects. How, I wondered, did the load in the wheelbarrow always balance? Why could I move a big rock with a crowbar, but not without? How does cement dry underwater?

It is hardly surprising that when I came of age, I followed in my father’s footsteps once more, this time to engineering school. Here I learned the precise formulae that govern the forces of nature. Boring to some, for me these axioms held a special magic, because understanding them conferred great power—the power to harness the forces of nature for the works of man.

I have strayed from my professional roots. Over the past decade at McKinsey, I have helped clients design and execute major change programs, and led research projects on frontline change, operational improvement, and company-wide transformation. I have borrowed many good ideas from the literature on personal and organizational change. Often, however, it has left me wondering how change really works.

I am a mechanical engineer. We mechanical engineers tease our civil engineering colleagues that they only have to figure out how to make things stand up or fall down. Mechanical engineers have to figure out how to make things go round and round—a skill of a higher order. Making change always seemed to me like mechanical engineering, but a lot of the literature reads as if it were written by civil engineers.

You can read books on the four, five, or six things you have to do to make a great company stand rather than fall, as though the corporation were a civil structure that you could make stand up, and leave it at that. These static, normative models are admittedly helpful, presenting as they do a vision of what ""good"" looks like, and identifying some of the changes that can bring it about. But they do not really capture the dynamic characteristics of change. They will not bring to life what happens when a dynamic system gets out of balance, when momentum falters, when the best-laid plans yield unexpected results. They won’t explain, in other words, how you get change to go round and round.

My colleagues and others tell me that business leaders like the static, normative way of thinking. This article, then, may not be for everyone. But there may be a few other poor souls who, like me, got hooked early on understanding the basic laws that govern action. So I decided to write down the five basic premises I consider as I help clients design their change programs—ideas I think of as natural laws of organizational change.

These laws are inspired by the power of scientific thinking. Unlike scientific laws, however, they have not been conclusively proven through controlled experiments. They represent a personal perspective developed through reading and research, as well as through trial and observation in the daily routine of client service. They are: the law of constituent balance, the law of leverage, the law of momentum, the law of feedback and adjustment, and the law of leadership.

## The law of constituent balance

The need for major change is often driven by an imbalance between a company’s constituent stakeholders: shareholders, employees, customers, communities, and management. This basic law answers the question ""Why change?""

Nature consists of ecosystems in balance—structures in which different species live interdependently. When an ecosystem is knocked out of balance for whatever reason, a period of often violent flux follows, during which scarce resources are dynamically redistributed and the system arrives at a new balance that better reflects the new environment. Similarly, when constituent interests are out of balance in a large corporation, a power struggle erupts. The gloves come off as shareholder groups rebel against complacent management, or customers punish a company for poor quality. The mentality of scarcity is at play.

Where possible, this imbalance should be exploited to create the conditions for change. However, if a winning formula, once found, is to be sustained, the system must eventually be brought back into balance. High performance can be maintained only when a mentality of surplus has been restored: when customers are satisfied, talent and investment flow in, and management, employees, and shareholders feel adequately rewarded. The evolution of constituent balance during the change provides clues as to which forces can be harnessed at different times to drive the change forward.

Early capitalist models emphasized the claims of owners and customers. More recently, democratic pluralist societies have substituted shareholders for owners and added employees and communities to create the four-stakeholder model that many modern corporations have in their credo. What always gets left out of the model, but should not be forgotten, is that a fifth group, management, weighs heavily in the balance of power. What value has an analysis of Iraq that does not consider Saddam Hussein?

## The law of leverage

Maximize the return on effort by changing the things that will produce the greatest results. This law helps me understand what to change.

Archimedes deduced over 2,000 years ago that force could be multiplied by applying it to a lever at a particular distance from a fulcrum. ""Give me a lever,"" he said, ""and I will move the world."" Finding the right levers—and pushing them hard enough—is as critical in change management as it is in mechanics.

My experience has been that our instinct is to make more changes than are necessary, without applying enough insight into which changes really matter. Too often, we are simply anxious to make something happen. How can we identify the important changes, and resist acting on secondary problems?

Much of the literature on change implies that a high-performing company needs to do everything remarkably well—and, in recommending across-the-board reengineering, seems to take for granted that low-performing companies must be doing everything badly. In fact, high-performing companies do many things imperfectly; they just do the important things—or enough of the important things—well. Meanwhile, underperforming companies often do many important things fairly well, but not with enough intensity.

Indeed, once analysis has confirmed which levers should be pulled, extraordinary tenacity will be required to pull them hard enough to drive changes uncompromisingly over the 60 percent threshold. Doing something 60 percent of the way is often enough; doing something 40 percent of the way, on the other hand, is often no better than doing nothing at all. That 20 percent swing makes all the difference. All of this means you have to examine a company very broadly before determining what really needs changing, and what merely needs intensifying. Your eventual path of action will be narrow, but to exploit the law of leverage you must begin with a wide field of vision.

Unfortunately, most of us start out blind in at least one eye. As an engineer, I found isolating the economic drivers of performance straightforward, but it was not until I worked alongside a firm specializing in cultural change that I came to understand the power of changing people’s beliefs. Some CEOs have acute antennae for cultural symptoms; others see only business results. You need to learn to see in a number of dimensions, and to integrate what you see into a coherent picture.

Tools can help, but few tools offer a complete paradigm. Recently, I have found that looking carefully at three types of levers has sharpened my vision. First, take aim at the direct economic levers: driving down costs and increasing revenues. Then, understand how levers that focus the organization—structures, processes, targets—affect performance indirectly. Finally, examine the performance context: levers such as vision, values, and power base.11.See Roger Dickhout, Michael Denham, and Norman Blackwell, ""Designing change programs that won’t cost you your job,"" The McKinsey Quarterly, 1995 Number 4, pp. 100–116, for more on this.

Acting on a path narrower than your field of vision calls for self-control and detachment—a detachment that must paradoxically be combined with an intense performance orientation and an impatience for results. As we have seen, you can do a lot of things fairly well and still not achieve the performance you aspire to; fortunately, you can also do a lot of things wrong as long as you get the important things right and drive hard enough on these to make the difference. Seek the fewest changes for the greatest result.

## The law of momentum

Liberate the energy to drive the change.

""We have to get this place in gear."" ""The challenge now is to keep moving forward."" ""We are running out of steam. How do we get restarted?"" Experienced change leaders struggle with these basic problems. Change is work. Work requires energy. Where is the energy to come from?

The first law of thermodynamics states that energy can be neither created nor destroyed. Consequently, the energy required to change a system from one state to another must come either from within a closed system as energy changes its form (from light to heat, say, or pressure to temperature), or from beyond the boundaries of the closed system.

So too with major change. Energy can be introduced from outside—as with pressure from shareholders or new management—or the system’s own potential energy can be transformed into kinetic energy. Potential energy is released by raising the aspirations and shaping the beliefs of pivotal members of the organization, and by liberating available capacity and capability to work on the change.

As with mechanical engineering, the horsepower of the engine must be matched to the task, or the task scaled to the horsepower of the engine. Consequently, the law of leverage, which focuses energy on the key changes, is especially critical during takeoff, when energy may be scarce.

Energy limits can also be managed by offsetting endothermic, energy-consuming change initiatives with exothermic, energy-liberating ones. A frontline focus on customer satisfaction, directly exposing a company to the demands of its customers, will unleash a massive surge of energy across the whole organization. On the other hand, cost reduction, while it may be a critical ingredient of a change program, often consumes energy by arousing fear at the same time as it removes capacity. Focusing sharply and quickly on cost opportunities and avoiding enervating rounds of organizational downsizing can minimize the energy required, but the sort of spontaneous combustion that can be generated by customer satisfaction efforts is unlikely to materialize.

Similar to the exothermic/endothermic balance is the balance between push and pull that a skilled change agent will exploit to get change going. Major change will inevitably call for new behaviors. The change agent instinctively gives the system a push by building new tools to enable these behaviors. Simultaneously, he or she must create a pull, or demand for these tools, by putting in place new targets and measures that will focus the organization on the desired behaviors, in turn causing it to reach for these tools.

If it is to drive continuing change, a change effort must build sources of energy as well as producing results. Accomplishing a transformation from low to high performance can take several episodes over a number of years. To power these episodes, a company must discover a pattern of change that builds momentum within an episode and that promotes the shared vision, confidence, leadership capacity, and capabilities that will make the next episode possible.

The particular strategy will vary with the situation. Eliminating a layer of change-resistant management and reorganizing into segment-focused business units can liberate the energy needed to engage new management in the task of improving performance. When this kind of approach reaches its limitations, however, new blood may be required before the next episode can be launched. But the general law remains: you must achieve results and build energy for more change. If you do not go forward, you will slip back.

## The law of feedback and adjustment

Learn how your organization responds to change, and adjust the program accordingly.

The laws of leverage and momentum offer insight into harnessing the underlying physics of your business system. But there are limits to the predictability of change. Acting on the bottlenecks to improvement will create new bottlenecks. Moreover, the forces driving the change will ebb and flow. Competitors may become stronger, raising customers’ expectations and redefining performance levels; shareholders may win more control; management may gain or lose courage. Change may itself create opportunity.

In mechanical engineering, control theory dictates that a closed-loop control system is required to monitor a transformation process when response characteristics are sensitive to environmental conditions. In a closed-loop system, transducers measure the input and output of the system and compare the actual output to the expected output. Then the input can be iteratively adjusted until the desired result is achieved.

In the same way, however complete the field of vision in a major change situation, or however sophisticated the strategies to generate momentum, some changes are bound to work out less well than others. In change efforts, leadership actions combine with the communication of the aspiration for change and its specific objectives to create an ""input."" Project structures, targets, and milestones provide a framework for measuring actual against expected ""output"" so that leadership actions can be modified accordingly. Thus early actions, while producing results and increasing energy, also serve as a dynamic diagnostic. You will learn at least as much by watching your organization’s response to change as by analyzing its current state.

Change leaders also establish other, less formal networks and processes to gauge progress and reset priorities for action. These make it possible to identify when an organization is running out of steam, or, conversely, when it has the confidence to take on a bigger challenge. Being dynamically responsive to change as it progresses also allows you to take advantage of timing. An obvious need to restructure work practices, for example, may be impossible to address in a tight market with an entrenched union leadership. If prices fall and union leadership changes, however, an opportunity may arise to broaden the change program in mid-stream.

## The law of leadership

Leadership is the catalyst of change.

In chemistry, small amounts of catalyst intensify and accelerate reactions in much larger masses. Indeed, in many chemical reactions, all the ingredients may be in place, but if the catalyst is absent, nothing will happen. Similarly, the four basic mechanisms of change—exploiting the imbalance between constituents, focusing on the high-leverage opportunities, generating momentum by liberating energy, feeding back and adjusting—are always intensified and accelerated by the personal example of a change leader. Without it, the change may be stillborn. Ultimately, leadership is the scarce resource.

The aspirations and preferences of the primary protagonist have a big impact on the way change unfolds. Notwithstanding the need for a broad field of vision, leaders do come with approaches they are most comfortable with. There is no such thing as a perfect leader. If change is to have credibility within an organization, it must be congruent with the actions of its leader.

Establish a small team at the top—think two to three, not one, not ten—to initiate and guide the change. These people must be role models for leaders down the line. Propel the vision, engaging the down-the-line leaders in the process of change through targets and objectives. Align coalitions: satisfy mutual interests where possible, but don’t be afraid to use your power if you have to (change, like everything else, has a dark side). Set expectations very high; the organization may not know what excellent performance looks like. Create new symbols by celebrating success and destroying vestiges of the old culture. These are the critical catalyzing activities in the process of change.

Well, for me, that’s how things work. There are obviously many specifics that need to be considered in any change process—industry dynamics, functional knowledge, the characteristics of the organization in question—and particular strategies must be devised to exploit them. But I find that no matter whether it is a resource or a consumer business, an Indian or a Canadian company, a total organizational change or a plant turnaround, these basic laws seem to hold. It’s easy to get lost in the nuts and bolts of performance imperatives, personalities, and processes. By stepping back to first principles, you can rise above minutiae to identify the crucial actions it will take to transform your company.

## How relevant and useful is this article for you?

## About the author(s)

Roger Dickhout is a principal in McKinsey’s Toronto office.

I would like to acknowledge Steve Dichter’s contribution to the thinking in this article, and particularly his idea that change is governed by a set of principles.

## Explore a career with us

## Related Articles

## Helping employees embrace change","{""publication_date"": ""May 1, 1997"", ""authors"": [""how things work""], ""word_count"": 2803, ""reading_time_minutes"": 14}",2025-03-14 11:52:54.391274
9,Five principles to manage change in the military,https://www.mckinsey.com/industries/public-sector/our-insights/five-principles-to-manage-change-in-the-military,"about $65 billion between 2012, 2015","## Five principles to manage change in the military

Defense spending has been under pressure for some time now in the developed world. After climbing dramatically for the better part of a decade in the aftermath of September 11, 2001, defense spending began to fall in many countries after the global financial crisis of 2008. European members of the North Atlantic Treaty Organization were the first to make cuts, with total spending falling by $37 billion from the high-water mark in 2008 through 2012, and
a further $4 billion in cuts between 2012 and 2015 is expected. Even the United States, where spending continued to rise until 2011, plans to reduce spending by about $65 billion between 2012 and 2015. The pressure of trying to squeeze more military capability from declining defense dollars has been with us for a number of years and seems likely to continue.

It’s not that hard for reasonable people to agree on a set of steps that militaries must take to cope with the tremendous pressures they face today. In the United States, for example, in June 2013, a bipartisan group of defense analysts agreed on an agenda of changes for the US Department of Defense. In Europe, many militaries have long agreed in principle to the pooling and sharing of equipment.

However, acting on the agenda is much harder, especially in today’s complex environment. The initiatives that militaries are contemplating—intensive, programmatic, cross-discipline, and often cross-service changes to fundamental processes such as procurement, logistics, and maintenance—are not minor adjustments. The changes these initiatives entail are transformational, not incremental, and require major shifts in mind-sets, behaviors, and capabilities.

Successfully implementing this type of transformational change is not easy; indeed, the majority of transformation programs in both the public and private sector fail. Our recent survey of almost 1,000 leaders and senior employees in more than 30 US government agencies found that only 40 percent believed that their transformation programs succeeded.

However, our experience with large-scale transformation programs in defense organizations around the world has taught us five lessons that can help contribute to the success of a defense transformation.

Start at the sharp end. Defense leaders are concerned first and foremost with preparing, deploying, and sustaining forces to deliver operational effect. Change programs in defense that start with operational effectiveness create stronger engagement and are more likely to succeed than those focused primarily on cost reduction. The United Kingdom’s work on end-to-end logistics serves as a good example. Rather than focusing primarily on cost reduction, the program set out to deliver a number of important operational improvements. These included reducing the deployed footprint, improving supply-chain performance, and increasing platform availability. By proposing to deliver a superior operational solution, the program secured the full support of operational commanders.

As a result of this work, delivery time to bases in the United Kingdom and Germany decreased from 30 days to 7 days, among other effects. In Afghanistan, customer wait time was reduced by 15 days. In almost all of the areas investigated, the program also delivered a more cost-effective solution. This served to prove that a better solution is usually also a cheaper one, though the converse is not always true. In its annual report and accounts for 2003–04, the UK Ministry of Defence reported that the end-to-end logistics review both improved logistics effectiveness and generated savings for investment in other priorities.

Similarly, in its restructuring as part of the Danish Defence Agreement (Forsvarsforlig) 2005–09, the Danish Defence set out to move from a static, defensive posture to one that could better support expeditionary missions abroad. The Danish Ministry of Defence described the situation and the work it did: “The support structures, the tail, had grown out of proportion, and the operational structures, the teeth, had reached a level of close to irrelevance. The restructuring from scratch entails a change in emphasis in order to bring the priorities from 40 percent operational capabilities and 60 percent support structures to 60 percent operational capabilities and 40 percent support structure.”11.General H. J. Helsø, “Transformation is key to armed forces’ relevance,” Danish Defence, July 2013, forsvaret.dk.  In the process of designing a more deployable force, the Danish military reduced support costs by a third.

Lead through the line. In a typical transformation program, a project team—often working in relative isolation—defines the program’s objectives, designs initiatives, and expects personnel on the ground to implement them. This is a mistake, particularly in military organizations where, in our experience, commanders often prefer to give up budget rather than authority. In contrast, leaders of successful defense transformations empower line personnel, set clear expectations of them, and hold them accountable for the transformation’s success within the established chain of command. The UK’s Defence Logistics Transformation Programme was particularly successful in this regard. Warfighters were embedded into each of the project teams and helped shape the specific recommendations. Suggested changes were then vetted with the appropriate frontline commanders, who were able to quiz their own embedded staff about the suitability of the resulting initiatives. An audit of the program by the UK Office of Government Commerce found “the programme appears to have been notably successful, through a structure of programme boards, in obtaining buy-in at senior levels in the frontline commands whose full involvement in implementing the change will be vital to success.”22.UK Office of Government Commerce Gateway Review 888.  Leading change programs “through the line” in this way capitalizes on the can-do attitude of military culture, empowering officers to hit aggressive targets set through the chain of command.

Resist the urge to reorganize; start with quick wins. When embarking on a transformation program, it can be tempting to focus first on reorganization. But an initial emphasis on roles, responsibilities, and reporting often delivers few results. Leaders of successful defense transformations resist the urge to reorganize; they focus first on securing successes that can make a big difference to the momentum of a program. They specifically aim to achieve quick wins, often through targeted pilots, over the first three to six months. Many of these initial successes can then be turned into transformational change across the organization.

In one example from 2009, a defense ministry conducted a diagnostic to assess the quality of procurement processes, organization structures, and outputs in its defense establishment. The diagnostic also assessed the value received for expenditures and the scale of the opportunity for achieving efficiencies. Detailed analyses of six categories covering approximately one-third of nonequipment purchasing identified the potential for annual savings as 8 to 10 percent. The diagnostic homed in on three root causes of inefficiencies. First, the defense establishment lacked a single point of accountability for each category. No function or individual in the organization had visibility into the cost implications of decisions made at each step of the process. Second, the absence of performance metrics resulted in an insufficient focus on cost efficiency. Third, a series of organizational, process, and budgetary barriers impeded efforts to capture scale benefits. The ministry piloted several initiatives to address these inefficiencies in four nonequipment categories. For each category, it created an integrated category-management team. Based on the success of this effort, it then conducted a major overhaul of the budgeting process and redesigned the purchasing organization by appointing a “lead purchaser” to manage each generic category. By running the pilots first, it was able to point to its success to overcome resistance within the organization.

## Would you like to learn more about our Aerospace & Defense Practice?

Expect (and plan to overcome) resistance to change. B. H. Liddell Hart probably said it best: “The only thing harder than getting a new idea into the military mind is to get an old one out.”33.B. H. Liddell Hart, Thoughts on War, first edition, London, United Kingdom: Faber and Faber, 1944.  Many military leaders would agree that their organizations are highly resistant to change as a result of their size, complexity, and culture. Yet despite a general awareness of this challenge, even seasoned defense leaders underestimate the degree of inertia and resistance to change within their organization. Leaders of successful defense transformations take an end-to-end approach to overcome this inertia in two ways. First, they set a clear vision and ambition for the transformation—one that emphasizes the link to the organization’s overall mission, clarifies why the program is necessary, and outlines a journey over the coming years that resonates within the organization. When the Danish Defence restructured to adjust to a more expeditionary posture, it set an ambitious goal to reduce support costs by a third while maintaining output, a target reached as promised within four years. The savings were required to fund a series of important increases in deployable forces, which served to secure support from operational commanders. Second, leaders of successful transformations provide credible and visible commitment to the transformation from top-level leadership. The United Kingdom’s end-to-end review of air and land logistics, for example, was jointly led by the vice chief of the defense staff and the Ministry of Defence’s second permanent undersecretary.

Invest in building capabilities. Building the right capabilities is a prerequisite to achieving and sustaining change in any organization. Among US government leaders who reported limited success in their change efforts, 75 percent said that the right capabilities were not present. In many defense ministries, leaders rise through the ranks based on a substantial body of excellent work that demonstrates mastery of core military and leadership skills critical to warfighting. But achieving and sustaining change often requires not military but management capabilities in fields such as project management, procurement, and product development. Successful transformation programs first define the core and functional capabilities required and then invest in building these capabilities using programs that follow best-practice adult-learning principles. Such approaches, which are familiar to the military from its combat-skill development, can be six to seven times more effective than conventional training courses. Take project management, for example, where a robust organizational capability can pare as much as 20 percent of costs in about half the defense budget. One defense organization used “learning by doing” programs to train several waves of project managers and leaders. Managers who successfully completed the training designed to build their project-management capabilities were able to cut costs on most projects by between 20 and 35 percent.

These five guidelines are the distilled wisdom of hundreds of military and civilian leaders with whom we’ve been privileged to work. We do not say that this is the sum of all the knowledge on the topic. But we do believe that a transformation that follows these five guidelines stands a higher chance of success.

## How relevant and useful is this article for you?

## About the author(s)

David Chinn and John Dowdy are directors in McKinsey’s London office.

## Explore a career with us

## Related Articles

## Fiscal shock, combat awe

## Preserving combat power when defense budgets are falling

## How militaries learn and adapt: An interview with Major General H. R. McMaster","{""publication_date"": ""December 1, 2014"", ""authors"": [""about $65 billion between 2012"", ""2015""], ""word_count"": 1828, ""reading_time_minutes"": 9}",2025-03-14 11:53:01.049170
11,How insurance can help combat climate change,https://www.mckinsey.com/industries/financial-services/our-insights/how-insurance-can-help-combat-climate-change,,"## How insurance can help combat climate change

In this episode of the Reimagine Insurance podcast, McKinsey senior partner Kurt Strovink leads a discussion with senior partners Kia Javanmardian and Dickon Pinner and partner Antonio Grimaldi about the impact of climate change on the insurance industry. An edited transcript of their conversation follows.

## How insurance can help combat climate change

Kurt Strovink: Welcome, everybody, to Reimagine Insurance. This is a podcast that focuses on the trends, disruptions, and strategies that are reshaping the insurance industry today. Each of these episodes features different experts on leading topics that we think are important to the way we reimagine insurance.

I’m your host today, Kurt Strovink, and I’ll be leading a conversation with a number of our colleagues to touch on climate change, which we think is an important area for the future of insurance and where insurance can play a leading role in shaping the future of this response for multiple industries.

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

I’m pleased to welcome three of McKinsey’s experts to shed light on this topic as part of our conversation. Antonio Grimaldi is a partner out of our London office. Kia Javanmardian, a partner and leader of our North American P&C practice, is from the Chicago office. And Dickon Pinner is a senior partner and global leader of McKinsey’s Sustainability practice.

I propose we have this conversation, if we could, in two broad parts. The first would be around the nature of the risks that we’re seeing in the climate space. The second part would be to really talk about what the insurance industry can, as a category, do.

Maybe we can begin with you, Dickon. You talk to senior executives around the world frequently across different industries. I wonder if you could just give us a sense of the systemic risks overall that you see climate change posing at this point in the business, more generally.

Dickon Pinner: We’ve spent a lot of time now looking at both the physical risk and transition risk posed by climate change. The physical one in particular is, I think, underappreciated in how near term it is, how nonlinear some of the impacts are. Also, as we know, the impacts will be systemic and potentially highly regressive.

As we talk to executives, I think I’ve seen a big switch between the real economy and the capital markets. I would say five years ago, the energy sector and automotive sector were ahead in terms of thinking about this. That has changed markedly in the past 12 to 24 months. If you pull back the cover on capital markets and you look across banking, asset management, and insurance, the lead dog has been the banking sector. I think that has been driven initially by regulation coming out of Europe, particularly the Bank of England, that has made the case that climate change represents an existential threat to the financial system.

We’re also seeing on the private equity side more around opportunity: people are very interested in how to invest and put new money to work into the kind of new green economy. We’re beginning to see that reflected in valuations.

And then insurance within that plays a critical role in terms of transferring and mitigating risk. Within the capital markets, it’s probably a little bit more behind, say, the banking sector, and I’m sure we’ll get into that with a little more detail.

Kurt Strovink: Thank you, Dickon, for that. Kia, you can comment a little bit to the point on insurance and where the industry is today. What are some of the trends? How are insurance executives, in your mind, thinking about this differently now from what they might have a couple years ago?

Kia Javanmardian: The shift has not been at the same pace, depending on what segment you’re in. The brokers and reinsurers are a bit ahead of the broader pack for understandable reasons, primarily as Dickon alluded to. A lot of the historical models won’t be predictive of the future. When you think about the role reinsurance brokerage and reinsurers play, it’s very critical to their business model to have a grasp on that.

When you look at the primary line carriers, it’s been a bit of a tale of two cities. In the US, for those with a heavy presence in California, climate change has come, and they’re seeing it with wildfires year over year, and they’re feeling it acutely because the indications of the rate they need is far greater than what they’re able to take in the state, as an example. You’re seeing a subsegment really feel that and thinking through: how do I diversify, and how do I think about prevention and mitigation?

The broader industry on the primary line, I think, acknowledges it. There’s a bit of difference in opinion on “Can I just price this in over time?” versus “Do I need to make a more proactive stance?” And I think the jury is a bit out in terms of where the industry is leaning on that dimension.

Kurt Strovink: Let’s talk a little bit more in a detailed way just about the kind of reactions that we’re seeing across the insurance industry. Antonio, obviously this has happened in a number of different ways, but I’m wondering if you could comment on some of the functional areas where you see some innovation beginning to happen—for example, underwriting.

Traditional models and, more broadly, past loss experience will not be predictive of the future, and that needs to be corrected.

Antonio Grimaldi: Insurers have started moving in the right directions, but I think much more can and should be done. For example, we see insurers working with customers on adapting to climate change. That means increasing resilience of their infrastructures, facilities, or supply chains. Much more should be done because climate change simply means that many of the technical insurance capabilities will need to evolve. Underwriting is a fascinating example.

In the space of underwriting, clearly new hazards will emerge, requiring new products and new underwriting solutions. Traditional models and, more broadly, past loss experience will not be predictive of the future, and that needs to be corrected. Obligations will change, requiring new techniques for portfolio management. And there will be more nonlinear effects at play. For example, what is the correlation between more frequent floods and the economic activity in a given region, making the work of underwriters even more complex? In a way, underwriting will need to become even more strategic.

Kurt Strovink: Kia, what about investment strategies? What kind of evolution are we seeing there, or changes in the insurance response?

Kia Javanmardian: One is literally their investment portfolio on the asset side of the balance sheet. We’re starting to see a bit of thinking in terms of what they’re willing to put money behind, partly reputationally, partly as an ESG measure. So seeing some movement there. I think it is more pronounced in Europe than in the US, given the regulatory environment.

On the broader investment question, we’re seeing three major themes. One, as Antonio mentioned, is getting greater sophistication on underwriting.

Tranche two is a refresh in terms of: what markets do we want to double down and plan? So if you look at our portfolio, where do we feel more vulnerable? If you were to play some scenarios out in the future, does that have an implication of how we want to rebalance that portfolio accordingly?

And then the third is, how do insurers play beyond risk transfer? There are a couple very prominent examples of carriers that are in the risk transfer business—but equally, if not more so, in the risk mitigation business, preventing things from happening. We’re seeing a lot more dialogue on that, and we think it’s a question of broadening the relevance of the industry beyond just pricing and transferring risk, but actually changing outcomes—whether it’s at the front end or, when bad things do happen, what’s the way to get recovery quickly and as seamlessly as possible?

The other one that does give us hope is the private-public partnership angle. What is that intersection between how carriers work with municipalities, regulators, and policy makers to create a sustainable model?

Kurt Strovink: Maybe on that point Kia just mentioned, any perspectives you’d offer, not just from an insurance perspective but, more broadly, the climate intent of regulators in this space in the next several years?

Dickon Pinner: I think that there is an ever-increasing drive toward transparency and disclosure. Because things are changing—it sounds so trite at first—but because the climate is changing, your previous estimation of your risk exposure is probably wrong. Right now, what we’re seeing—and I think some of this comes up from the regulation of the Bank of England initially, but through the TCFD, which asks for disclosure of transition risk, which actually is quite easy to calculate—we’re beginning to see the transition risk as a result of that is quite well priced in. Physical risk, by contrast, is actually very hard to price in because the translation from hazard to exposure to damage and the manifestation of that in cash flows is just hard to model. It actually requires quite a bit of judgment in terms of the second, third, and fourth orders.

There will be a kind of ongoing push for transparency from the regulator. We may also see, in the case of transition risk—and I get back to the point that Kia mentioned—we are in a world where risk is just increasing day over day because more carbon is going into the system, so just transferring that risk is insufficient. In fact, at a macro scale, this is about massive capital allocation and reallocation. Thinking through the price signals that the insurers can send to divert capital that currently is going into risky assets that further promote risky behavior, to burn down that risk, versus just transfer it, is actually critical because the rising tide of risk means the transferring it doesn’t solve the problem.

There are some unfortunate examples where you can see why the regulators made the move they have. If you’re on the West Coast, I think there’s some regulation that says the insurers could not drop insurance for coverage for a year and could not price on a forward-looking basis but just on a historical basis. I think what that would mean is, after that period is over, a lot of insurers will exit the state. That doesn’t seem like an effective response, but these are inherently connected to political systems, as well. I think we do need some more price signals, either from the insurers themselves or the regulator to help redirect that capital to a way that promotes the right behavior.

Kurt Strovink: I want to talk a bit more about the risks being quite different in different countries. We know that the tyranny of averages lies, but particularly here, there’s a lot of difference across different regions of the world and yet some common themes. Antonio, I’m wondering if you could comment from a European perspective: how do you see the nature of the risks evolving, and maybe by different regions even within Europe?

## Would you like to learn more about our Financial Services Practice?

Antonio Grimaldi: Europe seems to be most affected by heat and drought. The five hottest years ever recorded in history were the past five years. In 2018 and 2019, Europe experienced two consecutive summers of severe drought. This was unprecedented in the past 250 years. What I think is more concerning, though, is that in common insurance terms, we would have called these events one-in-250-years events, but the changing nature of climate risk means that the likelihood of these events actually repeating in central Europe over the next 50 years will increase sevenfold. And this really makes us all think about how important addressing climate change is.

Clearly, different parts of Europe are exposed differently. We’re talking about flood in the UK, winds in Italy. We observe that insurers have increasingly become more aware of the problem that lies ahead, Europe particularly. We have some of the most sophisticated global specialty insurers and reinsurers. This insurance needs to lead the way in terms of how we tackle climate risk. Many of the largest European insurance groups actually are making fighting climate change a core part of their ESG strategies.

And finally, regulators, particularly in the UK, are building greater awareness and facilitating the announcement of these capabilities. Earlier this year, for example, the Bank of England was very clear that there was a gap in capabilities, and it requested firms and issuers to act. This means really taking a more strategic approach to climate risk. This means conducting assessments on the physical side and the transition side, but also considering different scenarios and running stress testing under both to understand the impact.

Taking a different spin to what Dickon said earlier, I would say that insurers, to some extent, are particularly familiar with natural events and physical risk, but actually, transition risk may be a blind spot for them. Therefore, building capabilities in understanding the implications of transition risk, both on the asset sides and the liabilities sides, would be also as important.

Dickon Pinner: I would maybe just add on this topic of transition risk because, clearly, physical risk is a huge issue in closing the protection gap. But on the transition risk, if I step back and think through the macro problem, it’s actually about: how do you transition the installed base of the economy—which is today, by definition, high carbon—in an orderly fashion from brown to greener to green?

As I mentioned earlier, the good news is that transition risk is beginning to get priced in. The bad news, to some extent, is that transition risk is getting priced in, and the pendulum might swing so much, such that it may be difficult from an embarrassment reason or a reputation reason to get insurance for these fossil-based assets as they transition from brown to green. That would be a challenge because you don’t want those assets that are currently in the public eye to go private, for example, and into a kind of opaque environment. I think there needs to be mechanisms to allow insurers to continue to insure the real economy of good actors who are trying to transition and not just abandon some of the assets that are going through that transition, or that would lead to socioeconomic dislocation and the more disorderly approach and rapid repricing.

Kurt Strovink: I want to add a dimension to this, maybe just following on last point there, Dickon. Are there examples in other industries that you think would be either provocative or suggestive for executives who are thinking about transition in the way that you’re describing it? Where is the debate and dialogue?

Dickon Pinner: One of the things we’re seeing in other industries is we’re seeing the industry self-convene. We see it in particularly the ones that have perhaps known the transition was going to be a bigger problem for them—so the oil and gas sector, the power sector, many of the different industries. And they self-convene to try and understand where they can collaborate, where they need to define standards, and what role the regulators should play. I think we’re even beginning to see that now in the banking sector. On the topic of climate, they’re trying to understand which areas of data, for example, should be commonly shared across banks versus becoming a source of competitive advantage.

We’re also seeing in, say, asset management, you see lots of groups associated with becoming net-zero investors. You’ve got trillions of dollars of assets under management saying—if this is the direction of travel, what does it look like to get from A to B? We’re beginning to see the same thing in banking. Again, given the critical role that insurance plays in providing those signals to direct and redirect capital, that might be another interesting thing to consider, if it doesn’t already exist.

Kurt Strovink: Let me raise another angle to this problem. Obviously, this is one that has many different facets. What about the concept of the demand from different stakeholders—whether they’re employees, customers, or other partners—around making climate change progress in various ways? I’m thinking here about the E in ESG and the degree to which the next generation of employees wants to work for a firm that is doing something in this space that’s innovative, etc. How much do we think this will be an increasing requirement for firms that get out in front of this for their own employees, and stakeholders generally, and partners with whom they collaborate?

Dickon Pinner: Just across industries, we see, in general, a kind of multistakeholder approach taking grip now—so across the shareholders, the regulator, the customer, the employer. On the employee side, we’re definitely seeing this across industries as becoming a part of the war for talent, but I’ll let others comment specifically on this sector.

Antonio Grimaldi: In Europe, it is an increasing topic. Several insurers are increasingly thinking about ESG, and how can they become responsible underwriters? How can they become responsible investors? And what is the obligation that the industry has with regard to employees and shareholders, but actually to the world itself? So I think this is, in my mind, one of the very interesting angles that the industry could utilize in order to overcome some of the short term-ism that the industry might have, given the annual policy cycle.

Kia Javanmardian: And Antonio, on that I think one of the angles we’ve been talking to executives about is: how can you use the notion of climate change and the role of the industry in effecting that as a source of inspiration and meaning for employees today, but also in new sources of talent? What that could mean to the new generation of talent and how you can reframe it: We’re not an insurance company. We’re here to protect livelihoods. We’re here to protect the economy. We’re here to protect the Earth. And we’re not just risk transferring; we’re convening and doing something that is going to move the needle because we control capital. There is likely an angle there that has not fully been realized that does, as a practice, give inspiration and energy.

Kurt Strovink: Who are the actors in the companies that we think we’re talking to in this conversation? Who are the executives? What roles do they play? How broadly across the senior team is this area of concern? Who are the folks that should be having these discussions and dialogues over the next 12 to 24 months in a greater and greater way?

Kia Javanmardian: We think if the CEO is not involved in the conversation, it’s probably not this conversation. The reason we say that is this is a fundamental role of carriers: how they add value to clients, where they play, how they allocate capital. So you look at that at a headline view, and it is very much a corporate strategy and kind of direction of travel for a company.

The ESG angle, while very important, is just a part of this. When you really peel it back, this conversation should be an existential one of: where are we going to thrive, how are we going to add value, and what do we have to do to shift where we deliver for our clients?

Dickon Pinner: I get back to Kia’s point. To address this problem, it’s about capital allocation and reallocation. And so by definition, this is a CEO-level topic. Specifically, where we’re seeing it manifest itself in different industries: in the banking sector, in Europe, it’s through the CRO—the chief risk officer—but it’s increasingly becoming a commercial opportunity to deploy new sustainable infrastructure, so there’s a big commercial lens to this. In the energy sectors, this goes straight through the businesses.

Sector by sector, we typically see one or two companies with a sort of outsized voice and the CEOs who really get it leaning forward and trying to define the future path for the industry because they know: one, the industry or the sector is at threat if they do nothing; and two, they realize there’s a competitive advantage if they get ahead of it. So I think this is a top-team issue, and if it’s not being dealt with at that level, it’s hard to get the right level of action and activity around such an important thing.

Antonio Grimaldi: I fully agree—this is a top-team discussion. But I also want to call out explicitly the fact that the implications are profound throughout all the levels of an insurer. It is very hard to identify a function within insurance that is not affected by climate risk. We talked extensively about underwriting and pricing. Claims needs to evolve from paying financially, compensating financially, to actually rebuilding and further building resilience and risk mitigation to capital management, reserving actuarial propositions for employees.  It is a profound change for the whole industry.

Kurt Strovink: What do we think about collaboration opportunities more broadly, as insurance executives work maybe even with public sector in these areas that are going to be increasingly important? What’s the outlook on that? If I’m an insurance executive that’s looking at this in an innovative way, what kinds of collaboration should I expect to see or shape, even with the public sectors as part of this? Kia, do you have a perspective on that?

Kia Javanmardian: The opportunities are for the taking. Given the nature of this systemic risk we’re talking about, it is not carrier specific. We absolutely think there is a conversation to be had or executives at insurance companies working in partnership with one another and public sector to think through: what is the future policy that will help shape how risk is built up? Just a simple example of building codes, where and how to build for resiliency so we don’t keep falling into the same trap, is a massive opportunity for the industry and one that will require cooperation.

The second part of it is one of relevance. If you look at the total risks in the world and the percentage that insurance covers, it has been on a steep decline. You think about cyber; you think about a lot of these long-tail, hard-to-underwrite risks. And so it’s not just one of upside; it’s one of also ensuring the value and relevance of the industry, which will require some cooperation.

Antonio Grimaldi: In terms of public-private partnerships, this can be quite deep. Clearly, there are some risk-transfer solutions. For example, in the UK, there’s Flood Re, and the government in the US has been working for many years on Florida flood protection. But this can be done more systematically across all climate-exposed countries, especially in the emerging markets. I think this is an opportunity that some insurers are looking at first and foremost.

Secondly, there is a risk mitigation opportunity. So we could envisage insurers driving resilience in the climate-vulnerable countries, working with governments and local authorities where assets should be developed, and where assets should not be developed. How dwellings should be designed and with what standards. There are a number of different solutions where the industry could collaborate actively with governments to remove risk from the equation, as opposed to transferring it.

Kurt Strovink: Dickon, maybe you could share kind of the last word on this as we think about public partnerships of various kinds.

Dickon Pinner: I think the general framing is that the risk in the system is just going up over time and will continue to go up. If you don’t have a successful or a good collaboration between private sector insurance and the public sector, there are two sets of folks who hold the risk: it’s the consumer and the government. I think understanding what actions can happen by virtue of public-private partnership to not be those two stakeholders that end up holding the risk would be very beneficial.

You’ve got the physical risk gap. We’ve also got the transition piece. And then the third one, which was alluded to earlier, is the disaster response. Is there a way to pre-fund some of those, such that the poorest areas of the world, where lots of this physical risk often manifests itself, don’t then have to go around, cap in hand, post an event. Even days’ or weeks’ notice of an upcoming event, you can make a material difference if you can prepare for it, but that does require a public-private partnership. So a big role to play on such a complicated topic.

Kurt Strovink: Well, I think we’ll leave it there. Dickon, Kia, Antonio, thank you very much for joining us as part of this Reimagine Insurance series. I know you’re available for any follow-up questions that our listeners may have on these topics. This is an area that has multiple aspects to it but is a very important one for innovation for the category, maybe one we have a rightful role as an insurance category in. If we think about the signals for capital reallocation that’s coming, some of the points of view of the relevance of the industry, as Kia mentioned. And if we think about that, this is a preeminent concern for many, many people inside of insurance companies today at all levels of function roles, as Antonio pointed out.

Thank you for joining us today. We will look forward to following up with you in future sessions on Reimagine Insurance. Please do tune in. Thank you.

## How relevant and useful is this article for you?

## About the author(s)

Antonio Grimaldi is a partner in McKinsey’s London office, Kia Javanmardian is a senior partner in the Chicago office, Dickon Pinner is a senior partner in the San Francisco office, and Kurt Strovink is a senior partner in the New York office.

## Explore a career with us

## Related Articles

## Climate change and P&C insurance: The threat and opportunity

## Future of insurance: Unleashing growth through new business building

## The future of life insurance: Reimagining the industry for the decade ahead","{""publication_date"": ""January 6, 2021"", ""word_count"": 4458, ""reading_time_minutes"": 22}",2025-03-14 11:53:07.685561
12,Water resilience: Closing the funding gap for utilities,https://www.mckinsey.com/industries/energy-and-materials/our-insights/water-resilience-closing-the-funding-gap-for-utilities,,"## Water resilience: Closing the funding gap for utilities

Recent years have seen the publication of a number of reports about how water and wastewater utilities in the United States can become more resilient, particularly when it comes to addressing rapidly aging infrastructure, optimizing operational efficiencies, and contending with increasing water demand.

There has been significantly less discussion about how state and local leaders (including mayors and county offices) can help water utilities invest in resilience. We believe that this is the missing link in preparing the water sector for the years to come—and that state and local leaders can take critical actions today to strengthen water resilience.

Across the United States, private and public water and wastewater utilities are underfunded. As critical water infrastructure ages, maintenance expenditures go up. Rising user costs (including for citizens) have been unable to close the funding gap. Although the Bipartisan Infrastructure Law (BIL) and other legislation provide funding to address this issue, our research shows the US water utility sector faced an estimated $110 billion funding gap in 2024 (nearly 60 percent of utilities’ overall spending), primarily driven by significant investments in aging infrastructure, operating expenses, and water-quality regulations (exhibit). By 2030, this gap could increase to approximately $194 billion.1For more, see “Funding gap calculations” in the methodology section of the full report.

The growing gap in funding is created in part by the need for utilities to manage increasingly complex climate hazards, particularly regarding water stress and flooding. Water stress is driven by both supply and demand and refers to a combination of agricultural and industrial water use, policy changes, and climate change, while flooding includes pluvial (rainfall), fluvial (rivers), and coastal flooding. Both types of hazards could increase in the United States and globally, and although water utilities did not create these challenges, they must not fail to provide solutions as well as drinking water and wastewater services. If they do, the consequences for communities could be catastrophic.

Our analysis suggests that state and local leaders can provide the operational, technical, and financial assistance that the highly fragmented utilities landscape needs to solve these challenges. This report identifies ten key actions state and local leaders can explore to help utilities close 25 to 45 percent of the nearly $110 billion annual funding gap. These actions all use existing funding sources and fall into the following three categories:

• optimizing existing funding sources (approximately 5 to 10 percent of the funding gap), including innovating on existing rate structures, finding revenue opportunities, and maximizing existing state revolving funds and other programs

• prioritizing resilience outcomes (approximately 5 to 10 percent of the funding gap) by developing long-term resilience planning

• enabling operational efficiencies (approximately 15 to 25 percent of the funding gap) by supporting technology adoption, regionalization of the sector, and consolidated capital expenditures

While fully closing the gap will require rethinking how water systems are funded across the country, state and local leaders can play key roles in making existing funding go much further, thus boosting resilience for water and wastewater utilities. In the long term, working to close the funding gap could have positive economic as well as environmental effects.2Hazard mitigation funding covers the following hazard types: riverine floods, hurricane surges, hurricane winds, and wildland–urban interface fires. And for state and local leaders, working to solve challenges in the water and wastewater sector in their communities can put them at the cutting edge of innovation.

## How relevant and useful is this article for you?

## About the author(s)

Adam Barth is a senior partner in McKinsey’s Houston office, Humayun Tai is a senior partner in the New York office, and Sarah Brody is a partner in the Carolinas office.

The authors wish to thank Rob Dunn and Wendi Wilkes for their contributions to this article.

## Explore a career with us

## Related Articles

## How to protect our water—now, and for generations

## COP28: Food and water

## Water: A human and business priority","{""publication_date"": ""March 11, 2025"", ""word_count"": 665, ""reading_time_minutes"": 3}",2025-03-14 12:37:56.959677
13,"Anant Bhalla on the convergence of insurance, asset management",https://www.mckinsey.com/industries/financial-services/our-insights/anant-bhalla-on-the-convergence-of-insurance-asset-management,"Brookfield Reinsurance, which is part of Canadian investment firm Brookfield Asset Management","## Anant Bhalla on the convergence of insurance, asset management

Anant Bhalla became chief executive of American Equity Investment Life (AEL) in March 2020, a turbulent time as COVID-19 was spreading around the world. When he joined AEL, which was founded in the mid-1990s and based in West Des Moines, Iowa, the company was the last big independent seller of fixed-indexed annuities in the United States. Its specialty is using its insurance and investment underwriting capabilities to promise customers the “dignity of a paycheck for life,” as Bhalla puts it.

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

During his CEO tenure, Bhalla fundamentally transformed the company’s business model, dubbing it “AEL 2.0.” That transformation ultimately culminated in AEL’s acquisition by Brookfield Reinsurance, which is part of Canadian investment firm Brookfield Asset Management. Brookfield manages more than $850 billion in assets.

The transaction, which closed this week, valued AEL at about $4.5 billion, representing a more than threefold increase from the time Bhalla took over as CEO. Along the way, Bhalla also fended off two unsolicited takeover attempts.

McKinsey senior partners Ramnath Balasubramanian and Fritz Nauck and McKinsey Global Publishing editorial director Mark Staples sat down for a conversation with Bhalla about his career path, AEL 2.0, his predictions for the insurance industry’s future, and more. An edited version of their conversation follows.

McKinsey: Anant, tell us about your background, your journey across the insurance industry, and how you came to be CEO of AEL.

Anant Bhalla: I started my career at American Express, where I worked for about eight years. I began in investments and then moved to the insurance division, which was spun off into what is now Ameriprise Financial. After I left Ameriprise, I had roles in finance and risk at Lincoln Financial and AIG. Then, I spent about six years between being CFO of the US businesses at MetLife and CFO of Brighthouse Financial, which was spun out of MetLife in 2017. I started my career on the left side of the balance sheet, which is investing, and then had to learn the right side of the balance sheet, which is deposits or, in the case of an insurance company, policyholder promises and capital. Over the course of my career, I have been involved in various M&A transactions as well.

McKinsey: Would you say that you’ve had more transactions experience than other executives?

Anant Bhalla: I’ve had my fair share of it, for two reasons. One is that businesses are in need of transformation, and therefore transactions are a galvanizing moment for being the agent of change in them. And two, I enjoy transactions: they allow you to be creative, to think like an industry outsider, and to uncover value.

McKinsey: You’ve been in the industry for over two decades, during which the industry has undergone many changes. What are the major trends you’ve seen affecting the sector?

Anant Bhalla: The insurance industry has experienced three major trends. The first trend is the significant unbundling of the insurance value chain in terms of distribution, insurance underwriting, and investment management.

The second trend is debanking, as banks have significantly pulled back from lending. That created an opportunity for the insurance industry, which had not globalized as much as banks. Even though there are a few global players, the regulation is all very local, so the capital to back insurers’ promises is ring-fenced in local jurisdictions. And that’s an advantage, because you can be a nimble player. Most insurers are not systemically important. That means you can take prudent, long-term risks by being both a lender and an owner of real assets, as opposed to banks, which at best are only short-term lenders, given their deposit funding. In a way, the industry’s gone back to how it was after World War II, when large insurers lent money to, and owned, projects such as infrastructure that helped transform the economy.

The third trend is that because of deglobalization and the need for more local investing in markets, it becomes easier for a business that’s sourcing its capital locally to also invest locally.

While banks got into the “risk transportation” business—taking the risks inherent in financial instruments and using securitization to pass them on to third parties in the capital markets—insurance companies have been in the “risk warehousing” business, retaining these risks on their balance sheets. How you prudently manage those risks became a constant part of my career and continues to remain a big imperative for the industry at large.

McKinsey: Tell us more about AEL’s business and the role its products play in the insurance industry and society.

Anant Bhalla: AEL has a very focused strategy: provide a promise, a savings product for people, and the dignity of a paycheck for life. Because there are no more defined-benefit plans that are growing; everyone’s in defined-contribution land. There’s no principal protection in a 401(k) plan—you can still lose your money. And there’s no guarantee that you’re not going to outlive your money as there is with having a paycheck for life: a simple promise.

Our core product is almost like a personal pension. Working through an intermediary like an adviser, we give a retail client a personal pension. Clients give us $100,000, and if they wait ten years, they can take out 10 or 12 percent for life, guaranteed.

McKinsey: You have called your company’s transformation “AEL 2.0.” Can you tell us more about it?

Anant Bhalla: AEL 2.0 is exemplified by a virtuous “flywheel” with the following parts:

• differentiated investment management, with AEL taking a thematic view on where to allocate assets

• third-party capital through reinsurance vehicles, to increase the capital available to deliver on our promises to policyholders

We look at various private investments, without constraints, to find the best ideas that deliver a superior risk-adjusted return on assets. We structure these investments to fit the insurance balance sheet to deliver superior return on equity, accelerating growth.

We are an at-scale originator of long-term funding in the form of annuities policies through a range of distribution channels. We then invest this funding from our policyholders into differentiated investments and assets that align with the risks and duration of the policies. Then, we bring in new forms of capital to support these promises and generate additional revenue streams to effectively manage the capital on behalf of investors. The financial objectives of our AEL 2.0 strategy are to decouple our business model as much as possible from interest rates, generate a steadier stream of fee-based income, and increase the overall returns on equity we deploy.

McKinsey: Let’s start with the origination part of the flywheel. During your tenure, AEL has experienced significant growth in originating new annuities. Tell us more about what you have done there.

Anant Bhalla: When I took over running the company in early 2020, we were originating $2.3 billion in new fixed-income annuities a year. In 2023, we have done over $7 billion in new annuity origination—that’s $7 billion in new promises. Historically, we were largely a single-channel company; we worked with independent agents. We’ve gone deeper into banks and, more importantly, independent broker–dealers. What I’m most proud of is not just the $7 billion number but the fact that $5 billion of that total is income annuities—these personal pensions.

We got independent broker–dealers to buy into the fact that, as part of financial planning, you have to provide people with a decumulation option or a means of converting their nest eggs into retirement income. Not just an accumulation option but a decumulation option that’s guaranteed. In 2019, the year before I took over, AEL had slipped to number ten among US annuity companies by annual sales. In 2023, we were a top three carrier. But when it comes to income annuities, we are number one as of the fourth quarter of 2023, up from number 13 in the first quarter of 2020. The reason we value that a lot is that the business model we’ve constructed on the assets and liabilities side was “real promises, real assets.” We are weighted more toward the real assets, which, in our view, deliver more resilient profitability.

McKinsey: That’s a nice segue into the next part of your flywheel: investing in assets in a differentiated manner. What have you done there?

Anant Bhalla: We have the long-dated funding, or what we call the promises. How do we find the right assets whereby we can effectively match the duration of these promises while providing better returns to our policyholders to enable them to have the dignity of a paycheck for life? We saw a big opportunity to shift to differentiated private assets that fit the profile of our balance sheet. We have a very expansive definition of private assets—to provide a few examples, this includes investing across the capital structure, from loans to asset ownership in two areas: real assets and private credit. Real assets include infrastructure like pipelines, ports, rental real estate, hotels, data centers, and warehouses. Private credit means lending to midsize companies with tight covenant protections in Main Street businesses, secured and unsecured consumer lending, working-capital finance, or asset-backed finance, all areas where the debanking trend is our friend.

Today, we have nearly a quarter of our total portfolio, or about $15 billion, invested in a range of private assets, up from a fairly insignificant share of our asset allocation before I became CEO. We will continue to judiciously increase this allocation.

McKinsey: There are concerns about the trend of private assets on insurance balance sheets. They’re seen as riskier, and there are also reputational concerns. What’s your perspective, and what have you been doing differently?

Anant Bhalla: The criticism and concerns are very fair and justified in some respects. In the early 2000s, the insurance industry was an asset allocator and not an investment underwriter. In addition, chief investment officers at insurance companies largely limited themselves to publicly traded securities. The strategic mistake was to not see the huge value in funding from the policyholders, funding that could have allowed insurers to pivot toward private assets sooner.

Since the 1990s, there has been a significant increase in the supply of available securitized investments in the industry. Someone makes a loan and sells it to an intermediary that pools loans and structures them into various tranches. They convert a plain-vanilla BBB loan into multiple tranches of AAA, AA, A, BBB–, and then some Bs and an equity component as well. The senior-most tranches are perceived to be the safest, and they end up with investors, including insurers. There’s a global glut in savings. That translates into huge demand for more and more of the same paper, which is perceived to be high quality. The problem is that as insurers and others crowd into this paper, the price goes up, and there isn’t enough return to make the guarantees an insurer offers.

By the end of the last decade, the amount of cushion underneath you to absorb the loss of principal in BBB investment-grade public securities was about 10 percent. The view that we had, and the alternative managers who got into insurance had as well, was that if, as an insurer, you rely on the ratings of publicly available bonds and there’s too much demand for these and spreads are compressed, it’s not worth the risk. Owning any BBB piece of paper—whether it is CLO, CMBS, RMBS, or even pure corporate bonds—does not provide enough cushion underneath you. Conversely, there is much more of a cushion in private-credit assets. It was riskier for an insurer to own unsecured public bonds from large corporations than secured debt against real collateral from midsize companies and consumers. Traditional insurers missed an opportunity as they piled into the perceived safety of public bonds from the 1990s to the 2010s.

McKinsey: What you’re describing sounds like a different approach. You are focusing partly on hard-to-originate assets that require strong expertise and diligence in terms of how you underwrite. Can you tell us more about what you have done there?

Anant Bhalla: We decided to go back to the basics. That meant becoming a real underwriter for assets whose risks we understand well and can manage effectively, rather than relying on assets and ratings originated by someone else. That involved being willing to do the work at each asset level, expending the shoe leather to actively manage these assets.

First, underwrite so that you buy right, with strong legal protections. If you look at CLOs, many of the underlying leveraged loans have no documentation. If you look at public corporate bonds, they’re unsecured. Insurers need to get secure credit where you have covenants, where you track these companies monthly on KPIs so that before they go bad, you can jump in and talk to management.

Second, monitor the assets in real time so you can manage them before they go bad. And when they do go bad, work them out. Don’t be at the back of the line in court to get a recovery but be part of the recovery.

The other part is real assets. We’re making an annuity promise. What is better to back a paycheck for life, which is to be collected over 20-plus years, than an asset like a port? Or a pipeline? Or a hotel that’s a new development but has a great return? Or a portfolio of rental homes? AEL is a landlord on a portfolio of hundreds of homes spread across the Southeast of America. Because there’s a trend of migration to the Southeast, there’s a demand for rental housing.

We challenge the existing paradigm. We are focused on hard-to-originate assets, bringing real expertise, a real focus on burning the shoe leather, and real diligence in terms of how we underwrite these assets, as well as how we monitor them. It’s hard work; it’s not easy to pull this off. Our business is about “real promises, real assets,” and we are investing in real assets for sustainable returns, not a financially engineered tranche.

If you go back to insurance regulation, it envisioned insurer support for agriculture, real estate, infrastructure, and lending to businesses and consumers. We really didn’t reinvent the wheel. I keep telling people, AEL stayed in America and went “back to the future.” We worked with regulators and brought an integrative way of managing the two sides of the balance sheet together, the asset side and the liability side, compounding returns for our capital.

McKinsey: Tell us about the next part of the flywheel: third-party capital. What is AEL doing to raise capital, and how does it differ from the traditional insurance playbook?

Anant Bhalla: The traditional insurance model would be, you originate the liabilities, invest all those assets from your balance sheet, and hold all the capital against that on your balance sheet.

When I took over running AEL, we had $3 billion in capital and $50 billion in promises, so we were levered like 17 to one. The first thing we did was to delever the company by raising $1 billion in capital, so we went up to $4 billion. After that, we brought in additional capital to expand the balance sheet in a capital-light manner for our shareholders, through reinsurance structures.

For a public insurance company, it’s not that easy to raise capital from public-market investors who have opportunities to invest in, say, growth stocks, tech stocks, etcetera. The way to go about it is that as we grow our business, if we need an additional $3 billion to $4 billion of capital to reach nearly $100 billion in assets by the end of the decade, $1 billion can be contributed by the company and the remainder would come from third-party investors. The structure is that they’re not investing in a public company; they’re investing in a separate vehicle to which we transfer the balance sheet. While AEL is still responsible for managing that separate company and is providing all the services, it remains separate. It’s a public–private structure.

Essentially, we attracted third-party capital to co-invest in mini-clones of AEL, whereby the third parties could get a little share of this big company themselves through reinsurance. Reinsurance was just a risk transfer vessel by which we could attract folks to own mini-portions of AEL so that AEL would be more valuable as a public company. We earn fees for managing those private mini-clones of AEL, and this revenue stream is more capital efficient and helpful for increasing our returns on equity, thereby increasing the franchise value of AEL.

McKinsey: And now AEL has gone totally private with the acquisition by Brookfield.

Anant Bhalla: Yes, Brookfield’s transaction is great for shareholders because we unlocked a lot of the value of AEL 2.0 by matching up the two sides of the balance sheet and transforming a quarter of the liabilities into fee-generating liabilities. Our overall return on equity has increased. Brookfield is a great natural owner as it’s very good at real assets. Aligning a real promise originator of funding with a real-asset manager is a very strong point. Brookfield has adopted AEL 2.0 for itself. If you look at asset management and insurance coming together, two industries at a crossroads, they’re really two industries that have merged into each other. Why? Because the benefit of having long-term funding for an asset manager is to be able to invest for decades.

McKinsey: Let’s talk about the future of these two industries—asset management and insurance—which have been coming increasingly closer. How do you see the convergence developing?

Anant Bhalla: There are two clear models. In the first model, the asset manager is embedded within the insurer, and the goal is compounding capital at 12 to 15 percent a year for many decades, delivering multiples of invested capital. The second model involves a “captive” insurer affiliated with asset managers that focus on the fee-generation potential from the permanent insurance asset base.

Additionally, the debanking trend means that private alternative-asset management is here to stay, so you’ve got a parallel industry, which is private credit. And private credit is not just lending. There’s consumer and specialty finance in there; it’s become mainstream financing. But for private credit to be a sustainable business in the long term, it needs stable funding. Insurance and private credit fit together. Debanking has created a need: economies don’t recover without credit. If banks retrench from lending, someone is going to fill the void. Who better than another regulated industry like insurance? It’s better for the economy when insurance and private credit come together in a responsible manner.

McKinsey: What’s next for you?

Anant Bhalla: I will be launching a new venture that will be a principal investor using its own insurance balance sheet and an asset manager to improve its return on assets in the most compelling macro themes, and structuring assets to deliver superior return on equity.

## How relevant and useful is this article for you?

## About the author(s)

Anant Bhalla is the former CEO of American Equity Investment Life Holding Company. Ramnath Balasubramanian is a senior partner in McKinsey’s New York office, and Fritz Nauck is a senior partner in the Charlotte office.

Note: Anant Bhalla’s views are his own and not those of American Equity Investment Life Holding Company.

This interview was edited by Jana Zabkova, a senior editor in the New York office.

Comments and opinions expressed by interviewees are their own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement.

## Explore a career with us

## Related Articles

## Why private equity sees life and annuities as an enticing form of permanent capital

## Leading through uncertainty: An interview with Neeti Bhalla Johnson

## Modernizing the mindset: An interview with Biswa Misra","{""publication_date"": ""May 3, 2024"", ""authors"": [""Brookfield Reinsurance"", ""which is part of Canadian investment firm Brookfield Asset Management""], ""word_count"": 3361, ""reading_time_minutes"": 17}",2025-03-14 12:38:03.417869
14,Four considerations for better goal setting and performance,https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-organization-blog/four-considerations-for-better-goal-setting-and-performance,,"## Four considerations for better goal setting and performance

Drives lasting change at scale for global organizations through digital transformation, operating-model redesign, enterprise agility, and leadership development

January 13, 2025As the new year begins, many organizations and their employees turn their attention to performance management conversations and goal setting. This annual exercise should be considered more than simply perfunctory: According to a recent survey, 72 percent of employees cited goal setting as a strong motivator for performance.

Structure is important as well when it comes to performance management and incentives. Employees are most motivated when their company’s performance management system is consistent and simple, involving performance reviews with skilled managers, goal setting, ongoing feedback, and rewards.

As organizations and leaders prepare for 2025 and more years to come, this is an opportunity to revisit performance management systems to ensure they serve all stakeholders—the business, its leaders, and its workforce. Employers and employees should work together to refresh goal setting and make it an effective process that improves both organizational and individual performance.

Here are four changes to consider:

• Emphasize the link between business priorities and personal goals: Employees are more motivated when their goals include a mix of individual and team goals (44 percent) and are clearly linked to company goals (40 percent). As part of the goal-setting process, managers and their direct reports should discuss how the work aligns with organizational strategy, including business objectives, purpose, and the measurable targets for which they can be responsible.

• Provide year-round counseling: While goal setting may set employees up for success in the new year, managers should encourage employees to adjust goals throughout the year to align with changing business objectives for a high return on investment. Ongoing, regular check-ins can help drive performance, development, and connection, while ensuring that an employee’s goals remain relevant and top of mind.

• Find strategic ways to use technology, like generative AI: There are plentiful use cases for using emerging technologies, such as gen AI, to support performance management systems. These include helping to summarize and analyze peer feedback, building detailed career paths, and identifying the experiences and development opportunities necessary to help employees reach their professional goals. These technologies have the potential to speed up processes and reveal informative, data-backed insights that may have gone unnoticed otherwise. Now is an ideal time to explore their capabilities.

• Deploy nonfinancial rewards along with financial incentives: There are four reward categories that organizations can use to help motivate and incentivize employees—compensation, career progression, development opportunities, and recognition. Financial rewards get a great deal of emphasis. However, as work-life expectations continue to shift, nonfinancial rewards—like opportunities for upskilling or professional development—play an increasingly important role in performance management strategies.

Motivating employees through effective performance management systems can enhance employee experience and improve retention, but there’s a competitive advantage to revisiting these processes as well. Companies are more than four times more likely to outperform their peers when they focus on their people’s performance.

Take this opportunity to engage in dialogue with employees, not only to establish goals for the year ahead but also to learn how the performance management process can be adjusted to benefit all.

## Learn more about our People & Organizational Performance Practice","{""word_count"": 541, ""reading_time_minutes"": 3}",2025-03-14 12:38:08.671683
15,Integrated Impact Management,https://www.mckinsey.com/capabilities/operations/tech-tools/spendscape-technology/our-offerings/savings-tracking-and-integrated-impact-management,,"## Integrated Impact Management

Integrated Impact Management is project management software for procurement savings initiatives and savings tracking that allows you to identify, plan, manage, and track savings initiatives and anchor them in practice with a built-in link to spend data.

The real-time monitoring mechanism enables an always up-to-date overview of all planned, achieved, and forecasted savings. Its collaborative features facilitate better communication and collaboration among different teams within and outside of procurement, leading to more effective implementation and value capture.

It also significantly reduces the administrative burden of generating reports and controlling. The pipeline transparency achieved allows for greater focus on value and a more proactive, strategic, and savings-focused procurement function.

Our clients have been managing savings worth $1bn using our streamlined Integrated Impact Management solution. Further, they can significantly improve process governance and transparency in their savings pipeline for enhanced reporting and savings tracking.

## OUR CAPABILITIES

## Planning, forecasting, and monitoring initiatives

## Proactively demonstrate value contribution

## Holistic controlling capabilities

## Automate performance measurement

## React in a timely manner

## Integrated Impact Management built on Wave

Our proprietary, best-in-class program management platform embeds our procurement expertise and a variety of tactics including bulk purchasing, negotiated discounts, and streamlined processes, to help leaders drive sustained impact and cost savings across all categories and locations. It provides visibility into the procurement pipeline and directly leverages procurement data points from pricing, terms, and supplier performance, which can help buyers and category managers make more informed decisions and ensure they are getting best value for money.

Through integrations with diversity, risk, and carbon data providers, our program management platform can help our clients identify and prioritize sustained saving options, reduce their environmental footprint, or mitigate risk by identifying potential issues with suppliers and ensuring they are meeting their contractual obligations. As a collaborative savings platform, it facilitates better communication and collaboration among different teams within an organization, leading to more effective and efficient procurement processes.

## Connect with the Spendscape team","{""word_count"": 332, ""reading_time_minutes"": 2}",2025-03-14 12:38:14.513790
16,Chapter Zero and McKinsey & Company run a series of face-to-face events that convene non-executive directors. The objective is to bring the best thinking to boardrooms on achieving net zero-and effecting real change. | United Kingdom,https://www.mckinsey.com/uk/our-insights/the-mckinsey-uk-blog/global-climate-policy-and-cop29,,"## Global climate policy and COP29: Implications for business

January 20, 2025Daniel Mikkelsen, Senior Partner, and leader of McKinsey Sustainability’s financial work opened the session by sharing key takeaways from his attendance at last year’s COP, which took place from 11th to 22nd November in Baku, Azerbaijan.

He set the stage by outlining the global climate policy landscape: implementation efforts remain significantly off-track to meet the Paris Agreement's 1.5°C goal, with current trajectories pointing toward a 2.2°C to 3.5°C emissions outcome. Despite these challenges, there is reason for optimism: 66% of the world’s largest publicly listed companies have now committed to net zero targets, signalling the potential for greater synergy between policy and business decision-making.

Some of strategic priorities at COP29 were the setting of a new global climate finance goal – the New Collective Quantified Goal (NCQG); progress on countries' updated Nationally-Determined Contributions (NDCs); and increased clarity on carbon market rules in accordance with Article 6 of the Paris Agreement.

Mikkelsen offered practical insights for how boards can incorporate COP29 into their boardroom discussions:

• Rethink sustainability strategy – COP29 provided a pivotal moment for reflecting on sustainability strategies and recalibrating the scale and pace of climate transition plans. With NDCs being announced by governments—including the UK—boards have an opportunity to assess how evolving policy landscapes and technological advancements can influence target-setting, risk management, and long-term planning.

• Expedite competitive technologies – Research shows that only 10% of the low-emissions technologies required by 2050 to support the net zero transition have been deployed, with focus very much needed on how to effectively scale up and industrialise technologies. McKinsey's analysis highlights 12 core technologies that could deliver 90% of the required emissions abatement required and should be prioritised accordingly. Increasing technology readiness and maturity levels in key climate technologies is critical to enabling businesses to scale production assets and reduce the costs of transition-aligned infrastructure, which may help to create long-term strategic value.

• Unlock private capital to bridge the finance gap – While progress is being made, private capital remains a small proportion of the actual capital that is being mobilised, especially in developing countries. Multilateral financial institutions are doing more to provide capital and crowd in private sector finance, but many sustainability projects continue to need greater financial and regulatory support to become investable. Boards can be proactive in identifying where these needs exist and what forms of support may be most effective in filling existing financing gaps.

• Prepare for carbon as an investable asset – COP29’s agreement of a UN-backed carbon market framework is expected to unlock further investment potential in climate projects and support cross-border collaboration on emissions reduction strategies. With the proper integrity safeguards and transparency framework in place, these new rules could offer businesses confidence and clear guidelines for the international trade of carbon credits. In parallel, there have been policy signals (again, specifically in the UK) around increased investment in carbon technologies, with estimates by McKinsey & Company that the carbon dioxide removal industry could be worth up to $1.2 trillion globally by 2050.

• Harness digital technology to boost and de-risk transition delivery – The growing importance of digital technologies was reflected in the first-ever Digitalisation Day at COP29. Research shows that one half of the technologies and initiatives required to put the world on a 1.5°C emissions pathway can be enhanced through digitalisation, representing a major opportunity for boards to assess opportunities for enhancing the role of digital technologies in strategy delivery.

Enhanced business ambition on the road to COP30

We hosted a panel moderated by Susan Hooper, board member, Chapter Zero, and featuring panellists: Vanessa Havard-Williams, Chair of the Transition Finance Market Review, HM Treasury; Thomas Lingard, Global Head of Sustainability, Unilever; and Fiona Howarth, CEO, Octopus Electric Vehicles.

The panel discussion began with reflections on some areas of increased ambition at COP29, for example the announcement of the UK’s updated NDC, and how this may support a more consistent enabling environment for businesses’ climate strategies. Participants commented on the importance of clear policy direction from government for business planning and how greater recognition of the private sector’s role in delivering net zero could help to direct boardroom strategies. Consistent policy and market signals were seen by panellists as particularly beneficial in terms of target-setting, including reinforcing targets such as Scope 3 emissions reductions, which are outside the direct control of individual companies. Panellists discussed how tackling emissions across the value chain can often require cooperative action between private and public entities and supportive policy and regulatory frameworks, alongside alignment on an actionable timeframe.

Building on the discussions around enabling factors, one panellist reflected on the importance of sector-level pathways to net zero. Without a stable policy environment within and across sectors, they commented that the finance needed to deliver on cross-sectoral decarbonisation is unlikely to flow at scale. Panellists agreed that the operationalisation of finance needs to be a key area of focus going forward, and that it would be beneficial for innovative forms of blended finance and industry partnership to be explored at pace. There was panel-wide agreement that progress on these important levers could lower the risks associated with many long-term sustainability projects and crowd in the capital needed to deliver them.

Audience members were updated on several ongoing efforts from COP29 that are likely be carried forward into COP30 next year in Brazil, including developing discussions around the role of raw material supply chains in scaling up decarbonisation and the push for a new binding global treaty on traceability for critical minerals. Nature and biodiversity, and topics such as loss and damage financing, were also flagged as likely to be higher on the agenda at COP30 in November 2025.

Some of the key takeaways to emerge from the session for boards from COP29 could be summarised as:

• Strategic alignment – non-executive directors can use the emerging policy signals, particularly in the UK, to support long-term strategic planning in line with their stewardship role in relation to ensuring that organisations are properly balancing performance expectations with long-term sustainability objectives. Businesses that have set ambitious climate goals could now benefit from staying the course and maintaining strategic oversight of the mechanisms and technologies needed to transition. Aligning climate strategies to these broader policy and market signals, could enhance long-term business resilience, not only in terms of derisking portfolios and activities, but also in driving value and attracting investment.

• Stakeholder engagement – there is a huge opportunity for businesses to communicate across their stakeholder maps about their transition priorities. Business-government dialogue may also help ensure that policy and regulation reflect business reality and is geared towards impactful, measurable progress, while also being clearer about where policy interventions are not working. How businesses engage with the policy landscape will be entirely context-dependent, but for boards it will remain crucial to understand the direction of travel for policy and build this into scenario planning and strategic decision-making.

• Global cooperation – COP29 highlighted again that the climate crisis is a global problem that requires a global response. Businesses can foster opportunities for collaboration and innovative forms of industry partnership, both across sectors and geographies, to support climate resilience.

## Connect with our McKinsey United Kingdom office","{""word_count"": 1208, ""reading_time_minutes"": 6}",2025-03-14 12:38:19.812647
17,Strategy and management,https://www.mckinsey.com/capabilities/mckinsey-digital/cloud/cloud-insights/strategy-and-management,IT infrastructure changes,"## Strategy and management

## Featured Insights

## In search of cloud value: Can generative AI transform cloud ROI?

## Building an engineering culture and resilient technology

## Ending the confusion in cloud transformations: The dashboards and metrics everyone needs

## The state of cloud computing in Europe: Increasing adoption, low returns, huge potential

## The Middle East public cloud: A multibillion-dollar prize waiting to be captured

## Webinars & Events

## Cloud value in cash management

## More Insights

## Africa’s leap ahead into cloud: Opportunities and barriers

## Getting ahead in the cloud

There is $3 trillion worth of business value at stake for companies that successfully use cloud technology—yet...

## Projecting the global value of cloud: $3 trillion is up for grabs for companies that go beyond adoption

## Cloud-powered technologies for sustainability

## Five learnings from CTOs and tech leaders on their cloud strategies

## The cloud transformation engine

## It’s cloud time for boards—in seven charts

## The business value of innovation in the cloud

## The benefits of being a cloud trailblazer

## The case for cloud in life sciences

## What payers and providers can learn from successful cloud transformations in other industries

## Lessons from a high-ROI cloud transformation journey

## Four ways boards can shape the cloud agenda

## Five Fifty: Cloudy with a chance of billions

## Cloud’s trillion-dollar prize is up for grabs

## Making the cloud pay: How industrial companies can accelerate impact from the cloud

## Three actions CEOs can take to get value from cloud computing

I’ve heard too many overly simplistic business cases that account only for cost reductive driven by IT infrastructure changes. ... But if done correctly, the benefit of cloud technology go well beyond IT infrastructure costs and include a higher level of automation and faster time to market in combination with environments that can help the business scale flexibly.

## Three elements for capturing value

## Connect with Cloud by McKinsey","{""publication_date"": ""November 15, 2023"", ""authors"": [""IT infrastructure changes""], ""word_count"": 330, ""reading_time_minutes"": 2}",2025-03-14 12:38:28.085035
18,Matthews Mmopi,https://www.mckinsey.com/our-people/matthews-mmopi,,"## Matthews Mmopi

Supports the leaders of biopharmaceuticals, generics, and animal-health companies to unlock enterprise-wide value creation and change management, with a focus on innovation, growth strategies, and operating model transformations

## About Matthews

Matthews leads our enterprise-wide transformation work for the Pharmaceuticals & Medical Products Practice, globally. He is also a geographical leader in South Africa for the McKinsey Health Institute, a non-profit-generating entity within the firm that aspires to catalyze action to add 45 billion years of higher-quality life for all people around the world.

Since joining McKinsey, Matthews has advised companies in Africa, Europe, the Middle East, India, and the United States and has on-the-ground experience across more than 20 countries to date.

Drawing on his deep expertise in innovation, growth strategies and operating models, Matthews works with the leaders of human pharmaceuticals, generics, and animal-health companies to help unlock accelerated value creation and to support transformational change. He helps our clients achieve a simultaneous focus on top-line growth, profitability improvements, and organizational health.

Examples of Matthews’ recent client work include the following:

• supporting a multi-year, full-scale transformation program, including reorganization, functional capability building, establishing an innovation culture, and securing productivity gains of employees

• building a corporate portfolio strategy—including M&A, business development, in-licensing, and R&D—for a global pharma company to grow revenues and accelerate share gains in emerging markets

• leading a major growth and commercial transformation for a global generics company to drive EBITDA and cash improvement

• designing growth strategies and transformation programs for specialty care, primary care, and rare disease pharma companies in Africa and the Middle East, addressing operational, commercial, and organizational opportunities

Matthews also leads our Africa Pharmaceuticals & Medical Products Practice, where he spends his time working with global public health donors to help expand people’s access to medicines across the continent.
He is passionate about diversity and inclusion and serves as the leader of Equal at McKinsey—our LGBTQ network—for the Eastern Europe, Middle East, and Africa region.

Prior to joining McKinsey, Matthews worked as an economics researcher for the Aspen Institute in India.

## Expertise

• People & Organizational Performance

• McKinsey Transformation

• McKinsey Health Institute

• Strategy & Corporate Finance

• Vaccines & Infectious Disease

## Published work

“Against the odds: How life sciences companies excel in large transformations,” McKinsey & Company, September 2022

“Should sub-Saharan Africa make its own drugs?,” McKinsey & Company, January 2019

“Winning in Nigeria: Pharma’s next frontier,"" McKinsey & Company, May 2017

## Education

University of Oxford
MPhil, development economics

Harvard College
BA, economics","{""word_count"": 423, ""reading_time_minutes"": 2}",2025-03-14 12:38:34.616773
19,Climate change adaptation and security: Two sides of the same coin,https://www.mckinsey.com/industries/aerospace-and-defense/our-insights/climate-change-adaptation-and-security-two-sides-of-the-same-coin,,"## Climate change adaptation and security: Two sides of the same coin

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

With increasing populations and decreasing resources creating tensions around the world, climate change could have a detrimental impact on national security. In turn, greater insecurity could limit governments and organizations’ abilities to address climate change and the associated security risks. In this interview, Tom Middendorp speaks to Hugues Lavandier, a senior partner in McKinsey’s Aerospace & Defense Practice, about the role the defense industry can play, in collaboration with the public and private sectors, in mitigating the impact of a changing climate on security. Prior to his current role, Middendorp was the chief of defense of the Royal Netherlands Armed Forces and is the author of the book, The Climate General.

McKinsey: A little over a year ago, we interviewed you about the link between climate and national security. What has changed since then?

Tom Middendorp: I think we are increasingly facing a new reality, one that we can’t deny: climate change is something we must deal with. Last year, one record after another was broken when it came to high temperatures, droughts, floods, and severe weather events. In the United States alone last year, there were more than 28 separate climate disasters—the highest number on record—causing $92.9 billion in damages.1Adam B. Smith, 2023: A historic year of US billion-dollar weather and climate disasters, Climate.gov, January 8, 2024. And that’s just the direct impact of climate change, let alone the indirect.

However, the disruptive effects of climate change are increasingly being recognized and regarded as a matter of national security. For example, NATO regards climate change as a defining challenge and aims to be a global leader on climate and security. NATO in 2023 decided to establish a Centre of Excellence on Climate and Security in Montreal to deal with the issue.2“Environment, climate change and security,” North Atlantic Treaty Organization, January 12, 2024. In addition, various NATO member countries are designing mitigation and adaptation strategies for their security sectors; however, not all at the same pace.

McKinsey: You have previously made the point that “climate change is not a stand-alone issue.” Could you elaborate on that?

Tom Middendorp: This needs to be seen in the context of four main trends—separate from the technology revolution that continues in the background: population growth, scare resources, climate change, and the geopolitical landscape. The first of these is the increase of the world’s population, which currently stands at eight billion. At the start of this century, it was 6.1 billion and the United Nations expects an increase to about 11 billion by the end of this century.3“World population projected to reach 9.8 billion in 2050, and 11.2 billion in 2100,” United Nations Department of Economic and Social Affairs, 2017.

The growth of the world’s population will result in growth in the global demand for water, food, natural resources, and livable, arable land. This will result in a growing gap developing between demand and supply, leading to competition and tensions on a global scale. Climate change reduces the livable, arable land on our planet, meaning the current rate of production and consumption of resources is not sustainable in the longer term.

The changing geopolitical landscape is the last trend. We are moving away from a globalizing world toward a more fragmented one with competing coalitions and power blocs. This directly impacts the effectiveness of multilateral mechanisms and our ability to find global solutions, because these mechanisms require consensus.

The disruptive effects of climate change are increasingly being recognized and regarded as a matter of national security.

McKinsey: What could be the potential outcome if the nexus between climate change and security is not properly addressed?

Tom Middendorp: I think we will see impacts on a global, regional, and national level. On a global level, it will lead to more competition between power blocs, which could potentially lead to conflicts. Historically, most conflicts globally have been about access to scarce resources. Therefore, as resources become even scarcer due to the impact of climate change, we can expect more disruptions in global supply chains. This effect on supply chains needs to be integrated into our risk management.

On regional and national levels, climate change directly impacts water and food security, which could lead to internal tensions around access to arable lands and job opportunities. These tensions could easily escalate into internal and regional conflicts. Indirectly, supply chains are disrupted, which could lead to further security issues.

Developing countries in the Middle East, northern Africa, and South Asia, especially, are most affected by a changing climate and its disruptive effects. Countries in these regions are extremely vulnerable to floods and heat waves and are reliant on freshwater supplies from sources outside their own borders.

On a local level, climate change is causing an increase in the occurrence of extreme weather incidents, such as hurricanes, wildfires, flooding, and heat waves. This is already having severe consequences for communities and livelihoods. These incidents represent a “new normal” to which countries and vital infrastructure will need to adapt, bringing new challenges for local and regional crisis response mechanisms.

## Global Energy Perspective 2023

McKinsey: How can security and defense potentially provide an early warning to alleviate some of the challenges associated with climate change?

Tom Middendorp: I’m not a pessimist, despite having painted a very bleak picture. We need to face the situation, adapt to the changing climate reality, and innovate solutions. We have unprecedented foresight on the impact of this new reality, which gives us a responsibility to adapt and be prepared. The security sector needs to be part of the solution.

On the area of forecasting, it can help to assess the security effects of different climate scenarios by the tools at its disposal, such as big data, military expertise, and intelligence services. The sector can identify areas where climate change could lead to migration flows or instability, adding a security lens to help create a more comprehensive picture. Building this comprehensive understanding can help institutions be better prepared. These insights can be translated into early warning mechanisms to increase our reaction times and prevent governments from being taken by surprise.

On the adaptation side, there are internal and external dimensions to what the security sector—the military—can contribute. Internally, it is important to climate-proof organizations to enable them to operate under any climate circumstance and to protect their vital infrastructure (such as naval ports) against the disruptive effects of climate change. Externally, the security sector can help affected countries adapt. As explained earlier, many of these countries are vulnerable to the effects of climate change, so helping them to adapt and become more climate resilient could be regarded as a tool for conflict prevention. The security sector thereby has a vested interest in improving adaptation programs for fragile regions. These are programs that can—and should—be used also to reinforce stability in a country as a means for conflict prevention. There is no adaptation without security, as there is no security without adaptation. These are two sides of the same coin.

The third area of attention is mitigation. On a global scale, we need to find new ways to bridge the gap between growing demand and declining availability of resources. It is not sustainable to meet that growing demand by producing more in the way we are producing now, because that will only lead to a more rapid depletion of scarce resources and to more global competition. It is becoming crucial that we look for ways to become more autonomous and reduce our dependency on scarce resources. This requires us to innovate on circularity and on extending life cycles, reusing materials and components, and using alternative materials that are less scarce. The more self-sufficient countries can become, the less vulnerable they are.

It is important that the security sector recognizes the enormous potential of new green technologies. These technologies can enable the sector to operate more autonomously and become more self-sufficient. New technologies can help security organizations to become energy independent, to produce their own water (by extracting water from desert air with a small solar-powered device), and to print their own spare parts—with 3D printing—without needing to resupply. The defense sector has always been a front-runner on new innovations and can act as a platform for innovation for industries, private companies, and research centers.

There is no adaptation without security, as there is no security without adaptation.

McKinsey: You’ve emphasized that different sectors and various actors in the ecosystem need to come together. What could public-private sector collaboration look like to address some of these challenges?

Tom Middendorp: Collaboration between security experts and scientific research institutes is important. Scientists can use experts’ input to build further knowledge on the topic, and this can be used in the diplomatic arena to inform players as they shape new policies based on research. An example of such an interactive network is the International Military Council on Climate and Security—which I chair—where security leaders and research institutes join forces.4For further information, see the International Military Council on Climate and Security’s website, imccs.org.

From a future capabilities perspective, we need to innovate on self-sufficiency, which requires a new kind of cooperation between the public and private sectors, merging old and new technologies into new concepts. It is crucial that defense industries and defense organizations open their gates for innovators, start-ups, and research centers that together can come up with out-of-the-box solutions. This requires companies and organizations to accept risks and be willing to invest in innovation. Nine out of ten innovation attempts will not succeed, yet one successful innovation can help guarantee future security.

An interesting example of this is an initiative called FieldLab SmartBase in the Netherlands, a free space where military users, tech companies, and research centers can meet to look at what they can contribute to achieving one common goal: building a completely self-sustaining military compound.5Evert Brouwer, “Field lab with small and medium-sized businesses,” Defense Magazine, February 12, 2016. This pulls together many different players who all bring new pieces of the puzzle to the table and create an environment for innovation.

McKinsey: At COP28, the NATO Secretary General again stressed the Alliance’s goals to reduce emissions to become net zero by 2050. What can member states do to achieve these objectives?

Tom Middendorp: It starts with member states being made more aware of the need to change the defense sector in relation to a changing climate, for example, by common standards to be incorporated into their climate mitigation and adaptation programs. It’s also important to look for the right narrative. There is a perception that climate mitigation and adaptation will cost additional money that will affect operational readiness. It is crucial that these efforts be presented more as an opportunity than a cost. In many ways, if you innovate on circularity and self-sufficiency, you can create military units that are more autonomous and need less logistical supply.

McKinsey: What do you view as the most important message in the context of climate and security?

Tom Middendorp: Climate change is much more than just an environmental problem. I have just returned from Iraq where I saw how the Mosul Dam only contains 20 percent of its capacity, threatening the water supply to large parts of the population. Throughout the country, I met with farmers who have had to leave their lands because of increasing droughts and were struggling to sustain their families.

The geopolitical landscape is becoming more complex, and we are standing at the forefront of a challenge that requires innovation. Because the military can help predict where conflicts could occur due to a changing climate, we can provide unprecedented foresight into the impact that climate change could have.

## How relevant and useful is this article for you?

## About the author(s)

Tom Middendorp is the chair of the International Military Council on Climate and Security. Hugues Lavandier is a senior partner in McKinsey’s Paris office.

Comments and opinions expressed by the interviewee are his own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement.

## Explore a career with us

## Related Articles

## Global Energy Perspective 2023

## The link between climate and national security

## Decarbonizing defense: Imperative and opportunity","{""publication_date"": ""February 28, 2024"", ""word_count"": 2113, ""reading_time_minutes"": 11}",2025-03-14 12:38:41.489710
20,Leading through disruption requires ‘the gene for change’,https://www.mckinsey.com/capabilities/strategy-and-corporate-finance/our-insights/leading-through-disruption-requires-the-gene-for-change,,"## Leading through disruption requires ‘the gene for change’

Lila Snyder became the CEO of Bose in September 2020, when the COVID-19 pandemic was still very much affecting people’s lives. Undeterred by disruptions, she launched a corporate transformation to focus the consumer electronics manufacturer on creating distinctive audio products and experiences that would address customers’ needs. In a recent conversation with McKinsey chief client officer and senior partner Liz Hilton Segel, Snyder outlines the institutional capabilities that are helping the company adapt in a changing market, how she built a leadership team that is ready to embrace change, and the AI-driven technology that’s taking the company in new directions. The following is an edited transcript of their discussion.

McKinsey: Lila, tell us a bit about the journey you’ve been on to change where Bose is going.

Lila Snyder: It’s been an exciting couple of years. I joined right at that point in the pandemic when we all thought we were about at the finish line and were going back to the office soon. I did most of that first year by Zoom and Microsoft Teams, working remotely. But we spent a lot of time thinking about our long-range vision and refocusing the company on the things that matter most to our customers and what we think we’re best at.

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

McKinsey: What are some of the changes that you’ve implemented over the past three years?

Lila Snyder: What matters most for us is launching products that we’re proud of, so we’ve refocused our energies on areas where we think Bose is distinctive. We talk at Bose about our three technology franchises. The first is noise removal—the ability to have the kind of immersive quiet that’s so important, whether you’re trying to focus on something or listening to your favorite music.

Second, immersive, lifelike audio is super important to what we do. We’re always thinking about ways to innovate the experiences that we create for our customers while staying true to how the artist intended that music or that content to be delivered.

And the third area is something new that we call “hear what you want,” which is AI driven. It’s the marriage between noise cancellation and noise removal, allowing in the sounds that you want to hear—because we don’t always want blissful silence. Sometimes, we want to be able to hear the emergency vehicle on the street as we’re walking, or our kids shouting in the other room. Using AI, we’re starting to make progress in allowing customers to pick out the sounds they want to hear.

McKinsey: We often talk to clients about the idea of building superpowers—one or two capabilities that differentiate them from competitors or address changes in the marketplace. How are you thinking about building capabilities at Bose that can become such superpowers?

Lila Snyder: We actually use that word, “superpower,” and we talk about sound as our superpower. The reason why that’s so important is that we have amazing competitors, but we are one of the only companies that’s focused solely on sound. For us, sound is not an accessory or something we do on the side. It’s everything we do. This mindset allows us to understand the nuances of what customers want and how they feel about the devices that help them connect to sound. That’s where we find the differentiating space for Bose.

McKinsey: Bose has a long history as a hardware company, but you saw an opportunity to do more on the software side. What role does software play in enabling you to lead in sound?

Lila Snyder: We talk about experiences now, not just products. All of us as consumers think not just about what the hardware is doing or what the software is doing but about having a seamless experience. For us, the hardware piece comes naturally; we’ve been doing that for decades. The software piece is newer, and as we marry those two, it gives us the ability to create distinctive experiences. And that integration is tricky, right? The way you develop software is different from the way you develop hardware, and how you line up those processes is a key to success. There’s more work to do, but the software capabilities are unlocking a lot of exciting customer opportunities.

McKinsey: I know you have thought a lot about how to build effective teams. How have you approached it at Bose?

Lila Snyder: It’s one of my favorite parts of the job. If you have the right team, with a diversity of thought and the right passion and capabilities, everything else will fall into place. My team has a mix of diverse backgrounds, capabilities, skill sets, and experiences. A good portion have been at Bose for 20 years or more, and some have come from the outside.

We’re in the middle of a transformation at Bose, so our team leans toward people who thrive on change. Transformations are hard, and you need people who have a level of grit and resiliency beyond what you might need to run a business in a steady state. I looked for people with the gene for change and a desire for change to be a key element of what they do. And once everybody was in place, we spent a lot of time on team building. People underestimate how much time it takes outside of the day-to-day work to build the trust and candor necessary to get through difficult things. We’ve invested a lot of our time in building that trust. And it’s not something you do just once; it’s a continuous process as new members come in and others leave and as times change.

McKinsey: I love that expression, “the gene for change.” You talked about grit and resilience. Is there also a need for intellectual agility or the willingness to think about decisions from a new perspective as market conditions change?

Lila Snyder: In some ways, that’s the gene for change—you’re constantly looking at how the market is changing. We’re in a market with some fast-paced, successful competitors and we’re a fraction of their size, so the ability to look around and pivot quickly is so important. Between the pandemic, the supply chain crisis, the war in Ukraine, there are so many things coming at us. It requires every leader to be agile and to be able to pivot when the times and the market change.

McKinsey: As you mention, we’ve all had to deal with lots of disruptions recently. What do you think are the most important CEO skills for leading through an era of disruption?

Lila Snyder: A steady hand is important. You can’t get too high or too low. When challenges come, the company is looking to see how you react. If you’re panicked, that will create chaos in the organization, so the ability to take that in and say, “We’ve dealt with other things before, we’ll deal with this,” is incredibly important for a leader.

At Bose, we often talk about how the CEO is at the center, and the organization is at the end, and the more emotion you create centrally, the more that will feed into the field. The leader needs to take each thing in turn, recognize you’ve got a team that can handle the challenge, and just get to work figuring out how you will deal with it.

McKinsey: I want to talk about what it means to be a role model as a woman CEO. Any messages you would like to convey to the next generation of women who are eager to become corporate CEOs?

Lila Snyder: The great news is that there are more and more women CEOs every day. I certainly don’t feel like a pioneer or alone. I tend to focus on two things. One is being authentic. For many women, and certainly for me as I was growing in my career, seeing other women talk about how they make it work and being themselves is a huge part of how you figure out your own leadership style. I talk about the challenges at home. I talk about the fact that I have kids. I try to make sure people understand that every leader at every level is the same as everyone else. We all have a life that we’re trying to manage. I think that authenticity comes through in the way that you lead, and people appreciate that you have empathy for what they’re going through.

For people who want to get far in their careers, there’s nothing more important than taking risks every single day that make you uncomfortable.

The other piece of advice I always give is to take risks. I tell everyone—women and men—that the only way you can grow is by pushing yourself to do things that you don’t already know how to do. Put yourself out there and take on opportunities that you don’t feel ready for. Sometimes, someone else pushes you into those, and sometimes you need to raise your hand and step forward. Taking those risks is how you fail, how you learn, and how you develop new capabilities. And in a finite career, the faster you can develop yourself and your skills, the farther you’ll go. For people who want to get far in their careers, there’s nothing more important than taking risks every single day that make you uncomfortable. I still try to do that.

McKinsey: Tell us about a risk or two that you’ve taken that was meaningful to you.

Lila Snyder: Certainly, taking this job was a risk. CEOs bear responsibility for everything that happens in the company, and stepping into this role was scary and uncomfortable. I was joining Bose from outside. At that time, very few senior executives had come from outside. Bose very much had a culture of growing its own leaders. I was nervous about being a new CEO in a situation where there could have been organ rejection. There are small risks, too, like taking on opportunities to speak at conferences. I recently spoke at MIT’s [Massachusetts Institute of Technology’s] graduation, which was hugely scary but a great opportunity.

McKinsey: What are your daily rituals?

Lila Snyder: Practically speaking, the one daily ritual I am committed to is reviewing the sales report. It’s probably the first thing I look at on my phone every morning. I’m always looking to see how we’re doing against our targets.

## How relevant and useful is this article for you?

## About the author(s)

Lila Snyder is the CEO of Bose. Liz Hilton Segel is chief client officer and managing partner of global industry practices and a senior partner in McKinsey’s New York office.

Comments and opinions expressed by interviewees are their own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement.

## Explore a career with us

## Related Articles

## What’s your superpower? How companies can build an institutional capability to achieve competitive advantage

## Disrupting a mature industry with a digital solution: A conversation with Mlion’s Eric Leong

## The direct-to-customer edge: Increasing shareholder value through business building","{""publication_date"": ""October 16, 2023"", ""word_count"": 1922, ""reading_time_minutes"": 10}",2025-03-14 12:38:47.297757
21,What does it take to be a leader at a company?,https://www.mckinsey.com/featured-insights/themes/what-does-it-take-to-be-a-leader-at-a-company,,"## What does it take to be a leader at a company?

February 17, 2025“As the world grows more complicated, so must our perceptions of and approaches to leadership development,” write McKinsey’s global managing partner Bob Sternfels and coauthors. CEOs and top teams must make decisions while focusing on multiple critical issues at one time, so what does it take to be a leader in today’s fragmented world? This Presidents’ Day, hear from different company leaders—in software, product management, insurance, and more—about evolving as a leader during periods of rapid change, improving resilience across their organizations, the impact of generative AI on their industries, and beyond.

Wesco CEO John Engel on beating the odds with a merger of equals

Trisha Price on leveraging data to build great products

Numat CEO Ben Hernandez on mitigating the risks of hazardous chemicals

Vince Tizzio on resilience and responsible leadership

Yuhki Yamashita on ‘user love’ as the fuel for product-led growth

## MORE FROM MCKINSEY

The art of 21st-century leadership: From succession planning to building a leadership factory

How CEOs learn to lead from the inside out","{""word_count"": 183, ""reading_time_minutes"": 1}",2025-03-14 12:38:52.415154
22,Health in a changing climate,https://www.mckinsey.com/featured-insights/sustainable-inclusive-growth/charts/health-in-a-changing-climate,,"## Health in a changing climate

October 9, 2024The World Health Organization has called climate change “the greatest threat to global health in the 21st century.” Besides mitigation, adaptation—that is, dealing with existing or forecasted climate effects—is a pressing mandate, say senior partner Hemant Ahlawat and coauthors. Others seem to agree: the Health Innovation Exchange’s Climate Health Innovation Equity Fund’s call for solutions that address climate change sparked more than 80 adaptation-related applications, out of 130-plus received. These submitted innovations included medical products, surveillance and response systems, and healthcare infrastructure, supply chain, and workforce capabilities.

A series of area tree maps shows the number of Climate Health Innovation Equity Fund (CHIEF) applications for health-related climate adaptation, by region and adaptation type. Africa submitted the highest number of applications, with 59, followed by Asia with 37, North America with 15, Europe with12, Latin America with 5, the Middle East with 3, and Oceania with 2. The most common adaptation type across all regions was climate-resilient healthcare building, equipment, and IT infrastructure, with 33 from Africa, 25 from Asia, 12 from North America, 6 from Europe, and 2 each from Latin America, the Middle East, and Oceania.

Footnote: All digital-health applications.

Source: Health Innovation Exchange.

End of image description.

To read the article, see “Health-related climate adaptation: How to innovate and scale global action for local needs,” August 20, 2024.","{""word_count"": 228, ""reading_time_minutes"": 1}",2025-03-14 12:38:58.501668
23,How SQM accelerated operational excellence with technology,https://www.mckinsey.com/capabilities/operations/our-insights/how-sqm-accelerated-operational-excellence-with-technology,,"## How SQM accelerated operational excellence with technology

In 2013, SQM, based in Santiago, Chile, became the first mining company to adapt the principles of lean management to the complexities of extracting minerals in some of the world’s most challenging locations. Three years into the company’s transformation, McKinsey spoke with three senior SQM executives about the organization’s progress—especially the lasting benefits from changing the way people lead.

Now, more than ten years after SQM’s journey began, leaders at every level of the company keep pushing to improve. The new urgency: deploy the latest technologies, including gen AI, to keep raising quality, reducing water and energy use, and investing in people, even as ore extraction becomes progressively more difficult.

McKinsey spoke with SQM’s Pablo Altimiras, CEO for iodine and vegetal nutrition; José Miguel Berguño, senior vice president for corporate services; and Carlos Díaz, CEO for lithium and potassium. The common themes they discussed included cultural transformation, technology and data integration, sustainability, leadership, continuous improvement, and the importance of involving people at all levels.

The discussion has been edited for brevity and clarity.

## José Miguel Berguño

## Pablo Altimiras

## Carlos Díaz

McKinsey: What does continuous improvement mean to SQM, especially over time?

Carlos Díaz: We started this journey more than ten years ago, in November 2013, pioneering the implementation of lean management in mining globally. This initiative, which we called “M1,” led to a significant cultural transformation, impacting production, cost reduction, quality, and overall worker culture (Exhibit 1). The continuous-improvement process has evolved into what we now call “M1+,” an updated version focusing more on digital technology while maintaining the core cultural values—lean plus technology.

José Miguel Berguño: At the beginning, we thought that this kind of transformation was just a methodology transformation. And we put a lot of focus on how to implement different kinds of tools. But as we learned, we moved the focus from the methodology by itself to how to transform our culture.

Pablo Altimiras: And it was really because of the cultural change that we saw results. We increased production in some plants by more than 60 percent while decreasing costs by 20 percent. At the same time, we significantly reduced the number of incidents and accidents: The rate fell by two-thirds in the first couple of years.

It was really because of the cultural change that we saw results. We increased production in some plants by more than 60 percent while decreasing costs by 20 percent.

McKinsey: How has SQM’s approach to training and capability building evolved?

José Miguel Berguño: Our programs recognize that the complexity of our plants is constantly increasing. It’s completely different than five years ago or ten years ago. Moreover, the quality we must deliver keeps increasing as well.

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

Carlos Díaz: In lithium, for example, the purity required for batteries keeps rising. The product we delivered five years ago—even three years ago—does not meet today’s standards, and today’s product will not meet the standards two or three years from now. So we are constantly working with our leaders and their teams, holding regular meetings to discuss current and future plans. This approach ensures that everyone is aligned and understands the company’s direction.

Our training programs are designed to be attractive, to keep annual employee turnover  to less than 2 to 3 percent. We focus on both cultural and technical training, especially since lithium processing is not typically covered in technical schools or universities in Chile.

McKinsey: That turnover rate is unusually low in the mining industry, no?

Carlos Díaz: We work hard to keep SQM attractive to potential candidates, with a strong culture and opportunities for learning and growth. We emphasize entrepreneurship, zero bureaucracy, and technical orientation. People sometimes raise concerns about possible cultural changes in the future, but we are committed to maintaining our current way of working—adapting it, as we are with our focus on technology in M1+, but following the same purpose, principles, and behaviors.

McKinsey: How is SQM integrating technology into its operations?

Carlos Díaz: We have been integrating advanced technology into our operations for over a decade, always with a focus on the value that technology could create.

José Miguel Berguño: M1+ arose in part out of our recognition that we had an opportunity to incorporate even more technology, such as advanced analytics and AI. We had reached the limits of relying mainly on expert people to navigate a much more complex process, especially with new pressures to raise yield in a more sustainable way.

Carlos Díaz: For example, we have significantly increased our lithium production while improving quality and reducing our carbon and water footprints. The use of data and technology allows us to adapt quickly to market changes and customer demands.

Pablo Altimiras: We see technology as just a different type of tool. The real question is how you use the technology. Think of how people are using chat-based gen AI platforms. I use them myself, and I’ve concluded that these sorts of tools must be available for everyone. They illustrate a constant challenge; what is important is to ask the right questions. Only then can the technology provide correct answers. That same thinking shapes our approach to deploying technology at our sites: it’s thinking through the right questions. That’s how you develop your capabilities as an organization so you can outcompete.

We see technology as just a different type of tool. The real question is how you use the technology.

McKinsey: You’ve mentioned sustainability as a rising concern for SQM. What are some of the main challenges?

Carlos Díaz: Our customers, particularly in the electric-vehicle industry, demand lithium with the lowest possible environmental impact. We have several initiatives aimed at achieving these goals, such as the Salar Futuro project, which focuses on more sustainable brine-processing methods.

Pablo Altimiras: Sustainability obliges us to think differently. It gives us new ways to think about value—a very important word at our company—and that leads us to new opportunities.

José Miguel Berguño: For example, with M1+, we are working to increase our production by 10 percent over the next three years (Exhibit 2). That’s a very big challenge: more production, more yield, and a more sustainable process. Yet we are very optimistic, working in the same basic way as we have for ten years, with constant improvements to the quality of our methodology and to our technology. The real effort is to push our culture so that it can achieve these major results.

McKinsey: How does SQM ensure flexibility and adaptability in its operations?

Carlos Díaz: Flexibility and adaptability are crucial for us. We have to be able to respond to changing market conditions and customer requirements quickly. This involves using data and technology to make informed decisions and continuously improving our processes. Our performance dialogues, held every morning, involve various teams discussing challenges and potential solutions, ensuring that everyone is aligned and working toward common goals.

Our performance dialogues, held every morning, involve various teams discussing challenges and potential solutions, ensuring that everyone is aligned and working toward common goals.

Pablo Altimiras: It’s the end-to-end thinking that really matters: not just optimizing a particular step but an entire process. In fertilizers, we could focus on our leaching operation, which produces a nitrate-rich solution that our chemical plants transform into final products. But by itself, optimizing the leaching process cannot optimize fertilizer production. We have to take into account that the solution will affect the plant.

Now we have data-driven AI models that consider the potential variability in the ore, the water we use, and the leaching process, all running in parallel with plant operations. That gives our people much greater ability to control each step so that we can use the fewest resources in maximizing yields and value. These technologies can detect patterns that would never have been possible to see before.

McKinsey: How do employees adapt to SQM’s culture?

Carlos Díaz: New employees, especially those fresh out of school or university, usually adapt well to our culture. They are generally more flexible and tech savvy, which aligns with our focus on continuous improvement and technological integration. For more experienced employees, the initial transformation was more challenging, but now the organization is well adapted, and new hires quickly learn to fit into our way of working.

José Miguel Berguño: The business has grown substantially since the original M1 program launched in 2013, though, so an increasing challenge is to move thousands of people in the same way—thinking together, making decisions according to the same methodology—while constantly evolving. Our capabilities have increased even more: It’s one thing to improve yield from 30 to 35  and much more complex to move from 80 to 85. A major initiative now is to help strengthen the connections between different areas within the company.

Pablo Altimiras: We’re building work groups, or cells, composed of people from different parts of the organization so that they can collaborate more effectively: someone from ore production, from the chemical plant, from our data team, and so forth. An increasingly important role is that of the production translator, who has expertise both in technology and in our processes. That person can help guide the problem-solving process by giving everyone in the room a common language.

McKinsey: That sounds like a pretty major shift in how people have traditionally worked.

Pablo Altimiras: It’s really just an example of what we call our “participation culture,” which works to prevent silos. I have a personal commitment to promote a no-silos culture. José Miguel mentioned our growth: SQM encompasses multiple mines, plants, a port facility. We have commercial offices in more than 40 countries. We need to fight every day to keep a silo culture from forming.

McKinsey: How has SQM’s evolution through M1 and M1+ changed how you lead?

Carlos Díaz: What hasn’t changed is that leadership at SQM involves being deeply involved in both operational and strategic aspects. For example, as senior leaders, we all participate in daily operational meetings and quality discussions, ensuring that we are always aligned with our goals. This hands-on approach helps us stay connected with the realities of our operations and make informed decisions that drive continuous improvement. What has changed, at least for me, is perspective. For example, I see things even more from the customer’s point of view, and that informs our decisions on questions such as the standards we impose on ourselves for our sustainability goals.

Pablo Altimiras: We all feel a need to increase the quality of our leadership. Ten years ago, becoming an “M1 leader”—leading on cultural change, demonstrating new behaviors—took maybe 30 percent of my time. To become an M1+ leader involves much more: to connect technology, advanced analytics, and AI, plus connecting with other managers and senior people. This is the personal challenge I have set for myself.

José Miguel Berguño: Leaders achieve sustainable results and build culture. We need leaders who connect productivity, safety, and organizational well-being objectives. Increasingly, it’s not just how to be a good leader on the topics I am responsible for but how to be a good second for other leaders on their topics so we can collaborate effectively and reduce friction. That’s essential for planning. At SQM, we are in a long-term business. Improvement cycles in lithium production take between 14 and 18 months, so throughout the company, we need to work with one another in a planning process that identifies where to focus today and in six, 12, or 18 months’ time.

Pablo Altimiras: It’s all part of a value chain mindset. Sometimes you need to be ready to prioritize an area that is not exactly yours. We have been working very hard to make sure the whole executive team works from this point of view.

McKinsey: What do you see as the next challenge for SQM and its culture?

Pablo Altimiras: Overall, our goals are simple: to protect the business that we have today, to maximize its potential value, and to look for new business opportunities. And we have three focuses for managing the business. First is a clear strategy—not a fancy one—based on a sound diagnosis of current conditions, with a direct line through to concrete, simple plans. Second is good processes—not just traditional operational excellence, but the ability to improve our processes, react quickly, and become more efficient. This is where technology is critical. Third, and most important, is people.

José Miguel Berguño: Yes, I see a need to dedicate more time to developing our people throughout the organization and helping them develop each other. It’s not just developing the people who work very close to us. It’s the second layer of people, the third layer. It’s more than just helping them resolve a discrete problem. It’s dedicating time so that they can collaborate effectively, even when working on complex issues.

Carlos Díaz: We need people who can adapt to different scenarios in service of our role as the largest single producer of lithium. And that is why I try to push to use more data, more technology, equipping people with information that was impossible to find before to increase our productivity and reduce our carbon footprint and water use.

## How relevant and useful is this article for you?

## About the author(s)

Carlos Díaz is the CEO for lithium and potassium at SQM. José Miguel Berguño is the senior vice president for corporate services at SQM. Pablo Altimiras is the CEO for iodine and vegetal nutrition at SQM. This interview was conducted by Ferran Pujol, a partner in McKinsey’s Santiago office.

The author wishes to thank Alejandro Krell and Julio Gregorio for their contributions to this article.

This article was edited by Christian Johnson, an executive editor in the Washington, DC, office.

Comments and opinions expressed by interviewees are their own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement.

## Explore a career with us

## Related Articles

## Building a modern mining company: Interview with Neal Froneman

## Using AI to accelerate process optimization: Is your plant ready?

## Beyond the hype: New opportunities for gen AI in energy and materials","{""publication_date"": ""March 7, 2025"", ""word_count"": 2427, ""reading_time_minutes"": 12}",2025-03-14 12:39:05.748605
24,The fairness factor in performance management,https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-fairness-factor-in-performance-management,,"## The fairness factor in performance management

The performance-management process at many companies continues to struggle, but not for lack of efforts to make things better. Of the respondents we surveyed recently, two-thirds made at least one major change to their performance-management systems over the 18 months prior to our survey. With growing frequency, human-resources departments are dispensing with unpopular “forced curve” ranking systems, rejiggering relatively undifferentiated compensation regimes, and digging deeply into employee data for clues to what really drives motivation and performance. (For a look at how Microsoft CEO Satya Nadella is innovating with a system that uses hard and soft performance measures to reshape the culture, see “Microsoft’s next act.”)

## Stay current on your favorite topics

Yet companies don’t seem to be making much headway. Employees still complain that the feedback they get feels biased or disconnected from their work. Managers still see performance management as a bureaucratic, box-checking exercise. Half of the executives we surveyed told us that their evaluation and feedback systems have no impact on performance—or even have a negative effect. And certain experiments have gone awry: at some companies, eliminating annual performance reviews without a clear replacement, for example, has led employees to complain of feeling adrift without solid feedback—and some employers to reinstate the old review systems.

Amid ongoing dissatisfaction and experimentation, our research suggests that there’s a performance-management issue that’s hiding in plain sight: it’s fairness. In this article, we’ll explain the importance of this fairness factor, describe three priorities for addressing it, and show how technology, when used skillfully, can reinforce a sense of fairness.

## The fairness factor

When we speak of fairness, we’re suggesting a tight definition that academics have wrestled with and come to describe as “procedural fairness.”11.
For additional research and insights into fairness in the organization, visit EthicalSystems.org.
   It’s far from a platonic ideal but instead addresses, in this context, the practical question of whether employees perceive that central elements of performance management are designed well and function fairly. This eye-of-the-beholder aspect is critical. Our survey research showed that 60 percent of respondents who perceived the performance-management system as fair also stated that it was effective.

More important, the data also crystallized what a fair system looks like. Of course, a host of factors may affect employee perceptions of fairness, but three stood out. Our research suggests that performance-management systems have a much better chance of being perceived as fair when they do these three things:

• transparently link employees’ goals to business priorities and maintain a strong element of flexibility

• invest in the coaching skills of managers to help them become better arbiters of day-to-day fairness

• reward standout performance for some roles, while also managing converging performance for others

Such factors appear to be mutually reinforcing. Among companies that implemented all three, 84 percent of executives reported they had an effective performance-management system. These respondents were 12 times more likely to report positive results than those who said their companies hadn’t implemented any of the three (exhibit).

Our research wasn’t longitudinal, so we can’t say for sure whether fairness has become more important in recent years, but it wouldn’t be surprising if it had. After all, organizations are demanding a lot more from their employees: they expect them to respond quickly to changes in a volatile competitive environment and to be “always on,” agile, and collaborative. As employers’ expectations rise and employees strive to meet them, a heightened desire for recognition and fairness is only natural. And while embattled HR executives and business leaders no doubt want to be fair, fairness is a somewhat vague ideal that demands unpacking.

## Winning the battle of perceptions

In working with companies pushing forward on the factors our research highlighted, we have found that these require much greater engagement with employees to help them understand how their efforts matter, a lot more coaching muscle among busy managers, and some delicate recalibration of established compensation systems. Such shifts support a virtuous cycle that helps organizations get down to business on fairness.

## 1. Linking employees’ goals to business priorities

Building a foundation of trust in performance management means being clear about what you expect from employees and specific about how their work ultimately fits into the larger picture of what the company is trying to accomplish. Contrast that sense of meaning and purpose with the situation at many organizations where the goals of employees are too numerous, too broad, or too prone to irrelevance as events change corporate priorities but the goals of individuals aren’t revisited to reflect them. A typical ground-level reaction: “Managers think we aren’t sophisticated enough to connect the dots, but it’s obvious when our goals get disconnected from what really matters to the company.”

Give employees a say and be flexible. Connecting the dots starts with making employees at all levels feel personally involved in shaping their own goals. Mandating goals from the top down rarely generates the kind of employee engagement companies strive for. At a leading Scandinavian insurer, claims-processing operations were bogged down by surging backlogs, rising costs, and dissatisfied customers and employees. The company formed a working group of executives, managers, and team leaders to define the key areas where it needed to improve. Those sessions served as a blueprint: four overarching goals, linked to the problem areas, could be cascaded down to the key performance indictors (KPIs) at the business-unit and team level and, finally, to the KPIs of individual employees. The KPIs focused on operational measures (such as claims throughput and problem solving on calls), payout measures (like managing contractors and settlement closures), customer satisfaction, and employee morale and retention.

The company took a big further step to get buy-in: it allowed employees to review and provide feedback on the KPIs to assure that these fit their roles. Managers had observed that KPIs needed to vary even for employees in roles with seemingly similar tasks; phone calling for a targeted auto claim is different from skills needed to remedy damage to a factory. So the insurer gave the managers freedom to adjust, collaboratively, the KPIs for different roles while still ensuring a strong degree of consistency. A performance dashboard allowed an employee’s KPIs to be shared openly and daily with team members, making transparent both the teams’ overall progress and the efforts of motivated, top performers.

For the vast majority of traditional roles, this collaborative approach to KPI design is fairly straightforward. For more complex roles and situations—such as when tasks are deeply interdependent across a web of contributors—it can be more challenging to land on objective measurements. Such complex circumstances call for even more frequent feedback and for getting more rigorous about joint alignment on goals.

Adapt goals as often as needed. In today’s business environment, goals set at a high level in the strategy room are often modified in a few months’ time. Yet KPIs down the line are rarely adjusted. While we’re not suggesting that employees’ goals should become moving targets, they should certainly be revised in response to shifting strategies or evolving market conditions. Revisiting goals throughout the year avoids wasted effort by employees and prevents goals from drifting into meaninglessness by year-end, undermining trust. Of respondents who reported that their companies managed performance effectively, 62 percent said that those organizations revisit goals regularly—some on an ad hoc basis, and some twice a year or more. Managers must be on point for this, as we’ll explain next.

## 2. Teaching your managers to be coaches

Managers are at the proverbial coal face, where the hard work of implementing the performance requirements embodied in KPIs gets done. They also know the most about individual employees, their capabilities, and their development needs. Much of the fairness and fidelity of performance-management procedures therefore rests on the ability of managers to become effective coaches. Less than 30 percent of our survey respondents, however, said that their managers are good coaches. When managers don’t do this well, only 15 percent of respondents reported that the performance-management system was effective.

## Would you like to learn more about our People & Organizational Performance Practice?

Start with agility. In a volatile business environment, good coaches master the flux, which means fighting the default position: goal setting at the year’s beginning ends with a perfunctory year-end evaluation that doesn’t match reality. At the Scandinavian insurer, team leaders meet weekly with supervisors to determine whether KPI targets and measures are in sync with current business conditions. If they aren’t, these managers reweight measures as needed given the operating data. Then, in coaching sessions with team members, the managers discuss and adjust goals, empowering everyone. Even when things aren’t in flux, managers have daily check-ins with their teams and do weekly team-performance roundups. They review the work of individual team members monthly. They keep abreast of the specifics of KPI fulfillment, with a dashboard that flashes red for below-average work across KPI components. When employees get two red lights, they receive written feedback and three hours of extra coaching.

Invest in capabilities. The soft skills needed to conduct meaningful performance conversations don’t come naturally to many managers, who often perform poorly in uncomfortable situations. Building their confidence and ability to evaluate performance fairly and to nudge employees to higher levels of achievement are both musts. While the frequency of performance conversations matters, our research emphasizes that their quality has the greatest impact.

One European bank transformed its performance-management system by holding workshops on the art of mastering difficult conversations and giving feedback to employees who are missing the ball. To ready managers for impending steps in the performance-management cycle, the bank requires them to complete skill-validation sessions, moderated by HR, with their peers. Managers receive guidance on how to encourage employees to set multiyear stretch goals that build on their strengths and passions. Just before these goal-setting and development conversations with employees take place, managers and peers scrum it out to test each other’s ideas and refine their messages.

Make it sustainable. At the European bank, the support sessions aren’t one-off exercises; they have become a central element in efforts to build a cadre of strong coaches. That required some organizational rebalancing. In this case, the bank restructured aspects of HR’s role: one key unit now focuses solely on enhancing the capabilities of managers and their impact on the business and is freed up from transactional HR activities. Separate people-services and solutions groups handle HR’s administrative and technical responsibilities. To break through legacy functional mind-sets and help HR directors think strategically, they went through a mandated HR Excellence training program.

The Scandinavian insurance company chose a different road, seeking to disseminate a stronger performance-management culture by training “champions” in specific areas, such as how to set goals aligned with KPIs. These champions then ran “train the trainer” workshops to spread the new coaching practices throughout the organization. Better performance conversations, along with a growing understanding of how and when to coach, increased perceived fairness and employee engagement. Productivity subsequently improved by 15 to 20 percent.

## 3. Differentiating compensation

Capable coaches with better goal-setting skills should take some of the pain out of aligning compensation—and they do to an extent. However, new organizational roles and performance patterns that skew to top employees add to the challenges. Incentives for traditional sales forces remain pretty intuitive: more effort (measured by client contacts) brings in more revenue and, mostly likely, higher pay. It’s harder to find the right benchmarks or to differentiate among top, middle, and low performers when roles are interdependent, collaboration is critical, and results can’t easily be traced to individual efforts. The only way, in our experience, is to carefully tinker your way to a balanced measurement approach, however challenging that may be. Above all, keep things simple at base, so managers can clearly explain the reasons for a pay decision and employees can understand them. Here are a few principles we’ve seen work:

Don’t kill ratings. In the quest to take the anxiety out of performance management—especially when there’s a bulge of middle-range performers—it is tempting to do away with rating systems. Yet companies that have tried this approach often struggle to help employees know where they stand, why their pay is what it is, what would constitute fair rewards for different levels of performance, and which guidelines underpin incentive structures. Just 16 percent of respondents at companies where compensation wasn’t differentiated deemed the performance-management system effective.

Dampen variations in the middle. With middle-of-the-pack performers working in collaborative team environments, it’s risky for companies to have sizable differences in compensation among team members, because some of them may see these as unfair and unwarranted. Creating the perception that there are “haves” and “have-nots” in the company outweighs any benefit that might be derived from engineering granular pay differences in the name of optimizing performance.

Cirque du Soleil manages this issue by setting, for all employees, a base salary that aligns with market rates. It also reviews labor markets to determine the rate of annual increases that almost all its employees receive. It pays middling performers fairly and consistently across the group, and the differences among such employees tend to be small. Managers have found that this approach has fostered a sense of fairness, while avoiding invidious pay comparisons. Managers can opt not to reward truly low performers. Cirque du Soleil (and others) have also found ways to keep employees in the middle range of performance and responsibilities whose star is on the rise happy: incentives that are not just financial, such as explicit praise, coaching, or special stretch assignments.

Embrace the power curve for standout performers. Research has emerged suggesting that the distribution of performance at most companies follows a “power curve”: 20 percent of employees generate 80 percent of the value. We noted this idea in a previous article on performance management and are starting to see more evidence that companies are embracing it by giving exceptional performers outsized rewards—typically, a premium of at least 15 to 20 percent above what those in the middle get—even as these companies distribute compensation more uniformly across the broad midsection.

At Cirque du Soleil, managers nominate their highest-performing employees and calibrate pay increases and other rewards. Top performers may receive dramatically more than middle and low performers. In our experience, employees in the middle instinctively get the need for differentiation because it’s no secret to them which of their colleagues push the needle furthest. Indeed, we’ve heard rumblings about unfair systems that don’t recognize top performers. (For a counterpoint to radical performance differentiation, see “Digging deep for organizational innovation,” where Hilcorp CEO Greg Lalicker explains how the oil and gas producer sets exacting production standards and then—if they’re met—gives every employee a power-curve bonus.)

Innovate with spot bonuses. Recognizing superior effort during the year can also show that managers are engaged and that the system is responsive. Cirque du Soleil rewards extraordinary contributions to special projects with a payment ranging from 2 to 5 percent of the total salary, along with a letter of recognition. In a recent year, 160 of the company’s 3,500 employees were recognized. Spot bonuses avoid inflating salary programs, since the payments don’t become part of the employee’s compensation base.

## Technology’s role

Digital technologies are power tools that can increase the speed and reach of a performance-management transformation while reducing administrative costs. They’re generally effective. Sixty-five percent of respondents from companies that have launched performance-related mobile technologies in the past 18 months said that they had a positive effect on the performance of both employees and companies. A mobile app at one global company we know, for example, makes it easier for managers and employees to record and track goals throughout the year. Employees feel more engaged because they know where they stand. The app also nudges managers to conduct more real-time coaching conversations and to refine goals throughout the year.

Does technology affect perceptions of fairness? That depends on how it’s applied. When app-based systems are geared only to increase the efficiency of a process, not so much. However, when they widen the fact base for gauging individual performance, capture diverse perspectives on it, and offer suggestions for development, they can bolster perceived fairness. We have found that two refinements can help digital tools do a better job.

## Sweat the small stuff

In an attempt to move away from a manager-led performance system, German e-commerce company Zalando launched an app that gathered real-time performance and development feedback from a variety of sources. The company tested behavioral “nudges” and fine-tuned elements of the app, such as its scoring scale. Yet it found that the quality of written development feedback was poor, since many employees weren’t accustomed to reviewing one another. The company solved this problem redesigning the app’s interface to elicit a holistic picture of each employee’s strengths and weaknesses, and by posing a direct question about what, specifically, an employee could do to stretch his or her performance. The company also found that feedback tended to be unduly positive: 5 out of 5 became the scoring norm. It did A/B testing on the text describing the rating scale and included a behavioral nudge warning that top scores should be awarded only for exceptional performance, which remedied the grade inflation.

## Separate development from evaluative feedback

Digitally enabled, real-time feedback produces a welter of crowdsourced data from colleagues, and so does information streaming from gamified problem-solving apps. The data are powerful, but capturing them can trigger employees’ suspicions that “Big Brother is watching.” One way to address these fears is to distinguish the systems that evaluate employees from those that help them develop. Of course, it is tempting to make all the data gathered through these apps available to an employee’s manager. Yet when employees open themselves to honest feedback from their colleagues about how to do their jobs better, they’re vulnerable—particularly if these  development data are fed into evaluation tools. That also undercuts the purpose (and ultimately the benefits) of digitally enabled feedback. Apps should be designed so that employees can decide which feedback they ought to share during their evaluations with managers.

To broaden adoption of the system, Zalando stressed that the app was to be used only for development purposes. That helped spur intense engagement, driving 10,000 users to the app and 60,000 trials in the first few months. Employees reacted positively to sharing and evaluating data that would help them cultivate job strengths. With that base of trust, Zalando designed a performance dashboard where all employees can see, in one place, all the quantitative and qualitative feedback they have received for both development and evaluation. The tool also shows individuals how their feedback compares with that of the average scores on their teams and of people who hold similar jobs.

## An agenda for the talent-first CEO

The many well-intentioned performance-management experiments now under way run the risk of falling short unless a sense of fairness underpins them. We’ve presented data and examples suggesting why that’s true and how to change perceptions. At the risk of oversimplifying, we’d also suggest that busy leaders striving to improve performance management listen to their employees, who have a pretty good idea about what fair looks like: “Just show us the link between what we do and what the company needs, make sure the boss gives us more coaching, and make it all pay.” In our experience, when leaders understand, address, and communicate about the issues at this level, employees see performance management as fair, and the reform efforts of their companies yield better results.

## Stay current on your favorite topics

## How relevant and useful is this article for you?

## About the author(s)

Bryan Hancock is a partner in McKinsey’s Atlanta office, Elizabeth Hioe is an alumna of the New Jersey office, and Bill Schaninger is a senior partner in the Philadelphia office.

The authors would like to thank Sabrin Chowdhury for her contributions to this article.

## Explore a career with us

## Related Articles

## An agenda for the talent-first CEO

## Ahead of the curve: The future of performance management

## The CEO’s guide to competing through HR","{""publication_date"": ""April 5, 2018"", ""word_count"": 3367, ""reading_time_minutes"": 17}",2025-03-14 12:39:12.857567
25,Rethinking inventory management in defense,https://www.mckinsey.com/industries/aerospace-and-defense/our-insights/rethinking-inventory-management-in-defense,,"## Rethinking inventory management in defense

With competition growing, defense companies have been increasing R&D investments, boosting capital expenditures, and aggressively pursuing inorganic growth through M&A. These ventures, requiring vast amounts of cash, have recently put working capital in the spotlight. Adding to the attention, the COVID-19 pandemic has prompted governments, investors, CEOs, and others to take a closer look at the working capital of any potential contract partners, since this can serve as a proxy for their resilience.

## Listen to this article

Traditionally, defense companies have tried to optimize working capital through strong inventory management. A disciplined approach, they reasoned, could quickly generate enough cash to satisfy their obligations and provide a cushion against tough economic times. But a new revenue-recognition framework, Accounting Standards Codification (ASC) 606, has complicated their strategy. Under the updated guidelines, companies must reclassify much inventory held on balance sheets into one of two new categories that were previously less relevant: unbilled accounts receivable (A/R) and contract assets.1A contract asset is an item (either a good or service) for which a customer has not yet provided any consideration. The right to reimbursement depends on something other than the passage of time, such as satisfactorily meeting performance standards. Items fall into the unbilled-A/R category if the customer has not paid any consideration, but the right to reimbursement is unconditional and depends only on the passage of time. For simplicity’s sake, this article will just refer to unbilled A/R, although the same principles apply to contract assets. Both categories reflect revenue for products or services for which a customer has not yet been billed.

With ASC 606 creating much higher unbilled-A/R balances, inventory management morphs from
an operations task to a cross-functional challenge requiring the close involvement of CFOs, chief procurement officers (CPOs), COOs, and contract leaders. Now with a broader group of executives rightly involved in managing inventory, a relook at everything from incentives to processes and key performance indicators (KPIs) is needed to optimize cash.

The defense industry has been under a higher regulatory burden than many other sectors because most of its business involves large products for which the government allows it to recognize revenue and bill costs over time. We estimate that the top 50 defense companies worldwide could free up over $32 billion in cash that is currently tied up as unbilled A/R on their balance sheets.

We estimate that the top 50 defense companies worldwide could free up over $32 billion in cash that is currently tied up as unbilled A/R on their balance sheets.

Our experience leading working-capital transformations has allowed us to develop a new approach to managing inventory and unbilled A/R. It involves four critical activities:

• simplifying product portfolios to match customer demand

• optimizing the end-to-end material-management process to reflect production needs

• rightsizing production-cycle times to accelerate material through the factory floor

• optimizing billing and performance milestones during customer negotiations

By following this approach, defense companies can become more agile partners to government customers because they will have more cash on hand to respond to customer requests, such as those for new products. It takes time to build the necessary capabilities, however, and companies should act now to maximize their advantage.

## The repercussions of ASC 606 for inventory management

The reclassification of inventory as unbilled A/R occurs because ASC 606 accelerates the recognition of revenue associated with customer contracts. Rather than waiting until the time a final product or service is delivered, companies recognize a portion of revenue on their balance sheets when they meet specific performance milestones or dates specified in their contracts. ASC 606 also specifies that labor, profit, overhead, and general and administrative costs must be considered when calculating unbilled A/R (Exhibit 1). These costs, which were not traditionally bundled with inventory, are periodically recognized and billed to customers throughout the life cycle of a product or service, with the frequency varying by contract.

The conversion of inventory balances to unbilled A/R creates a distinction between physical and financial realities. Consider the example of a defense company that purchases $1 million in parts and other materials to build a system for a government (Exhibit 2). Based on the contract, it can immediately bill 80 percent of the value of that material—$800,000—to the government. This amount gets classified as billed A/R, and the company carries the remaining $200,000 as unbilled A/R on its balance sheet. Thirty days later, the government pays the company $800,000 for the material it received. From the second month on, the defense company incurs labor and overhead charges of $150,000 that get added to the unbilled-A/R balance. The contract specifies that the government can only be billed for $50,000 in labor and overhead each month. Before the first labor and overhead payment is received, the defense company would carry $350,000 of unbilled A/R on its balance sheet for on-hand material that is worth $1 million.

At top defense companies, over a third of their inventory—about $92 billion of the total $286 billion value—has been reclassified as unbilled A/R over the past few years (Exhibit 3).2About 82 percent of these balances are concentrated in US companies, although international companies also have growing balances. Over the past three years, the 26 percent compound annual growth rate for unbilled A/R has outpaced that for defense inventory (10 percent) and revenues (5 percent). This growth shows no sign of slowing because companies are still struggling to manage unbilled A/R effectively.

## Challenges managing unbilled accounts receivable

Controlling the outsize growth in unbilled A/R will require cross-functional collaboration among leaders from operations, commercial, supply-chain, contracts, and finance functions. But even the most committed teams will encounter three challenges.

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

## After a government makes a partial payment, it shares ownership interest in materials

By accelerating the recognition of cost and revenue, ASC 606 also hastens the point at which purchased materials are committed to the production of a specific customer system. This occurs because a government becomes a shared owner of materials once a partial payment is recorded on the balance sheet. With shared ownership, companies cannot use many of the levers they have traditionally applied during inventory management, such as scrapping, selling, or repegging materials to different programs.

## Unbilled accounts receivable is not tied to on-hand material

The inclusion of unbilled A/R on the balance sheet can vastly understate the value of on-hand material because it is burdened with costs that are billed for at monthly intervals. Early in a system’s production life cycle, these costs will largely relate to labor, material, and overhead. When production is near complete, costs will overwhelmingly consist of profit margins that cannot be billed until final delivery. Overall, we estimate that the inclusion of unbilled A/R on a balance sheet underestimates material value by 60 percent or more at some points in the product life cycle. Such discrepancies present the opportunity for operations, finance, procurement, and contracts leaders to work together to look beyond the balance sheet and understand the end-to-end life cycle of their inventory.

## The cash life cycle of unbilled accounts receivable can vary

Payment and performance milestones vary by contract, adding another layer of complexity to managing the overall balance of unbilled A/R. For instance, some contracts front-load payment milestones in the program life cycle, which makes the balance sheet appear healthy, at least early on, since unbilled A/R is relatively low. Other contracts spread performance-based milestones throughout the life cycle, which could result in very high unbilled-A/R balances if a product is delayed. To interpret and manage unbilled-A/R balances correctly, executives should thoroughly understand such operational issues, as well as contract milestones and metrics, such as the size of production batches relative to the amount of material ordered.

## A new approach to cash management for defense companies

Defense companies may still improve their working-capital position through some traditional inventory-management levers, such as rightsizing safety stocks by SKU, but ASC 606 will limit
the application of others. Faced with these restrictions, companies should explore a new
four-part approach to inventory management (Exhibit 4).

## Simplifying product portfolio(s) to match true customer demand

Defense companies have complex portfolios that include multiple product generations spanning decades. Traditionally, there have been limited contact points between portfolio management and cash management at these companies, since sales and engineering leads handle customer conversations about product specifications. But forging connections between cash and portfolio management can produce major benefits in both areas. For instance, companies can free significant amounts of cash if they simplify their offerings by “sunsetting” old product generations, removing incentives for sales of product lines with variable demand, and increasing the use of common parts across product lines. These actions optimize the timing of payments to suppliers for material purchases and reduce the on-hand materials required for production—a major benefit in times of uncertain customer demand.

## Optimizing the end-to-end material-management process to reflect production needs

When considering inventory, defense companies must consider many trade-offs. On one hand, companies are offered incentives to bring material in early to recognize revenue, reduce the financial risks associated with delays, and secure discounts from large order quantities. On the other hand, they cannot bill for materials until they meet key production or timing milestones, which could boost their unbilled-A/R balances.

## Modernizing military acquisition and sustainment for the 21st century

Two material-management levers can drive near-term impact while increasing cash flow. First, companies can institute time-phased planning for purchase orders. In other words, they choose the time and date of purchase orders based on planned production batch sizes and schedules, thereby minimizing excess on-hand material. Second, companies can increase alignment between material receipt dates and production-need dates to minimize on-hand material between billing milestones. Applying both levers together will produce even higher gains.

## Rightsizing production cycle times to accelerate material through the factory floor

As noted earlier, some contracts specify that companies will receive payments when specific performance milestones are met. But many governments refrain from paying profit margins on systems and products until they have been delivered and inspected. (There may be some exceptions to this, depending on the contract.)

If companies can reduce the length of production cycles by eliminating all dead time before, between, and after various steps, they can send out their final invoices earlier and fully liquidate unbilled A/R from balance sheets.

## Optimizing billing and performance milestones during customer negotiations

Billing and performance milestones traditionally vary by defense program or customer. Some contracts set firm payment milestones with very specific performance requirements, while others are more flexible. If contract negotiation is possible, defense companies can unlock significant amounts of cash by moving payment milestones forward. They could also lower the average quarterly unbilled-A/R balance by increasing the frequency of cash-billing milestones.

Defense-company executives have the opportunity to rethink their approach to inventory management to reduce unbilled A/R and maximize working capital. While COVID-19 has forced many defense companies to focus on short-term issues, they should begin preparing for the next normal by unlocking the cash needed to make strategic investments and better serve their customers.

## How relevant and useful is this article for you?

## About the author(s)

Ryan Brukardt is a senior partner in McKinsey’s Miami office; Isabelle Klinghoffer is a consultant in the New York office, where Michael Park is a senior partner; Allie Owens is an associate partner in the Boston office.

The authors wish to thank Peter Bacon, Brian Baum, Chris Daehnick, Aidan Fitzgerald, Sarah Georgin, Tyler Harris, and Brittany Worstell for their contributions to this article.

This article was edited by Eileen Hannigan, a senior editor at the Waltham, Massachusetts, office.

## Explore a career with us

## Related Articles

## Modernizing military acquisition and sustainment for the 21st century

## Value creation in industrials

## Call to action: How A&D companies can build the workforce of the future","{""publication_date"": ""May 3, 2021"", ""word_count"": 2044, ""reading_time_minutes"": 10}",2025-03-14 12:39:20.127861
26,"Why, and how, utilities should start to manage climate-change risk",https://www.mckinsey.com/industries/electric-power-and-natural-gas/our-insights/why-and-how-utilities-should-start-to-manage-climate-change-risk,,"## Why, and how, utilities should start to manage climate-change risk

The Fourth National Climate Assessment, released in late 2018, stated that climate change was already having noticeable effects in the United States and predicted “more frequent and intense extreme weather and climate-related events,” such as floods and hurricanes. For utilities, the assessment concluded, the possibilities were grave: lower efficiency, higher expenses, and more power outages—even as demand for energy rises. And many utilities are not ready. As the assessment noted, “Infrastructure currently designed for historical climate conditions is more vulnerable to future weather extremes and climate change.”

The cost of extreme weather is already high, and the frequency and the cost to life and property of extreme weather events has increased in recent years.

The cost of extreme weather is already high, and the frequency and the cost to life and property of extreme weather events has increased in recent years. If such events become more common or intense, as the assessment predicts, the price will be even higher. Even now, some utilities are making investments in long lived assets in risky locations, increasing system vulnerability and balance sheet risk. On that basis, we believe there is a strong case for utilities to start now to take steps on climate-change adaptation. And there are ways for them to do so—for example by strengthening the grid, exploring investments in batteries and microgrids, and working with new partners.

## The brewing cost storm for utilities

In 2017, Hurricane Irma made landfall in the Caribbean and Florida. A category 4 and 5 storm, Irma damaged 90 percent of the buildings on the island of Barbuda and caused the fourth-largest blackout in US history. The total cost of damage was $50 billion. And Irma was no outlier. Since 1958, the frequency and intensity of serious Atlantic hurricanes, like Irma, has risen (Exhibit 1).

In other ways, too, utilities are already more vulnerable to extreme weather events than in the past. When homes are built in areas prone to wildfires, power companies follow, placing their own assets at higher risk. These can even exacerbate the problem, if sparks from power lines ignite. Fires also emit additional carbon dioxide (CO2), a greenhouse gas that contributes to climate change. In California, the devastating 2018 fire season emitted approximately 15 percent of the CO2 California emits from all sources in a typical year.

Many of the nation’s 8,625 power plants were deliberately sited near shorelines in order to have access to water.

If climate change brings significant sea-level rise, as many models predict, that raises new vulnerabilities, but the risk is material today. In the United States, nine nuclear-power plants are located within two miles of the ocean. Many of the nation’s 8,625 power plants were deliberately sited near shorelines in order to have access to water. As a result, when hurricanes strike, power plants already face significant flooding damage.

According to the Department of Energy, 44 power plants were in flooded areas in Hurricane Irene and 69 were in flooded areas in Hurricane Sandy. During these hurricanes, eight nuclear power plants had to shut down or reduce service. During Houston’s Hurricane Harvey in 2017, wind and catastrophic flooding knocked down or damaged more than 6,200 distribution poles and 850 transmission structures; 21.4 gigawatts of generation were affected by wind damage, flooding damage, fuel supply issues, or evacuations and shutdowns. If sea levels rise, storm surges would hit further inland, causing more damaging coastal flooding to generation, transmission, and distribution infrastructure.

Unless utilities become more resilient to extreme weather events, they put themselves at unnecessary risk, in both physical and financial terms. Repairing storm damage and upgrading infrastructure after the fact is expensive and traumatic. Hurricane Katrina in 2005 forced Entergy New Orleans into Chapter 11 bankruptcy reorganization. There are, of course, compelling environmental and social reasons to invest in mitigation efforts sooner rather than later. We believe there are also economic ones. Power utilities need to invest on the basis that the present is already riskier than what was planned and the future will be more volatile. There is evidence that climate change adaptation can also be cost-effective.

## The benefits of being prepared

In order to understand the economics of mitigating climate-change risk in the United States, we considered the effect of extreme storms, largely hurricanes, on utilities, because it is relatively easy to measure storm-related impacts. To do so, we examined the financial records of ten large power utilities in seven states where hurricanes are common (Alabama, Florida, Georgia, Louisiana, North Carolina, South Carolina, and Texas), plus New Jersey, where hurricanes are less common but dense coastal populations mean damage from storms can be particularly costly.

According to this analysis, a typical utility saw $1.4 billion in storm-damage costs and lost revenues due to outages caused by storms over a 20-year period. Then, using estimates from the Fourth National Climate Assessment for increases in extreme weather events and coastal infrastructure damage driven by climate change, we estimated that by 2050, the cost of damages and lost revenues would rise by 23 percent ($300 million), or approximately two to three additional years with major hurricane damage. (These projected increases are conservative; they are based on estimates of regional increases in extreme weather or storm damage due to sea-level rise.) Combined, these estimates give us a baseline: $1.7 billion in economic damage for each utility by 2050.

A typical utility saw $1.4 billion in storm-damage costs and lost revenues due to outages caused by storms over a 20-year period.

Next, we looked at how much utilities have spent on programs to make their assets more resilient. We estimate it would take $700 million to $1 billion for a typical Southeastern US utility to prepare for impacts related to climate change. That is less than current 20-year storm costs of $1.4 billion and much less than the projected future storm costs of $1.7 billion. While each utility’s cost-benefit calculation will differ based on its unique risk exposure profile and infrastructure costs, our conclusion is that it pays to prepare for extreme weather (Exhibit 2). There are also likely to be ancillary benefits, such as improved reliability and enhanced diversity of supply.

This analysis only looks at the threat of increased storm damage to these ten utilities as a potential future cost; the National Climate Assessment notes that utilities could also see negative impacts from increased temperatures and heat waves, as well as sea-level rise even in the absence of storms. This will increase the financial costs to utilities of climate change and increase the benefits of being prepared.

## How to improve preparedness and resiliency

Many power utilities in the United States have already started taking steps in this direction. There are different ways for them to adapt, depending on their geographic circumstances and natural endowments. Even so, we find that these efforts are clustered around the following themes:

Harden the grid. This term refers to reinforcing the transmission and distribution (T&D) infrastructure to prevent or reduce the damage from extreme weather events. There are many examples. New Orleans Entergy, which lost 95 out of 125 miles of transmission lines during Hurricane Katrina, has invested $1 billion to improve the resilience of the substations and T&D lines, to ensure that they can withstand a storm of similar magnitude.

Similarly, after Superstorm Sandy hit the Northeast in September 2012, ConEd spent $1 billion and four years to strengthen its infrastructure. The utility installed distributed and elevated adjustable relay panels; elevated control houses; ensured all new equipment in flood zones will be able to function if submerged; strengthened overhead lines; and added capabilities to allow isolation of parts of the grid in order to reduce the number of customers affected by damage to one section.

Florida Power & Light (FPL) embarked on a long-term grid-hardening program after Hurricane Wilma caused extensive damage in 2005. FPL spent more than $3 billion on flood protection, distribution feeder reinforcement, and replacing wood poles with steel or concrete structures, among other programs. FPL has also buried power lines underground in select areas, as have other utilities, though the cost-benefit analysis of doing so is mixed.

These investments are relatively recent. Moreover, the timescales are extended and long-term effects are therefore difficult to calculate. It is too early to know, then, whether these efforts will work as intended. What can be said is that in each case, different utilities chose a similar strategy and that their infrastructure is stronger as a result.

Explore nonwire options that go beyond hardening the grid. Grid hardening is expensive, and even an extensive program may not be enough to cope with the most extreme events. After completing much of its $3 billion grid-hardening program, for example, FPL still suffered more than $1 billion in damage during Hurricane Irma in 2017. There are other ways to build resilience and adaptability. Here are some possibilities:

• Decentralizing generation. Locating smaller, utility-scale facilities closer to population centers can reduce reliance on long transmission lines that are vulnerable to damage during storms. It also means that if one facility goes down, others still keep going. FPL, for example, is beginning construction on four new solar plants. While economics and FPL’s clean-energy strategy played a large role in the decision, one of the installations in Miami–Dade county is explicitly designed as part of a resiliency strategy to provide more local generation.

• Battery storage. Batteries can provide backup power in the case of outages caused by storms and help utilities meet spikes in power demand. In 2017, Duke Energy announced a plan to invest $30 million to install North Carolina’s largest battery-energy storage system to provide backup power and improve grid reliability. In 2018, Duke increased the investment to $500 million over 15 years. In addition to providing enhanced reliability to the grid, these investments have already enabled the deferral of the construction of a new gas-peaker plant and allowed the utility to integrate larger amounts of renewable power into its mix.
The world’s biggest lithium-ion battery was installed in the state of South Australia in 2017 near the Hornsdale Wind Farm; the $63.25 million project was intended to support its main power grid during peak summer demand and to help integrate renewable energy. In 2018, the first full year of operation, the system brought in $20.7 million in revenues.

Battery storage. Batteries can provide backup power in the case of outages caused by storms and help utilities meet spikes in power demand. In 2017, Duke Energy announced a plan to invest $30 million to install North Carolina’s largest battery-energy storage system to provide backup power and improve grid reliability. In 2018, Duke increased the investment to $500 million over 15 years. In addition to providing enhanced reliability to the grid, these investments have already enabled the deferral of the construction of a new gas-peaker plant and allowed the utility to integrate larger amounts of renewable power into its mix.

The world’s biggest lithium-ion battery was installed in the state of South Australia in 2017 near the Hornsdale Wind Farm; the $63.25 million project was intended to support its main power grid during peak summer demand and to help integrate renewable energy. In 2018, the first full year of operation, the system brought in $20.7 million in revenues.

• Microgrids. A microgrid is a set of locally controlled loads and distributed-generation resources that can function apart from the centralized grid. A microgrid can power a specific site, such as a jail, campus, or office building; utilities can deploy them to provide backup power in the event of power outages on the central grid. Batteries can also provide power to microgrids.
After Hurricane Irene knocked out power to many Connecticut residents in 2011, the state began encouraging the formation of microgrids to improve resiliency. Subsequently, the town of Fairfield launched a microgrid for its critical infrastructure services, including its police department, fire department, communications center, and homeless shelter. While no storm has knocked out power to the main grid since installation, the town estimates the combined heat-and-power microgrid has saved the town an estimated $60,000 a year in electric expenses and $10,000 in heating expenses during normal operations—an example in which improving resiliency can be cost-effective.

Microgrids. A microgrid is a set of locally controlled loads and distributed-generation resources that can function apart from the centralized grid. A microgrid can power a specific site, such as a jail, campus, or office building; utilities can deploy them to provide backup power in the event of power outages on the central grid. Batteries can also provide power to microgrids.

After Hurricane Irene knocked out power to many Connecticut residents in 2011, the state began encouraging the formation of microgrids to improve resiliency. Subsequently, the town of Fairfield launched a microgrid for its critical infrastructure services, including its police department, fire department, communications center, and homeless shelter. While no storm has knocked out power to the main grid since installation, the town estimates the combined heat-and-power microgrid has saved the town an estimated $60,000 a year in electric expenses and $10,000 in heating expenses during normal operations—an example in which improving resiliency can be cost-effective.

• Environmental management. Active management of the natural environment can provide utilities and other infrastructure owners with protection against extreme weather. For example, coastal wetlands provide a natural barrier to lessen the impact of extreme storms. A recent study estimated that New Jersey’s coastal marshes reduce flood damage by 16 percent during normal storm years, and that after Hurricane Sandy in 2012, the presence of wetlands and marshes up and down the east coast reduced hurricane damage by 27 percent.
In 2015, Entergy and other Gulf Coast companies began a pilot program to restore coastal wetlands in Louisiana to provide storm protection. The effort can also be counted as an offset to the companies’ carbon emissions, since wetlands act as a carbon sink, providing a direct financial benefit.
The Alabama Power Company has constructed wetlands near its generation facilities; these also serve as filtration systems to remove chemicals from the water used in power-plant cooling.

Environmental management. Active management of the natural environment can provide utilities and other infrastructure owners with protection against extreme weather. For example, coastal wetlands provide a natural barrier to lessen the impact of extreme storms. A recent study estimated that New Jersey’s coastal marshes reduce flood damage by 16 percent during normal storm years, and that after Hurricane Sandy in 2012, the presence of wetlands and marshes up and down the east coast reduced hurricane damage by 27 percent.

In 2015, Entergy and other Gulf Coast companies began a pilot program to restore coastal wetlands in Louisiana to provide storm protection. The effort can also be counted as an offset to the companies’ carbon emissions, since wetlands act as a carbon sink, providing a direct financial benefit.

The Alabama Power Company has constructed wetlands near its generation facilities; these also serve as filtration systems to remove chemicals from the water used in power-plant cooling.

Active management of the natural environment can provide utilities and other infrastructure owners with protection against extreme weather.

Factor an up-to-date view of risk into operations. Utilities should consider the increased risk from climate change predicted by the Fourth National Climate Assessment and other reports as they examine their daily operations, not just when they are considering long-term investments. In a 2019 filing before the California Public Utilities Commission, Southern California Edison proposed changes to its operations to reflect its acknowledgement of the increased risk of wildfires. These measures include the increased monitoring of electrical equipment, clearing trees that pose a wildfire risk, and enhancing situation-awareness capabilities to allow for rapid emergency response, as well as prioritization of investments based on which locations are at greatest risk of wildfires.

Look for new partners to help develop and finance resiliency strategies. Utilities can work with insurers and reinsurers to assess climate risk and adaptation strategies. The latter can then help them underwrite those risks after the utilities have made agreed-upon investments in modernizing their infrastructures. In developing the Gulf Coast resiliency report, for example, Entergy worked with Swiss Re to develop regional models for climate
risk assessment.

Public–private partnerships are another way to finance new investments in resiliency (see sidebar, “The role of regulation”). One effort in Colorado is creating a demonstration solar panel and battery-storage microgrid outside Denver. In the event of an outage, the microgrid would automatically be switched on, with power provided by an intelligent rooftop photovoltaic battery system to keep critical services running. The project is also intended to improve the integration of renewable energy and to cope with peak demand.

## The role of regulation

Climate change could burden utilities with substantial costs above and beyond the damage caused by a particular event. In some jurisdictions, utilities can be held responsible for lost economic output caused by power outages. These assessments are, of course, ultimately borne by consumers, in the form of higher rates. A decade after Hurricane Katrina, Gulf Coast consumers were still paying storm damage charges.

Given their capabilities and knowledge, regulators are well positioned to work with utilities to help them make cost-effective investments in resiliency. Regulators can incentivize utilities to develop climate-adaptation plans that protect and upgrade their infrastructure. They can design liability structures that encourage utilities to take preventive actions by shifting the liability burden if specific measures are taken. And they can encourage experimentation and forward thinking. Regulators will have to define their priorities based on their specific circumstances, such as the state of their grid and generating system.

An example of resiliency-oriented regulation comes from Florida. Since 2006, the Florida Public Service Commission has required investor-owned power utilities to devise three-year storm-protection plans. The commission has also required utilities to implement aggressive vegetation management and an inspection program with an eight-year life cycle for wooden poles. Some utilities, for example, have replaced those poles with concrete structures designed to withstand 140 mile-per-hour winds.

Finally, research institutions can help apply new ideas and strategies to a specific utility’s context. For example, the Natural Capital Project—a partnership among Stanford University, the Chinese Academy of Sciences, the University of Minnesota, the Stockholm Resilience Centre, the World Wildlife Fund, and the Nature Conservancy—works with stakeholders to develop plans and stimulate investment in developments that improve resiliency through nature-based projects.

These and other ideas must be stress tested and analyzed to ensure they are appropriate for specific circumstances. But the point is to begin considering them.

Utilities are asset-heavy businesses that must maintain extensive and expensive infrastructures. Unless they become more resilient to extreme weather, those assets will be vulnerable—and so will the utilities. They are not, however, helpless before climactic impacts. They can prepare. Not only does this make good sense, it is good business.

## How relevant and useful is this article for you?

## About the author(s)

Sarah Brody is a consultant in McKinsey’s Washington, DC, office; Matt Rogers is a senior partner in the San Francisco office, where Giulia Siccardo is an associate partner.

The authors wish to thank Romina Mendoza and Jinchen Zou for their contributions to this article.

## Explore a career with us

## Related Articles

## Climate resilience: Asset owners need to get involved now

## How companies can adapt to climate change

## Short-termism and the threat from climate change","{""publication_date"": ""April 24, 2019"", ""word_count"": 3232, ""reading_time_minutes"": 16}",2025-03-14 12:39:26.460149
27,Change Leaders Forum,https://www.mckinsey.com/industries/public-sector/our-insights/change-leaders-forum,us or by third party providers whose services we have added to our pages,| McKinsey,"{""publication_date"": ""June 3, 2015"", ""authors"": [""us or by third party providers whose services we have added to our pages""], ""word_count"": 2, ""reading_time_minutes"": 1}",2025-03-14 12:39:33.073497
28,Source AI: Category management software,https://www.mckinsey.com/capabilities/operations/tech-tools/source-ai,us or by third party providers whose services we have added to our pages,"## Source AI: Category management software

## How we support you

## Harnessing the power of generative AI

## Enhance understanding and visibility of category spend

## Leverage market intelligence

## Boost your strategic category management capabilities

## Drive cost savings and efficiency

This tool has been a dream come true for us since we first deployed it last year. We envisioned a fully automated solution combining real-time internal data with the right category-specific market insights to create an ideal category strategy. Deploying Source AI has significantly added value on cost savings along with process efficiency improvements.

## Our capabilities

## Unlock the power of strategic category management with cutting-edge technological solutions

## Access comprehensive category insights

## Stay informed on category and supplier trends

## Drive value from automated advanced analytics

## Streamline contract review

## Boost problem solving

## Prepare for negotiations

## Technology in action

## Innovation & Learning Centers

## Connect with our Operations Practice","{""authors"": [""us or by third party providers whose services we have added to our pages""], ""word_count"": 159, ""reading_time_minutes"": 1}",2025-03-14 12:39:39.645443
29,Generative AI will change the social contract in Europe,https://www.mckinsey.com/featured-insights/lifting-europes-ambition/videos-and-podcasts/generative-ai-will-change-the-social-contract-in-europe,large language models,"## Generative AI will change the social contract in Europe

Generative AI is powered by large language models. Language means culture, and we’ve got a very diverse set of cultures and languages in Europe. Therefore, one cannot speak about global gen AI applications, because you must take the local context and culture into account, which makes Europe quite a unique place.

For the first time in 15 years, we’re experiencing the birth of the next generation of platforms. Think about the first smartphone, social network, or cloud application yodu first saw in 2007, and then all the apps that appeared on top of them. And suddenly, we now have AI—not just generative AI—augmented in virtual reality, coming together with Web 3 to form the new platforms. This will allow many European companies to create the first hyperskillers of the future, as well as a lot of the applications on top of these platforms.

If we think about the second dimension of generative AI, it's really around changing our current social interactions. Imagine a voice-activated virtual assistant that helps you schedule your day, shop, and even provides emotional support when needed. This idea creates enormous opportunities for new applications that could be developed by European technologists and entrepreneurs. We’re seeing a lot of European entrepreneurs and technologists returning to their countries to help solve very local problems. One of the toughest problems we’re dealing with involves ageing. Therefore, we could apply technology, and generative AI in particular, to provide support for an ageing population.

## How relevant and useful is this article for you?

## About the author(s)

Alexander Sukharevsky is a senior partner in McKinsey’s London office.

Comments and opinions expressed by interviewees are their own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement.

## Explore a career with us

## Related Articles

## Lifting Europe’s Ambition on generative AI

## Leveraging generative AI in Europe: The opportunities and challenges","{""publication_date"": ""October 17, 2023"", ""authors"": [""large language models""], ""word_count"": 331, ""reading_time_minutes"": 2}",2025-03-14 12:39:45.196389
30,Periscope receives four Best-in-Class distinctions in the POI 2024 Enterprise Planning Vendor Panorama report,https://www.mckinsey.com/capabilities/growth-marketing-and-sales/solutions/periscope/analyst-reports/periscope-receives-four-best-in-class-distinctions-in-the-poi-2024-enterprise-planning-vendor-panorama-report,,"## Periscope receives four Best-in-Class distinctions in the POI 2024 Enterprise Planning Vendor Panorama report

Periscope has received four Best-in-Class distinctions in the POI 2024 Consumer Goods Enterprise Planning & Retail Execution Vendor Panorama report.

The POI report measures how vendors help consumer packaged goods (CPG) and retail clients better understand the technologies and services available to them, so they can profit more from their promotions.

Periscope was named Best-in-Class in four functional areas:

• Collaboration—External

• Revenue Growth Management (RGM) Suite

• RGM User Experience (UX)

Periscope was cited in the POI report for its:

• Advanced analytics user experience (UX). Periscope combines power with simplicity in delivering capabilities. It provides clients with the ability to plan pricing and promotions together rather than in a silo so holistic planning decisions can be made.

• Revenue growth management (RGM) executed via elements of five RGM pillars. McKinsey has deep roots in pricing, promotion, assortment, and trade investment, which is evident in the Periscope platform. RGMx is a platform for delivering RGM impact at speed and scale.

• Trade promotion management (TPM). Periscope’s focus is optimization and RGM, and effective promotion planning is done through its trade promotion optimization (TPO) planning module.

• Generative AI/chatbot assistant. Periscope leverages gen AI to enrich data—for example, automating the extraction of features from product descriptions for competitive matching or defining price lines.

For more information, please contact us.

## Periscope has locations in 28 countries on 5 continents. If you would like to learn more about our solutions and expertise, please fill in the form below.

All fields are mandatory. Thank you.

## How relevant and useful is this article for you?","{""publication_date"": ""February 25, 2025"", ""word_count"": 278, ""reading_time_minutes"": 1}",2025-03-14 12:39:52.073592
31,How to get more value from your new tech? Five technologists weigh in,https://www.mckinsey.com/about-us/new-at-mckinsey-blog/how-to-get-more-value-from-your-new-tech-five-experts-weigh-in,,"## How to get more value from your new tech? Five technologists weigh in

Ivan Danov, senior principal machine learning engineer, and Debanjan Banerjee, a principal data engineer, at a QuantumBlack hackathon

November 15, 2024While McKinsey has almost a century of experience in management consulting, we are also a technology firm. We have 7,000 technologists, designers, and product managers serving clients in more than 50 countries. They range from specialists in AI, cloud and infrastructure to experts in domain transformations, including all aspects of industries and functions. This dual nature shapes our belief that it’s Never just tech: that the right strategy, talent, processes, and culture also need to be in place for tech to deliver on its potential.

Five of our experts share what Never just tech means to them.

We are helping our clients … create amazing new things.

I work with designers and engineers to develop software that helps our clients’ data science teams work at double or triple the speed. For example, with our Brix platform, developers can find and reuse existing code rather than reinventing it.

They can train and deliver AI models faster, across many different business units and geographies, and execute on the initiatives in their roadmap—realizing the potential of their AI investments more quickly.

We also contribute some of our products to the open-source community so they are publicly available, such as our industry-leading development tool, Kedro. Our open-source strategy is about helping our clients become truly independent because they can use Kedro in perpetuity, access the upgrades, and use the community-led support model for projects that live way beyond our engagement with them.

To me, the Never just tech approach means we come with our expertise, change management, portfolio of products, and capability building. It’s all based on helping our clients truly transform—so they can carry on and create amazing new things—long after we’ve gone.

## Creating value beyond the hype

…developers are freed from 80 to 90 percent of the routine work…

I help clients build capabilities and implement large-scale solutions for operating AI at scale. This involves deploying hundreds, if not thousands, of AI-enabled applications across their business units. For instance, we collaborated with a client to develop a new multi-tenant platform for real-time machine learning models. This platform ran multiple sites with over 10,000 events per second flowing to over 50 applications per site. It provided data validation, anomaly detection, event routing, and more—all integrated with robust data governance.

Despite the impressive technology, we cannot start there. It’s Never just tech. We must integrate business and non-technical requirements, ensure value capture, improve skills, and determine the necessary change management so the technology is adopted. These fundamental questions must be addressed for every technology build. Interestingly, the more we did this, the more we realized we could use technology itself to assist with these non-technical aspects.

For every platform we deliver, we begin with a self-service portal for training and knowledge updates. It allows users to find reusable components and complete application patterns. The platform enforces process improvement by orchestrating best-in-class automation for application deployments, ensuring continuous enhancements, calibrated risk controls, and automated security checks.

With these functions managed by the platform, developers are freed from 80 to 90 percent of the routine work. They essentially gain “bionic arms,” enabling them to move quickly onto more creative tasks and develop the next set of models. In essence, we are using tech to solve the Never just tech challenges.

What we do is almost ethnographic research…

The most exciting part about gen AI is that it can change the way people do their work. People clock in and clock out; they open Excel and their email, and interact with these applications. But when we build gen AI applications, we’re trying to transform how that work world functions—automating manual tasks, integrating workflows, or creating a whole new set of insights that we didn’t think possible.

We’ve been helping a legal firm automate some of its processes and working with lawyers and paralegals to translate their expertise into gen AI models. That entails understanding how they break down problems, the decision points, and the relevant legal regulations such as consumer rights. We “teach” the models by developing prompts, identifying and refining data sets, and presenting example images. It’s rarely 100 percent correct and there needs to be a human in the loop checking the accuracy of the data. This is where Never just tech comes in: the tech on its own can never be built “for purpose” unless you have the end users and the right experts co-build and shape the solution.

What we do is almost ethnographic research. We need the UX experts, who understand the human and emotional aspects of work, to help people describe their thoughts as they complete tasks. Analytics translators match the tech and tools to the need; scientists and engineers build it; designers make it engaging; and lastly, industry experts ensure the best practices and guardrails are in place.

The benefit is you get a much more well-rounded solution, with valuable, exciting insights that are intuitive and more readily used. This drives an experience that “delights” end users.

It’s about working side by side, getting into the details.

Never just tech isn’t something new. It goes back 12 years, when I first joined McKinsey as a software engineer. It describes our approach to technology implementations.

I recently served a major financial services institution. They had been attempting a digital transformation to update their core operations and customer experience, but were approaching it from a technology-only lens for years. We all agreed it was time for something different.

We established a digital innovation hub for developing new customer-facing applications, transforming their business, customer-first. We augmented their internal talent with external digital-native talent, changing the ways of working markedly with speed, agility and constant learning as they became change agents. We ultimately grew into a team of 200 and delivered five product launches in 20 months. Our clients could see not just the speed but also how excited their own people were to be working in such a cohesive and cross-functional unit, with all the skills needed to transform the business under one roof.

Our team included engineers from QuantumBlack and Leap; banking experts; agile coaches; McKinsey Academy colleagues for building capabilities; and an external tech partner to help with scaling. The team was not just cross-functional, it was cross cultural, from six different countries.

We worked side-by-side with our clients for months. It wasn’t: “Let’s redo an operating model and watch them succeed.” It was: “Get your hands dirty. Get into the details. Solving for a production launch at 6 AM and truly living a client’s business as if it was our own.” That kind of experience is what Never just tech means to me.

The hardest part? Saying goodbye to the clients I’d been working with for months.

The Never just tech approach is something that really excites me—it is the foundation of how we serve clients: every digital project is about people, process, and tech. Recently, we developed an enterprise-level bill payment app. We leveraged modern, cloud-based technologies with cutting-edge technical stacks and developed the application code for customers, all while using modern deployment and data management strategies. That’s the tech.

In terms of “people,” the project partnered all of the tech people, from department leads to entry-level engineers, with their business counterparts, so together they were creating solutions that the business needs and customers want.

In terms of “processes,” we created a framework that helped the team integrate customer feedback every time they developed new features, as well as a skills roadmap to guide their technical, business, and communication capabilities. These were some of the ways we could make sure that the workflows were in place, and they would keep growing—and train and integrate new people—even after we leave.

The hardest part of any project? Saying goodbye to the clients I had been working with for months. You develop great relationships and it’s exciting and inspiring to watch each of their growth journeys.

## Never miss a story","{""word_count"": 1354, ""reading_time_minutes"": 7}",2025-03-14 12:39:59.090918
32,The challenge of climate change,https://www.mckinsey.com/capabilities/sustainability/our-insights/the-challenge-of-climate-change,pressing the Escape key or activating the close button,"## The challenge of climate change

• descriptions off, selected

• captions settings, opens captions settings dialog

• captions off, selected

This is a modal window.

Beginning of dialog window. Escape will cancel and close the window.

End of dialog window.

This is a modal window. This modal can be closed by pressing the Escape key or activating the close button.

This is a modal window. This modal can be closed by pressing the Escape key or activating the close button.

## Share:

## BrightCove Video

McKinsey senior partner Dickon Pinner and others discuss the importance of addressing environmental sustainability in the next normal.

## The Next Normal: Doubling down on sustainability

When the world came to a standstill in the wake of the coronavirus outbreak, governments and businesses had to shift the focus of their agendas. Today, more than eight months after the shutdown, energy and resources are being poured into stopping the spread of the virus, and into repairing the economic, social, and emotional toll that the pandemic has wrought. Given the scope of this challenge—and the months, and even years, it could potentially take to address it—can the world afford to devote attention to climate change and the broader issue of sustainability?

It has to. The earth’s warming over the next decade is unavoidable, and with that reality comes an increased risk of physical and economic hazards. The only way to avoid the worst impacts of climate change post 2030 is to aggressively decarbonize our economy and our daily lives. Mitigating climate change through decarbonization is, therefore, a huge and necessary response. The emission goals of the Paris Agreement state that all parties will reduce their carbon footprint by more than 50 percent by 2030 and eliminate it by 2050.

“This is a unique time for companies on their sustainability journey, and the transition at large in the global economy,” says Dickon Pinner, senior partner and global leader of McKinsey & Company’s Sustainability Practice. “Doing nothing or doing just enough is not going to cut it. We have to act in this decade to avoid the most severe environmental and socioeconomic effects of a changing climate.”

Companies of all sizes are getting that message. Increasingly, business leaders and governments realize that responding to COVID-19 and addressing sustainability issues are not mutually exclusive efforts. Furthermore, smart investments in climate resilience and a lower carbon future are actually cost effective. Just look at the utility industry in the US: McKinsey research found that the average US utility company could save up to $1 billion over 20 years by investing in strengthening infrastructure and building resilience and adaptability through the use of microgrids and battery storage, for example, compared to the cost of repairing damage after it happens.

McKinsey research found that the average U.S. utility company could save up to $1 billion over 20 years by investing in strengthening infrastructure and building resilience and adaptability through the use of microgrids and battery storage, for example, compared to the cost of repairing damage after it happens.

Similar to the response needed to battle COVID-19, addressing sustainability in the broadest sense requires setting goals and creating a detailed road map for achieving them. The companies that are serious about this are focused on transitioning the real economy to be lower carbon at scale. The levers they’re using to get there? Reallocation of capital, innovation, resiliency, and transparency at every step of the way.

In the process, one thing is beginning to come into sharper focus, says Pinner. “For too long, companies, and governments for that matter, have been overexposed to the risks involved in climate change but underexposed to the opportunity,” he says. “It’s a colossal undertaking, but the 2020s are going to be the decade that proves whether the world will succeed or fail in meeting this critical challenge.”

The companies featured herein are taking decisive, massive, and transformative action. They understand the risks inherent in big, bold steps—but they’re equally aware of the danger of doing nothing or doing too little. And here’s something else: They’re not shy about saying that every company—big or small, legacy or disruptor—has a part to play and a contribution to make. That is not an easy mission, and it’s being made more complex by a ferocious global pandemic. But addressing climate change now is the only path to attaining a more prosperous, resilient and sustainable planet in the years ahead.

Climate change and plastic waste are among the biggest issues the world is facing, even in the midst of COVID-19, and our products and the technologies we’ve developed are crucial to addressing both.

## Feeding the planet, sustainably

“The food system is broken,” says Emmanuel Faber, CEO of Danone, the French food and beverage giant. That’s a provocative statement coming from a food company executive whose brands include Évian water, Dannon yogurt, and International Delight coffee creamers, but it underscores Faber’s commitment to operating Danone in a way that connects the health of consumers with the health of the planet.

In 2017, the company unveiled a guiding vision entitled One Planet. One Health. Faber explains: “For the last 50 years, the food industry has worked to lower the cost of calories that we bring to people, and we’ve done it very successfully. But a parallel result of that is that we have increased obesity, diabetes, and monocropping that ruins soil health. We’re not preparing the next generation for a food system that works.”

To address the twin issues of obesity and food waste, the company has set ambitious sustainability targets for each of its product lines. It can now also determine the source location, sustainability standard, and environmental impact of its ingredients. In February, Danone announced a $2.3 billion climate acceleration plan, which over the next three years will overhaul the company’s agriculture, energy, operations, and packaging to generate more resilient and sustainable growth for its brands. Faber says the investment will go a long way in helping the company cut in half the amount of plastic its water brands use and achieving carbon neutrality in Europe by 2025.

Danone is also working toward becoming a Certified B Corp by 2025. B-Corp status verifies that a company has met a high set of social and environmental performance standards and transparency. The company’s North American operations achieved B-Corp status in 2018. “For us, climate is not an externality,” Faber says. “It’s part of the resilience of our business, so addressing it is not a question of philanthropy—it’s a question of smart business.”

For us, climate is not an externality. It’s part of the resilience of our business, so addressing it is not a question of philanthropy—it’s a question of smart business.

## A ‘close to the core’ approach

When the world’s largest retailer decides to transform its operations to battle climate change, big things can happen. When it asks more than 60,000 suppliers to join that mission, the impact is enormous. Kathleen McLaughlin, chief sustainability officer at Walmart, says the retailer is leveraging its considerable sustainability know-how on “close to the core” areas: climate, nature, waste, and people. And while the pandemic has certainly presented its own set of challenges to businesses in nearly every corner of the globe, it has also underscored how powerful collective action can be, she says.

“One thing we’ve learned over the years, and certainly through the pandemic, is that there isn’t a trade-off between economic prosperity, social justice, and environmental sustainability,” McLaughlin says. “They all work together, and individual actions, even small ones, can have a meaningful impact.”

Within its own operations, the retail giant has committed to zero emissions by 2040 and 100 percent renewable energy by 2035. In its more than 10,000 stores, clubs, and distribution centers worldwide, nearly 30 percent of its electric needs now come from renewable energy, with a goal of 100 percent by 2035. And Walmart reports that it’s diverted an estimated 80 percent of its unsold products, packaging, and other operational materials from landfills and incineration globally, as part of its goal to generate zero waste in its operations.

The company also gets its massive network of suppliers involved. In 2017, it launched an ambitious initiative called Project Gigaton. The goal, McLaughlin explains, is to reduce 1 billion metric tons (a gigaton) of greenhouse gas emissions from the company’s supply chain by 2030. To put that number in perspective, consider that eliminating a gigaton of greenhouse gas emissions is the equivalent of taking 211 million passenger cars off the road for a full year, according to calculations by the Environmental Protection Agency (EPA). So far, she says, more than 2,300 of Walmart’s suppliers have signed on, and have reported that they’ve avoided 230 million metric tons of emissions through their own sustainability efforts in energy, packaging, agriculture, forests, waste, and packaging use and design.

One thing we’ve learned over the years, and certainly through the pandemic, is that there isn’t a trade-off between economic prosperity, social justice, and environmental sustainability. They all work together, and individual actions, even small ones, can have meaningful impact.

## Closing the loop

Dow Inc. Chairman and CEO Jim Fitterling knows the impact his company—one of the world’s largest producers of plastics and packaging—has on the environment. So in January 2019, he decided to do something about it, directing Dow to become a founding member of the Alliance to End Plastic Waste, an initiative to accelerate efforts to—as the name makes clear—end plastic waste in the environment.

That dichotomy isn’t lost on Fitterling, who joined Dow in 1984, two weeks after graduating from the University of Missouri-Columbia. He’s spent his entire career at the company, witnessing its transformation from a low-margin, commodity business into one that’s focused on higher-growth, consumer demand-driven markets. Now he wants to take Dow further into the future by transforming the business into what he calls the “most sustainable materials science company in the world.”

A tall order, for sure, but it’s one that’s driven by a detailed plan with measurable goals and a commitment to accountability and transparency, he says. Fitterling explains that Dow’s new sustainability targets launched in June this year focus on three areas: protecting the climate, stopping the waste, and closing the loop. “Climate change and plastic waste are among the biggest issues the world is facing, even in the midst of COVID-19, and our products and the technologies we’ve developed are crucial to addressing both,” he adds.

When it comes to climate change, Fitterling says that by 2030 Dow will reduce its net annual carbon emissions by 15 percent from its 2020 baseline, and the company intends to be carbon neutral by 2050—in line with the goals of the Paris Agreement. On the plastics front, it will help “stop the waste” by enabling 1 million metric tons of plastic to be collected, reused, or recycled through its own actions or through partnerships by 2030.

“Clearly, the issue that’s front and center with plastic is the amount of it that winds up in the ocean,” Fitterling says. He says Dow’s commitment is substantial but is not enough to solve the problem alone. “We’re among the 25 top producers of plastic in the world by volume,” he says. “If every one of those other companies made this kind of commitment, we’d make a massive move toward stopping the plastic waste.”

On the plastics front, Dow will help “stop the waste” by enabling 1 million metric tons of plastic to be collected, reused, or recycled through its own actions or through partnerships by 2030.

But perhaps the biggest challenge is what Fitterling calls “closing the loop.” To meet that challenge, he says, Dow will make sure that by 2035 all of its products sold into packaging applications will be reusable or recyclable. “A lot of things that people buy or use are perfectly capable of being recycled but they’re not because there’s not a collection method,” he says. “Some of them are not at all capable of being recycled, so we want to make sure the whole product line can be recycled.”

The conversation isn’t about shutting down industries. It’s about how they transition to operate in a cleaner, more sustainable and resilient way that doesn’t continue to put humankind’s future on this planet at risk.

And while Fitterling concedes that the pandemic is at the top of everyone’s mind, he views the issues of climate change and plastic waste as no less critical. “We’re in a situation where the market has slowed down, but our scientists are still working on new technologies that are more sustainable and will address these longer-term issues,” Fitterling says. “When we come out of this pandemic, I want us to keep moving ahead on everything we’ve committed to doing.”

The changes required to successfully address climate change are huge, transformative, and ultimately essential. Every industry, government, and even individual has a role to play. “The conversation isn’t about shutting down industries,” Pinner says. “It’s about how they transition to operate in a cleaner, more sustainable and resilient way that doesn’t continue to put humankind’s future on this planet at risk.”

Go behind the scenes and get more insights with “Dickon Pinner: Why sustainability must be core to the post-pandemic recovery” from our New at McKinsey blog.

## How relevant and useful is this article for you?

## Related Articles

## McKinsey on Climate Change

## COVID-19: Implications for business","{""publication_date"": ""December 11, 2020"", ""authors"": [""pressing the Escape key or activating the close button""], ""word_count"": 2235, ""reading_time_minutes"": 11}",2025-03-14 12:40:06.229197
33,Leading from the front: How DBS embraces change and empowers employees,https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/leading-from-the-front-how-dbs-embraces-change-and-empowers-employees,"several global publications, such as Euromoney, Global Finance","## Leading from the front: How DBS embraces change and empowers employees

## The State of Organizations 2023

Singapore-based financial institution DBS has been named “World’s Best Bank” by several global publications, such as Euromoney and Global Finance. It has focused on its purpose, pushed the limits of technology to shape the future of banking, and invested in creating a healthier and more diverse workforce.

As the managing director and head of group human resources, Yan Hong Lee works closely with the senior leadership team to drive the company’s strategic people agenda and empower its more than 33,000 employees to make faster, better decisions in line with the bank’s values and priorities.

We spoke with Yan Hong about how DBS fosters a distinctive workplace culture and engages and empowers its employees.

What sets DBS apart from other organizations?

## More about Yan Hong Lee, managing director and head of group human resources at DBS

Yan Hong Lee has more than 30 years of experience working in human capital management across a spectrum of industries and geographies. She has worked at General Motors, Hewlett Packard, and Citigroup on topics related to compensation and benefits, talent and performance management, learning and development, employee relations, and organizational design.

At DBS, Yan Hong drives the overall strategic people agenda by setting the direction and spearheading various functions and initiatives in the organizational growth of the bank. Under her leadership, DBS has won a number of global and regional accolades, including Regional Best Employer in Asia–Pacific by Kincentric and being named to the Bloomberg Gender Equality Index for six years running.

Yan Hong Lee: There are three special ingredients that set us apart. The first is strong and consistent leadership. Our management team has been together for a long time. They’ve set a vision, purpose, mission, and strategy for our organization and communicated it clearly through an easy-to-understand mission of “making banking joyful.” That simple mantra has helped our employees engage and actualize our goals very successfully. We also use a balanced scorecard to prioritize our efforts; it’s created from the top down and bottom up, so everyone buys in.

Next, we foster a culture that supports our purpose. DBS was created 54 years ago to help in the development of Singapore. We are here to do good things for people and make a positive difference; that is deeply rooted in our organization’s psyche. When we laid out our vision to be “the best bank for a better world,” it wasn’t something we were trying to discover or overlay onto our existing culture. At the same time, we want to make sure the culture we build has a tangible impact on our business, customers, and the community we serve.  We had to become more agile, flexible, and customer centric. We started by streamlining our matrixed organizational structure to three levels. Now we also have a horizontal organization that enables us to move faster by removing roadblocks, breaking down silos, and leveraging data more effectively.

We want to make sure the culture we build has a tangible impact on our business, customers, and the community we serve.

Our third ingredient is the way in which we deliver our employee value proposition: “Live Fulfilled: Be the Best, Be the Change, and Be the Difference.” We are committed to building the long-term careers of our people. For instance, we identified more than 8,000 employees for upskilling in 2020 so they could master new skills and have new career opportunities. We offer more than 10,000 learning programs and job exposure opportunities so our employees get to experience what it’s like to do a different job in the bank. Today, one out of four vacancies in the bank are filled by our own people. We were also ahead of the curve when we launched several flexible work arrangements in 2020, including hybrid work and a 100 percent work-from-home option for six months for employees with caregiving responsibilities or parents with newborns.

## State of Organizations: Lessons from leaders

How did you get employees on board with the transformational changes?

Yan Hong Lee: Change must start at the top, with a strong and consistent leadership team like ours, and then involve employees at all levels. People support what they help create.  We went to our employees and asked them what they needed to take the organization forward. That’s how we came up with our PRIDE! values: purpose-driven, relationship-led, innovative, decisive, and everything fun! Our PRIDE! values and behaviors are deeply embedded across all our people programs and processes, including performance appraisals, during which we evaluate employees on the “how” in addition to the “what”; during our recruitment process, through which we screen for candidates who are the right fit for our culture; promotions; and in our various leadership development programs.

We sought ways to empower our employees, trust them more, and give them more freedom to make decisions. We delegated decisions to the lowest possible level; for instance, performance and compensation decisions, which were managed by senior vice presidents and above in the past, are now made by line managers. Customer service representatives are empowered to make decisions on anything less than $200. We encourage people to experiment—just not make preventable mistakes—even if they fail. We created a safe environment that allows people to speak up and take risks. For example, during meetings, we give everyone a chance to contribute and encourage the most senior employees to speak last. We ask employees to play devil’s advocate to create space for differing opinions.

## The State of Organizations 2023

How has DBS further fostered that psychological safety and mental wellness?

Yan Hong Lee: We’ve created a lot of transparency and accessibility, which feeds into psychological safety and helps us meet our goals around DE&I [diversity, equity, and inclusion], employee engagement, mental health and well-being, etcetera. We’ve been able to do that in a way many other companies haven’t, and it has been a critical element of our success.

Employees have several opportunities to directly access senior leaders. These include a quarterly bank-wide employee town hall with a Q&A segment hosted by CEO Piyush Gupta and joined by other group management committee leaders. Senior leaders regularly visit offices across markets and host their own town halls, skip-level meetings, and small group sessions to connect with staff and understand sentiment on the ground. “Tell Piyush” is another open channel for employees to write to our CEO with any questions or ideas they have, and each question receives a personal reply.  Our CEO also hosted a series of “Candid Conversations” last year with employees across different departments and ranks to understand their experience in working for DBS.

This level of transparency has led to some fantastic results. Nearly 97 percent of our employees complete the engagement surveys we field annually, which tells us people trust that we take their opinions seriously. In the most recent survey, 91 percent told us they felt DBS was a psychologically safe environment. We were very proud of that.

This interview is part of the Lessons from leaders collection within The State of Organizations 2023 report. These conversations were conducted by members of McKinsey’s People & Organizational Performance Practice with leaders of organizations that exemplify best practices relating to the ten most significant shifts facing organizations today.

Yan Hong Lee is the managing director and head of group human resources at DBS.

Comments and opinions expressed by interviewees are their own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement.

## How relevant and useful is this article for you?

## Related Articles

## Lessons from leaders

## The State of Organizations 2023: Ten shifts transforming organizations","{""publication_date"": ""April 26, 2023"", ""authors"": [""several global publications"", ""such as Euromoney"", ""Global Finance""], ""word_count"": 1287, ""reading_time_minutes"": 6}",2025-03-14 12:40:12.865099
34,McKinsey & Company Named a Leader in the IDC MarketScape: Worldwide Retail Media Network Service Providers 2024 Vendor Assessment,https://www.mckinsey.com/capabilities/growth-marketing-and-sales/solutions/periscope/analyst-reports/mckinsey-and-company-named-a-leader-in-the-idc-marketscape-worldwide-retail-media-network-service-providers-2024-vendor-assessment,,"## McKinsey & Company Named a Leader in the IDC MarketScape: Worldwide Retail Media Network Service Providers 2024 Vendor Assessment

According to the report, “The organization's reputation as a strategic partner has played well in the building and scaling of new retail media networks. Specifically notable for the strategic management consulting firm is a focus on experienced business building with unbiased vendor and agency-agnostic solutions on both supply and demand sides of the market.”

We are thrilled to be named a Leader by IDC MarketScape for the worldwide retail media network service providers’ 2024 vendor assessment report. With the retail market slated to grow rapidly, 22 percent YoY, spending in retail and commerce media will be bigger than for all global television and streaming advertising. We believe this recognition reinforces our commitment to helping our clients reimagine  data monetization, effectively build and scale RMNs, and operationalize it, leveraging our expertise, deep bench of talent, and extensive partner ecosystem.

## Key highlights of McKinsey’s strengths from the IDC MarketScape:

Business advocacy for retail media: “McKinsey brings a highly nimble teams that are designed to accelerate internal operations and supplement any gaps with expert support and leadership until companies can operate independently. The Firm emphasizes executive management buy-in, cross-functional stakeholder alignment, capability development, and change management.”

Objective-oriented delivery: “Much of the focus for McKinsey's team is leveraging data to support model building, scenario planning, and establishing goals and objectives, including financial specifications that executives are willing to support for the RMN development journey.”

Deep expertise and resources: “McKinsey offers expediting client launches and ensuring RMN success using superlative talent. The firm has deep benches of expertise built through building numerous RMNs and experience mitigating both common and rare obstacles across clients.”

To access the report excerpt, please fill out the form below.

## How relevant and useful is this article for you?","{""publication_date"": ""November 25, 2024"", ""word_count"": 310, ""reading_time_minutes"": 2}",2025-03-14 12:40:18.568005
35,The product management talent dilemma,https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/the-product-management-talent-dilemma,,"## The product management talent dilemma

Product management remains one of the most critical roles for any company for which software is a core growth driver. Amid the growing importance of data in decision making, an increased customer and design focus, and the evolution of software-development methodologies, the role of the product manager has evolved to influence every aspect of making a product successful. As a result, CEOs and technology leaders often identify the role of product manager as one of their top talent priorities. Paradoxically, results from the McKinsey Product Management Index reveal that companies are underinvesting in this crucial talent pool.

The McKinsey Product Management Index is a survey of product managers at leading software companies to understand the capabilities and enablers that create top-performing product managers (Exhibit 1). This research surfaced systemic gaps around software-talent management; in fact, fewer than half of the product managers feel prepared to play the roles expected of them or grow into future product leaders.

## Product managers spend time across a range of critical areas and influence every part of the product

The McKinsey Product Management Index highlights the wide range of activities that demand the attention of product managers. The days and weeks of an average product manager are fragmented, which requires they be good at wearing multiple hats and prioritizing ruthlessly (Exhibit 2).

Modern product managers are involved in a wide range of decisions. For example, nearly 80 percent of product managers actively participate in design activities, over 80 percent are involved in go-to-market decisions, and nearly half are involved in pricing decisions. Additionally, 60 percent of product managers have basic analytics skills that enable them to dive into metrics and draw insights without relying on analysts.

## Talent management is a pervasive gap

Despite the central role that a product manager plays, the talent-management practices associated with this function are surprisingly underdeveloped. This gap is evident across the industry—at large software companies in Silicon Valley, early-stage tech companies, and incumbents in other industries that are becoming more software oriented.

As an example, only 35 percent of the product managers have clarity on what it would take to advance in their organizations, roughly the same number feel sufficiently coached and mentored and around 20 percent say that their companies have highly effective programs to identify and retain the best talent.

We observe several underlying drivers for this gap in talent development. First, there are limited roles that involve managing people and teams in the product organization, and unlike in engineering, companies have not consistently defined an expert track for product managers. This can prevent product managers from growing or feeling that their careers are progressing unless they are managing more people.

## Would you like to learn more about our High Tech Practice?

Additionally, the leadership development model for product management—that is, the behaviors and mind-sets that product managers are expected to display at various levels—is often poorly articulated. As a result, the only way to measure product managers is on the success of their product. Product managers tell us that they believe career progression at their companies is a matter of being in the right place at the right time to become part of a hit product rather than of doing the right things.

What is more, product management primarily requires learning on the job, but few software companies have put in place mechanisms to support this learning. Product managers often start in other functions, such as engineering, design, or marketing, and bring a specific set of skills from their previous roles. But this transitioning talent needs support to wear the multiple hats required of product managers.

Compounding the issue is the fact that product managers make up a small talent pool at most companies and hence often end up lower on the agenda of HR leaders.

## Several elements can help companies build a world-class product management talent program

There are four key levers to pull to build a world-class program for product management talent.

First, articulate the product management leadership development model for the organization. This should include a concrete, actionable description of what the organization wants and expects from its product managers. It should reflect the organization’s strategy and priorities and is not the same as the conventional list of competencies used to assess employees. For example, competency models are often expressed as innate traits, qualities, or values that product managers should have, such as “is decisive,” whereas a leadership model is expressed as concrete descriptions of desired behaviors, such as “acts to reach timely closure on decisions.” The leadership model should also articulate what it looks like to make different transitions in the organization. For example, how do the behaviors and mind-sets differ for an established, principal product manager from one who is transitioning to a director of product.

Second, provide the product managers with organizational enablers for ongoing growth and apprenticeship. There are many ways to do this, including rotational programs, regular cadence of product reviews (with focus on coaching and knowledge sharing rather than inspection), walking in the shoes of other functions (taking support calls or doing customer demonstrations, for example), conducting skip-level one-on-one sessions, providing formal mentorship programs, giving regular growth-based feedback, and so on.

## Linking talent to value

Third, leverage a field-and-forum approach to design an end-to-end learning journey. There are several principles and approaches for learning programs that we have discovered through our work with technology companies. The first is that product managers, like most adults, learn best by doing rather than by watching videos or sitting in classrooms. Additionally, product managers learn most effectively through activities that are grounded in their day-to-day context rather than through generic product management trainings. For example, we have run a product management academy program in which product managers take on ambitious projects and are coached through them on a weekly basis (Exhibit 3). It is important to note that these learning programs must be tailored to the different transitions that are critical for the individual organization. Additionally, it is important to put hard metrics on the “soft stuff” by tracking key performance indicators for these programs that measure both participation and subsequent effectiveness.

Last, hiring should be a strategic priority for senior leadership. At best-in-class software companies, senior product managers often report spending 3 to 5 percent of their time (equivalent to a half day to a full day per month) on recruiting. Doing recruiting well includes getting three elements right:

• identifying and articulating the organizations’ unique value proposition for product managers

• leveraging diverse sourcing channels (using online communities like Hacker News, sponsoring meet-ups, identifying internal talent in other functions that are likely to produce product managers, and making “acqui-hires,” for example)

• a recruiting process that is efficient, removes unconscious biases, and tests real-life skills (through cases, actual presentations on product ideas, analyses using real product data, interactions across functions to test the ability to work with engineering and design, for example)

Product management is one of the most critical talent pools for any company that is writing software but often does not get the right level of attention. Having a world-class product management function requires a multipronged approach under a holistic talent-management program. We recommend that this be a joint priority of the chief HR officer and the head of product.

## Stay current on your favorite topics

## How relevant and useful is this article for you?

## About the author(s)

Chandra Gnanasambandam is a senior partner in McKinsey’s Silicon Valley office, where Martin Harrysson is a partner, Shivam Srivastava is an associate partner, and Vaish Srivathsan is a consultant.

## Explore a career with us

## Related Articles

## Linking talent to value

## Product managers for the digital world

## An executive’s guide to software development","{""publication_date"": ""November 28, 2018"", ""word_count"": 1302, ""reading_time_minutes"": 7}",2025-03-14 12:40:25.232444
36,Medical Cost Management,https://www.mckinsey.com/industries/healthcare/how-we-help-clients/americas/medical-cost-management,,"## Medical Cost Management

## What we do

## Payment integrity to safeguard patients and other stakeholders

## Appropriate services for patients

## Pharmacy-value-chain optimization

## Care gaps and opportunities for heightened risk accuracy

## Featured capabilities

We invest heavily in developing proprietary tools, databases, and methods.

RTS: Through RTS, a special unit of McKinsey, we deliver a proven approach for transformational change to clients seeking radical, rapid, and sustainable performance improvement.

Payment-integrity artificial intelligence: Our payment-integrity solution uses proprietary analytics to enable deeper discovery of fraud, waste, and abuse.

Fraud, waste, and abuse concept library: Our library of thousands of automated payment integrity and medical management initiatives identifies immediate business value while reflecting proven implementation methods.

AI-based clinical decision support: Raise care quality and consistency and reduce lead times in your case management, care management, prior authorization, and appeals and grievances processes with our clinically-trained algorithms.

Clinical-concept benchmarking: We identify opportunity hot spots through a benchmarking solution built on our proprietary grouping methodology and designed to maximize clinical understanding and fit.

Policy benchmarking: Our policy-benchmarking solution compares variations between an organization’s policies and those of its peers to identify opportunities for collaboration to drive improved clinical outcomes for patients.

## Examples of our work

## Portfolio ideation

## Medical-cost management

## Reduction of fraudulent claims

## Featured insight

## Using machine learning to unlock value across the healthcare value chain

## Featured experts

## Sameer Chowdhary

## Partner, Dallas

## Gunjan Khanna

## Senior Partner, Pittsburgh

## Mahi Rayasam

## Partner, Ohio - Columbus

## Prashanth Reddy

## Senior Partner, New Jersey

## How we help clients

• Digital Strategy & Transformation

• Healthcare Innovation

• Medical Cost Management

• Performance Transformation

• Provider Performance

• Provider Revenue Excellence

## Connect with our Healthcare Practice","{""publication_date"": ""August 2, 2018"", ""word_count"": 296, ""reading_time_minutes"": 1}",2025-03-14 12:40:31.739811
37,Medical Cost-Management,https://www.mckinsey.com/industries/healthcare/how-we-help-clients/asia/medical-cost-management,,"## Medical Cost Management

## What we do

## Payment integrity to safeguard patients and other stakeholders

## Appropriate services for patients

## Pharmacy-value-chain optimization

## Care gaps and opportunities for heightened risk accuracy

## Featured capabilities

We invest heavily in developing proprietary tools, databases, and methods.

RTS: Through RTS, a special unit of McKinsey, we deliver a proven approach for transformational change to clients seeking radical, rapid, and sustainable performance improvement.

Payment-integrity artificial intelligence: Our payment-integrity solution uses proprietary analytics to enable deeper discovery of fraud, waste, and abuse.

Fraud, waste, and abuse concept library: Our library of thousands of automated payment integrity and medical management initiatives identifies immediate business value while reflecting proven implementation methods.

AI-based clinical decision support: Raise care quality and consistency and reduce lead times in your case management, care management, prior authorization, and appeals and grievances processes with our clinically-trained algorithms.

Clinical-concept benchmarking: We identify opportunity hot spots through a benchmarking solution built on our proprietary grouping methodology and designed to maximize clinical understanding and fit.

Policy benchmarking: Our policy-benchmarking solution compares variations between an organization’s policies and those of its peers to identify opportunities for collaboration to drive improved clinical outcomes for patients.

## Examples of our work

## Portfolio ideation

## Medical-cost management

## Reduction of fraudulent claims

## Featured insight

## Using machine learning to unlock value across the healthcare value chain

## Featured experts

## Sameer Chowdhary

## Partner, Dallas

## Gunjan Khanna

## Senior Partner, Pittsburgh

## Mahi Rayasam

## Partner, Ohio - Columbus

## Prashanth Reddy

## Senior Partner, New Jersey

## How we help clients

• Digital Strategy & Transformation

• Healthcare Innovation

• Medical Cost Management

• Provider Performance

## Connect with our Healthcare Practice","{""publication_date"": ""August 2, 2018"", ""word_count"": 289, ""reading_time_minutes"": 1}",2025-03-14 12:40:37.108607
38,Financial data and markets infrastructure: Positioning for the future,https://www.mckinsey.com/industries/financial-services/our-insights/financial-data-and-markets-infrastructure-positioning-for-the-future,,"## Financial data and markets infrastructure: Positioning for the future

Financial data and markets infrastructure (FDMI) companies provide data, infrastructure, and technology services to the financial industry. This segment of the financial services industry comprises exchange groups and trading venues as well as providers of post-trade and securities services, data and analytics, and financial technology and workflow. It is one of the fastest-growing financial services segments.

## About the authors

This article is a collaborative effort by Anutosh Banerjee, Laura Heaphy, Matthieu de Vergnes, and Rushabh Kapashi, with Promila Gurbuxani, representing views from McKinsey’s Financial Services Practice.

The global FDMI industry has had an impressive few years, outperforming the financial services sector as a whole. From January 2019 to December 2023, FDMI delivered a 17 percent CAGR in TSR, compared with 10 percent for financial services.1Facts and figures cited in this article come from McKinsey’s analysis of data from its FDMI and corporate and investment banking (CIB) revenue pools, its value intelligence and performance growth data, the global market intelligence business IDC, the financial markets platform Dealogic, press searches, and expert interviews.

Several factors contributed to this performance, including the rise of the buy side as a core customer segment, the continued increase in passive investing, and evergreen demand for data and analytics. These and other tailwinds propelled outsized demand for FDMI solutions, and providers rose to the challenge. Revenues grew at 8 percent CAGR from 2018 to 2023, and M&A activity surged, accounting for an aggregate of $185 billion in deal value during the same period.

However, the future likely holds several sources of disruption. Big Tech is expanding beyond technology and cloud provision, partnering with incumbents to address the core verticals in the value chain. Sell side revenues have continued to decline as a share of overall capital market revenues, and buy side revenue growth is slowing. Nonbank market makers are emerging as a new segment to serve, while private markets have become too large to ignore. Finally, generative AI is enabling a step change in innovation, with client-facing applications such as virtual research assistants going from pilot to rollout within a few months. Combined, these factors are creating an inflection point for the sector.

## FDMI archetypes

• Exchanges and trading venues are platforms where financial instruments are bought and sold. Exchanges are centralized, highly regulated markets that ensure transparency and liquidity for trades, which typically involve stocks, bonds, and commodities. Trading venues, a broader category, include private exchanges, interdealer brokers, multilateral trading facilities, alternative trading systems, electronic communication networks, and over-the-counter markets, offering varying levels of transparency and trading mechanisms.

• Post-trade service providers manage the processes following the execution of a trade, ensuring its successful completion and settlement. These services include clearing, where the provider acts as an intermediary to guarantee the trade, and settlement, where the actual transfer of securities and funds occurs.

• Securities services providers offer a range of services that support the life cycle of securities transactions. These services include custody, which safeguards and manages clients’ financial assets, and fund administration, which involves middle- and back-office operations and processes for investment funds. Additionally, these providers offer clearing and settlement services to ensure the accurate and timely exchange of securities and payments between parties.

• Data and analytics providers offer comprehensive financial data, tools, and analytical services to support decision-making throughout the financial industry. They aggregate and process vast amounts of market data, economic indicators, and financial metrics, providing real-time insights and historical analysis. Their platforms often feature advanced functionalities such as predictive analytics, risk assessment, and portfolio management tools.

• Financial workflow and technology providers offer specialized software and services that streamline and automate the various processes within financial institutions, including solutions for trading, such as order and execution management systems, risk management, compliance, and client relationship management.

In this new environment, FDMIs cannot rely on the strategies they used in the past to sustain their rapid growth and TSR. They will need to find new sources of value and change their playbooks to address two things at once: strengthening the core to improve the performance of existing businesses and innovating beyond the core to unlock new adjacencies and value pools.

## The FDMI industry

Financial data and markets infrastructure is one of the fastest-growing segments of financial services. Companies in this segment provide data, infrastructure, and technology to the financial services industry. The five main archetypes of provider are exchanges and trading venues, post-trade services, securities services, data and analytics, and financial workflow and technology (see sidebar “FDMI archetypes”).

## FDMI verticals

• Trade execution and post-trade services include activities related to trade execution and listings; post-trade services; asset servicing, including custody and fund administration; and other securities services, such as securities lending and issuer services.

• Information services include activities related to markets and trading data; pricing, reference, and valuation data; indexes, benchmarks, and corporate ratings; portfolio management and analytics; news and research; and data and analytics on emerging areas, including cybersecurity, sustainable investing, digital assets, and private markets.

• Technology services underpin all functional services for finance, including trade life cycle management and ancillary services, such as financial and regulatory reporting. They comprise application-level solutions—including order management systems, trade processing, and clearing and settlement systems—and full-stack solutions running in the cloud or hosted data centers.

FDMI activities comprise three primary verticals (see sidebar “FDMI verticals”). Many providers operate in two or more of these. For instance, exchange groups may offer post-trade services and data and analytics alongside their traditional trading businesses.

## FDMI has had an excellent five years

Global FDMI revenues have grown at an 8 percent CAGR since 2018 and exceeded $278 billion in 2023. From January 2019 to December 2023, the FDMI segment’s TSR was 17 percent, 70 percent higher than that of the broader financial services sector.

The largest vertical in 2023 was trade execution and post-trade services, which accounts for 42 percent of total FDMI revenues (Exhibit 1). Technology services accounts for 30 percent, and information services 28 percent.

Trade execution and post-trade services experienced 4 percent annual growth over five years ending in 2023, with revenues reaching $117 billion (Exhibit 1). Its largest revenue segment is asset servicing, including custody and fund administration, with $47 billion, which grew by 2 percent a year over the period. The fastest-growing segment in this vertical is post-trade, with 8 percent annual growth to $24 billion, due to higher volumes and regulators’ emphasis on the importance of clearinghouses.

The information services vertical represents a $77 billion revenue pool, with 10 percent annual growth from 2018 to 2023. Democratization of alpha—the increasing accessibility of investment strategies and tools to individual investors—has obliged the buy side to pursue more complex strategies and demand increasingly sophisticated data. Also, the emergence of new asset classes, such as private markets and digital assets, and risk areas, such as cybersecurity, has created new data demands from investors, banks, and others. The emerging-areas segment grew the fastest, at 19 percent per year, over the period.

Technology services, the second-largest FDMI vertical, grew at 11 percent over the period, reaching $84 billion in revenue. RegTech—regulatory technology for monitoring, reporting, and compliance—was the second largest revenue contributor, with $26 billion, driven by cost pressures throughout the industry and rapidly evolving regulatory requirements for technical risk management and cyber resiliency. Heightened complexity in the regulatory environment drove financial institutions to further outsource middle- and back-office functions, benefiting FDMI providers.

## Valuations are primarily a result of revenue growth

To explain FDMI’s strong performance, we analyzed shareholder returns for 32 publicly listed FDMI providers. This allowed us to determine the importance of intrinsic value drivers, such as profitability and revenue growth. Our analysis shows that revenue growth was central to shareholder returns. For most types of companies, it has been the most critical driver (Exhibit 2). However, investors also rewarded data and analytics providers as they expanded their business models to include recurring revenue models, such as data subscriptions, and advanced into new growth areas, such as private markets, climate, and cybersecurity. Profitability also was critical to sustain shareholder returns.

## Disruptions are creating an inflection point for the sector

Several industry-disrupting trends have emerged in recent years. For example, providers are deepening their presence in areas where they expanded, and M&A is moving to more targeted niche deals. Buy-side growth is slowing, Big Tech is expanding beyond cloud and technology provision, private markets are becoming too large to ignore, and generative AI (gen AI) is accelerating innovation.

## Incumbents are expanding and deepening their presence along the value chain

Over the past ten years, FDMI providers have diversified into adjacencies along the value chain. Exchanges, for example, have expanded into pre-trade services to become data aggregators, shifting their revenue from transactions tied to trading volumes and toward subscriptions, such as data licensing, which command higher-valuation multiples. Exchanges are reorganizing their business lines accordingly, leading to more transparent reporting of these revenues. Similarly, financial technology and workflow providers have expanded their coverage along the value chain, moving into settlement and reconciliations.

While expansion along the value chain is expected to continue, providers will likely first look to deepen their reach in areas they have already expanded into. For instance, exchanges may further embed themselves as core providers of data and services to make themselves indispensable, claim a greater share of the value pools, and exploit the full value of their expansions. M&A served as the primary pathway through which FDMI providers diversified over the six years to 2023, with $185 billion in deal value. M&A activity peaked in 2021 and 2022, with $107 billion in deal volume for the two years combined (Exhibit 3).

Since the 2021–22 peak, which included the acquisition of several large FDMI assets, acquirers have focused on integration and realizing the value of their investments. M&A activity is expected to shift from large deals to targeted acquisitions for FDMI providers seeking niche capabilities.

## Big Tech is entering the infrastructure landscape

Big Tech companies have entered the FDMI sector over the last few years by partnering with incumbents. FDMI providers use these partnerships as a path to modernizing and operating as digital natives. Big Tech companies partner because they recognize incumbent providers’ deep expertise and track record and FDMI clients’ trust in them. Collaborations are increasingly strategic, combining revenue opportunities with infrastructure and cloud consumption deals. These new market participants are currently partners but may, over time, become competitors.

## Fintechs are emerging, and brokers are expanding along the value chain

FDMI fintechs are growing in size and number and, in some cases, becoming acquisition targets for incumbents. Funding in capital market fintechs more than doubled between 2018 and 2022, from $1.3 billion to $2.9 billion. From 2020 to November 2024, there have been 215 deals involving fintechs in FDMI.2Includes deals where FDMI providers purchased a controlling or a noncontrolling interest.

Meanwhile, established brokers managing the interface with end clients are expanding further into the trading value chain. Acquisitions of crypto exchanges by certain brokers and the growth of customer-facing prediction market platforms are a new, longer-term threat to exchanges and venues. Because they manage the client interface, these brokers could acquire or develop the technology to provide integrated trading offerings.

## Growth of the buy side customer segment is slowing

Since the 2008 financial crisis, buy side capital market revenue has grown faster than sell side revenue. Between 2015 and 2023, the buy side’s share of revenue increased from 51 percent of total revenue to 60 percent, benefiting from growing assets under management (AUM) and the rise in passive investing. This growth increased demand for the FDMI sector, which responded with buy side-centric solutions.

However, the growth rate of buy side revenue has slowed from 8 percent between 2015 and 2018 to 5 percent from 2018 to 2023 (Exhibit 4). This slowdown is likely to affect FDMI providers, which will need to find new avenues of growth.

## Nonbank market makers are becoming an important customer segment

Nonbank market makers, with lower regulatory constraints and unencumbered by legacy technology stacks, are taking share of the dealer market in multiple asset classes. For example, in 2023, the top four nonbank market makers accounted for 48 percent of US off-exchange equity volumes, compared with 12 percent for the top four banks. FDMI providers can look holistically at these fast-growing businesses and the products and services they can customize and offer them.

## Private markets are a growth area for FDMI providers

Global private markets AUM has grown at 14 percent CAGR over the past ten years. We expect this trend to continue, driven by increased participation from retail investors across all private markets asset classes, and increased allocations from the institutional segment.

As they grow, private markets are becoming more complex. The introduction of new asset classes and fund strategies and the creation of new structures like special-purpose vehicles are making processes for fundraising, investing, and fund operations more difficult to navigate. Also, multi-asset and multiproduct platforms are becoming the norm as general partners (GPs) seek to broaden their offerings and grow. However, as these platforms grow, GPs must manage the added complexity of product, asset class, and geographic expansion. This leads to support functions becoming a larger share of operations, inducing diseconomies of scale for the largest managers. To address this challenge, GPs are actively exploring outsourcing their middle- and back-office functions to fintech providers with more scalable infrastructures.

## Generative AI is accelerating the pace of innovation

FDMIs have led the adoption of AI for several decades, especially for trading algorithms and portfolio insights. Large language models, with their ability to handle unstructured data, will expand the impact of AI for FDMIs, particularly for tasks that were difficult to digitize in the past because of their low process frequency or uniqueness.

New gen AI applications are focused on engineering (for example, coding copilots), corporate use cases such as virtual HR assistants, and select business and compliance use cases, including document summarization. FDMIs are creating value with many applications piloted over the last 12 to 18 months, including the following:

• Several large securities services platforms are modernizing legacy code much more quickly than was possible without gen AI.

• One leading data and analytics provider has developed a private gen AI language model, trained on its proprietary documents, to deliver research and reports to its users, giving them vastly improved access to market insights.

• Another FDMI business has partnered with a Big Tech company to launch a virtual research assistant that supports employees globally by integrating proprietary data, analytics, and research insights.

Gen AI initiatives will likely have a more significant P&L impact as they expand to automate corporate actions, client services, and operations.

We have not found a single dominant use case that would carry a substantial business case. Rather than pursue just one, companies would do better to deploy an internal platform that features the technology, data access, and the required controls and governance to scale many small-to-medium-size gen AI use cases in a regulated FDMI environment.

As the deployment of use cases grows, gen AI will have impacts on work and the workforce. This may require that FDMI providers adapt capacity and acquire new capabilities, such as software engineering, and new skills, such as prompt handling, distributed among more people.

## The focus is shifting in the realm of digital assets

Over the last few years, the focus of FDMI providers moved from crypto to the underlying technology of tokenization, the process of issuing a digital representation of an asset on a blockchain. A previous McKinsey report indicates that tokenized market capitalization could reach $2 trillion in 2030, excluding cryptocurrencies.3Anutosh Banerjee, Julian Sevillano, and Matt Higginson, “From ripples to waves: The transformational power of tokenizing assets,” McKinsey, June 20, 2024. With this focus, several FDMI providers are building solutions to enable the tokenization of specific assets. Given the nascency of the technology and the lack of institutional-grade infrastructure, providers need to partner and collaborate to drive progress and encourage adoption.

## Positioning for the next phase of growth

In light of these disruptions, FDMI providers should follow a two-pronged approach to sustain their growth and TSR: strengthening the core and investing beyond the core.

## Strengthening the core

To improve the operating performance of their existing businesses, FDMI companies should focus on three activities: continuing to build resiliency into their infrastructure, exploring the adoption of a product operating model, and elevating their focus on commercial excellence.

## Building resiliency into infrastructure

Technology and operational disruptions at FDMIs pose a systemic risk to the flow of critical financial information and transactions. Because of the interconnectedness of global financial systems, disruptions in one region or infrastructure provider can quickly cascade, affecting markets worldwide and disrupting international trade and banking operations, potentially causing widespread economic instability. Increases in transaction volumes coupled with rapidly shrinking timelines (for example, real-time settlement) have or will put additional stress on architectures at FDMIs. Companies with vulnerable architectures can strengthen them by elevating the role of the office of business resilience and adopting three principles:

• Take a business-backed, end-to-end customer experience lens. Typically, organizations improve resilience by remediating and defining service levels for critical applications and infrastructure in isolation. A better approach is to take a business-backed view to understand customer journeys and solve for end-to-end customer experiences.

• Design for “no trade-offs” and move from reactive to proactive. Build IT solutions without compromising scale, stability, or security. Take a defensive engineering mentality and partition components or resources into separate compartments to limit the impact of failures or overloads in one area on the rest of the system. Anticipate issues to build solutions that are future-proof. Practice techniques such as pre-mortem analysis and war-gaming.

• Create a culture of reliability across the organization. Strengthen automation and reliability engineering capabilities centrally and among infrastructure and application teams. Adopt advanced engineering practices such as service-level indicators and objectives, error budgets, graceful degradation, fault-tolerant patterns, and robust observability to ensure system resilience and full-life-cycle ownership of code.

## Adopting a product operating model

Many organizations ask whether a more modern enterprise operating model, one that more closely resembles that of a digital native, is better suited to today’s opportunities and challenges. Among modern operating models, the product operating model is most relevant for institutions that manage operations and technology-intensive businesses at scale and is particularly well suited to FDMIs. The product operating model brings together business, technology, operations, and other relevant functions (such as risk, legal, marketing, and distribution) across the enterprise.

There is no textbook product operating model; every institution that has adopted the model has tailored it to its own strategy, context, and priorities. However, there are three common themes. The first is the creation of “products” with end-to-end accountability for the delivery of client value and a discrete P&L. The second is platforms, which bring together similar technology assets, people, and funding to deliver scale through standardization and reuse. The third is practices that include groups of employees with the same specialization, who are managed together to ensure their professional development with agile ways of working; small, cross-functional pods or teams; quarterly and eventually sprint-based prioritization; a passion for customer and employee experience; an emphasis on fast delivery; and simplified project funding.

The product operating model allows organizations to move with greater speed, efficiency, and simplicity. Leading companies have seen improvements in several performance areas: time to market shrinking up to 70 percent, employee engagement scores rising 20 percent, costs declining 20 percent, and the company becoming a leading destination for top talent.

## Elevating the focus on commercial excellence

FDMI providers are often legacy incumbents with entrenched market positions and well-established client relationships. As competition increases within the sector—for instance, from Big Tech and fintechs—it is crucial to have a sales strategy that can manage volume and deliver quality interactions.

To optimize sales coverage, FDMI providers should consider self-serve digital channels and inside sales teams to address standard queries, serve long-tail clients efficiently, and free up capacity for the most valuable accounts. Providers can also serve new customer segments by building inside sales teams comprising junior personnel who operate remotely at half the cost of in-person sales teams.

In addition, FDMI providers should develop comprehensive segment-focused coverage and offerings—for example, by combining lines of business offerings for a defined end segment. This can be an effective way to acquire new clients, deepen relationships with existing clients, and better retain both.

We have seen institutions improve the efficiency of their sales teams by 20 to 30 percent by leveraging AI and gen-AI-enabled automation, giving them more time for client-facing activities. These tools can support account planning, for instance, by retrieving company details, designing sales campaigns, and creating collateral sales materials. In addition, AI can improve the quality of client interactions by providing an overview of publicly stated priorities, customizing experiences, automating repetitive tasks, analyzing customer sentiments, and more.

## Investing beyond the core

FDMI providers must simultaneously drive innovation outside the core. There are multiple ways to do this; two of the most promising are to build new ecosystems of services and develop a leading position in private markets.

## Building new ecosystems of services

The FDMI industry is modernizing, and the slowdown in the core as a result of ongoing pricing pressure is driving further innovation. For the mid-to-long term, players should explore new asset classes, opportunities in data and analytics, and integration with a wide range of ecosystems. These include upstream integration into users’ workflows, orchestration of end-to-end technology platforms, and creation of services for sectors and asset classes such as commodities and foreign exchange.

Upstream integration allows providers to better assure incoming transactions rather than waiting for upstream users to initiate them. It also makes them more customer-centric, viewing clients individually rather than monolithically and offering tailored client propositions.

FDMI providers are also beginning to play the role of orchestrator to resolve clients’ disjointed legacy platforms, particularly for buy side businesses with multiple service providers and fragmented market infrastructure solutions. FDMI’s end-to-end platforms provide best-in-class open-source technologies that can differentiate and offer seamless plug-and-play service that can provide integration beyond basic safekeeping services. FDMI providers that play the orchestrator role have an appetite for vertical and horizontal expansion in collaboration with partners including data providers, distribution platforms, technology players, and other market infrastructure providers.

FDMI providers can also create interconnected services so users can fulfill various needs in one integrated experience in areas such as commodities, foreign exchange, and real estate. This ecosystem approach is an emerging lever for differentiation; it can avoid commoditization and increase user engagement.

To build these new ecosystems, FDMI players will need to invest in technology that can deliver a wide range of services, seamlessly integrate with client systems, and make their operating model client-centric.

## Developing a leading position in private markets

FDMI providers need a strategy to address the fast-growing segment of alternative asset managers. With growing assets under management, these companies have shown an increased appetite for outsourcing parts of their middle- and back-office functions to enable scalable economics. A McKinsey survey of GPs in private equity revealed that the range of AUM for which insourcing these functions is economical is tightly constrained to $8 billion to $10 billion.

To provide the scalable infrastructure needed by these increasingly large funds, FDMI providers could build off their existing capabilities in public markets. For example, they could support GPs in their investment life cycle with workflow, data, and limited-partner reporting, as they have supported the buy side in public markets. They could also facilitate institutional and retail participation in alternatives. Some participants have developed private markets exchanges to liquefy holdings for issuers and improve investor relations.

Leading fintech platforms have also emerged to provide a connection for retail and high-net-worth investors. For instance, accredited investors in the United States can partner with large alternatives managers to co-invest in an asset or company without directly investing in the fund.

Beyond sponsor needs, FDMI providers could also explore how to serve the underlying assets of businesses such as private-equity portfolio companies. As holding periods increase, GPs have a growing influence on the operations of their assets and are looking for new ways to extract value.

The confluence of market trends, technological advancements, and evolving needs has led to an inflection point in the FDMI sector. Also, geopolitical stresses are likely to bring about more volatility in financial assets. There is now a unique opportunity for FDMI providers to grow beyond their core. By building resilience, embracing innovation, expanding into new territories like private markets, and offering new ecosystems of services, FDMI players can not only secure their future but also shape the future of the broader capital markets industry.

## How relevant and useful is this article for you?

## About the author(s)

Anutosh Banerjee is a partner in McKinsey’s London office; Laura Heaphy and Matthieu de Vergnes are partners in the New York office, where Rushabh Kapashi is a senior partner; and Promila Gurbuxani is a senior expert in the Delhi office.

The authors wish to thank Alexa Wright, Andrew Banhidi, Arun Gundurao, Clara Aldea Gil de Gomez, Daniele Chiarella, Doran Schifter, Georgina Coleman, John Spivey, Jordan Thomson, Karim Thomas, Lama Sabbagh, Mariann Lysholm, Milan Mitra, Neira Hajro, Phil Tuddenham, Priyanth G. Krishnan, Roger Rudisuli, Sanchit Aggrawal, Stefan Schorsh, and Tim Parker for their contributions to this article.

## Explore a career with us

## Related Articles

## The data and analytics edge in corporate and commercial banking

## Global Banking Annual Review 2024: Attaining escape velocity

## From ripples to waves: The transformational power of tokenizing assets","{""publication_date"": ""January 28, 2025"", ""word_count"": 4291, ""reading_time_minutes"": 21}",2025-03-14 12:40:44.020392
39,From engines to algorithms: Gen AI in automotive software development,https://www.mckinsey.com/features/mckinsey-center-for-future-mobility/our-insights/from-engines-to-algorithms-gen-ai-in-automotive-software-development,,"## From engines to algorithms: Gen AI in automotive software development

Companies in the automotive and industrial sectors are rewiring to become software-enabled enterprises. As in-vehicle software emerges as a critical differentiator, companies have started to reevaluate the role of software and overhaul their development approaches. Today, software serves as the backbone for advanced features and safety-critical functions while enhancing operational efficiency and propelling innovation. But software can also introduce organizational challenges, because underdeveloped software capabilities can result in start-of-production delays and budget overruns.

## About the authors

This article is a collaborative effort by Dominik Hepp and Martin Harrysson, with Lukasz Maslaniec, Mateusz Wozniak, and Michael Amroudi, representing views from McKinsey’s Automotive & Assembly Practice.

Generative AI (gen AI) is disrupting the ongoing software transformation by introducing new opportunities and challenges. Companies are still in the process of changing their software operating models, for example, by setting up and maturing dedicated software development and delivery units while adapting the collaboration model with their suppliers. Additionally, organizations are actively recruiting new talent with specialized software expertise while simultaneously reskilling their existing hardware-focused workforces to adapt to software-centric roles. As gen AI advances, organizations must be able to capture the substantial productivity potential reported across various domains while balancing the nondeterministic challenges of this technology and the criticality and security requirements of their systems.

A recent McKinsey survey of automotive and manufacturing executives revealed that more than 40 percent of respondents are investing up to €5 million in gen AI research and development, and more than 10 percent are investing more than €20 million.1“Automotive R&D transformation: Optimizing gen AI’s potential value,” McKinsey, February 9, 2024. Leading automotive and industrial companies have become even stronger competitors by effectively experimenting with gen AI and leveraging its potential for software-defined hardware.2Ali Rizvi, Ani Kelkar, and Philipp Kampshoff, “Software-defined hardware in the age of AI,” McKinsey, forthcoming. The gap between top performers and others is likely to widen further as these companies implement gen AI effectively and derive value from it.

This article discusses the potential for gen AI to improve software development processes in the automotive and industrial industries, as well as the change management and strategic approaches required to properly integrate it into current procedures. The insights presented are drawn from McKinsey’s work with leading automotive and industrial organizations, including initial gen AI impact pilots, organization-wide rollout strategies, and holistic R&D transformations.

## Overcoming challenges to enhance software operating models

## About the McKinsey Center for Future Mobility

These insights were developed by the McKinsey Center for Future Mobility (MCFM). Since 2011, the MCFM has worked with stakeholders across the mobility ecosystem by providing independent and integrated evidence about possible future-mobility scenarios. With our unique, bottom-up modeling approach, our insights enable an end-to-end analytics journey through the future of mobility—from consumer needs to a modal mix across urban/rural areas, sales, value pools, and life cycle sustainability.

In the automotive and industrial sectors, gen AI can transform how software is created and used, greatly increasing productivity across the software development life cycle. Software engineering is expected to be the area most affected by gen AI.3“Where business value lies,” in The economic potential of generative AI: The next productivity frontier, McKinsey, June 14, 2023. It could boost the productivity of developers by reducing the time they spend on various software engineering activities, such as generating initial code drafts, correcting or refactoring code, and creating new system designs. These capabilities have led to rapidly rising adoption of gen AI, with most companies currently experimenting with at least one gen AI application.

Succeeding with gen AI requires more than just technology, however; it necessitates the right operating model. Executives perceive significant barriers to implementing and rolling out gen AI, largely due to the organizational and cultural changes required to integrate gen AI into existing operating models. The value of gen AI will not be realized by merely adding new gen AI tools—it hinges on an organization’s ability to adapt to new ways of working and embrace a transformative operating model. For example, if an organization is underperforming in software development, gen AI alone is unlikely to resolve the issue.

In addition, applying gen AI to critical embedded software is often perceived as more challenging than traditional software development. To embed gen AI, for example, organizations have to maintain a highly optimized code that works within their computational resource constraints, ensures low latency, and interacts with hardware interfaces. In safety-critical applications such as automotive, software must undergo extensive testing and validation to meet safety standards. Ensuring that gen AI meets stringent certification processes, is checked and approved by multiple reviewers, and uses specific languages and models requires additional effort and oversight.

While gen AI can support software transformations, it is not a perfect solution; it cannot solve all the software challenges an organization might face. Developing the wrong product will not lead to innovation or customer satisfaction, and without an adequate tool chain and database, the applicability of gen AI will be significantly limited. Previous McKinsey research outlines what successful software operating models at automotive companies should look like.4“When code is king: Mastering automotive software excellence,” McKinsey, February 17, 2021. With the introduction of gen AI, the steps for properly developing and embedding software take a new shape. Gen AI has important implications for each dimension of the software operating model (Exhibit 1).

How can gen AI help with product management and defining requirements? It’s important to consider how gen AI can help product managers define software requirements for developers. It should reduce complexity, increase modularity, and ensure development of the right features for the customer.

How can gen AI be embedded in the software development process? Considering how gen AI can be embedded into software development processes is important in incorporating it at scale. Selecting the right use cases for gen AI, with consideration for the technology’s limitations and the criticality of specific systems, is essential.

What capabilities are required to use gen AI end to end along the software development cycle? To manage the risks of applying gen AI in safety-critical software, investing in capability building is essential. In addition, effective training programs can address concerns about gen AI limiting productivity in the automotive and industrial sectors.

What tool chain is required to maximize value from gen AI in software development? Companies can decide what tools are required to maximize the value from gen AI in their software development. Due to the complexity of embedded systems in the automotive and industrial sectors, gen AI tools and models require customization, and fewer off-the-shelf solutions are applicable.

Ensuring that the processes, capabilities, and tools are in place to help usher in the gen AI transformation is imperative. Organizations that neglect these foundations may drive individual, isolated use cases without prioritizing and aligning them across the business, ultimately hindering their progress or creating safety risks.

## Mastering software development with gen AI

Integrating gen AI can be an opportunity for automotive and industrial companies to advance their software development capabilities. The automotive and industrial sectors can accelerate transformations across operating models, tooling, process changes, ways of working, and upskilling with these tools. They can also greatly increase productivity, helping organizations close the gap between the complexity of new digital tools and ways of working while managing costs, supporting talent, and improving innovation. What’s more, these advancements can improve customer experience by, for example, offering more sophisticated voice assistants that enhance the human–machine interface, bolstering safety through advanced driver-assistance systems, and elevating the overall driving experience with increased personalization.

## How gen AI can support product managers

Gen AI can support product managers (PMs) in various use cases. It is especially helpful in supporting PMs as they refine business case assumptions, generate objectives and key results or KPIs, or compile a summary of new feature development. It’s also adept at helping to create product artifacts, including summarizing product requirement feedback from technical experts, drafting user stories, and creating and refining press releases, frequently asked questions, and product requirement documents.

In the development of safety-critical embedded systems, gen AI can significantly assist PMs by ensuring comprehensive coverage of safety aspects. For example, gen AI can analyze regulatory standards and historical project data to automatically generate detailed and compliant requirement specifications, acting as a quality controller to ensure that no critical element is overlooked. Advanced models can parse and understand complex regulatory documents, aiding PMs in meeting safety requirements. Additionally, gen AI can automate the creation of detailed documentation, continuously checking for compliance throughout the development process, flagging any deviations from safety standards, and suggesting corrective actions. It is important that rigorous validation and verification processes are employed, including human-in-the-loop systems for which AI outputs are reviewed before being acted upon.

We estimate that PMs could save between 10 and 30 percent of their time on these tasks when they get access to the right gen AI tools and receive proper training. The most impactful use cases can achieve a time savings of 40 percent or more. One of our recent surveys of PMs tested the time-saving potential of gen AI in ten different use cases. The results indicated that PMs with access to gen AI could save up to 39 percent of the time they take to create and refine product requirements and user stories. Survey respondents also indicated a productivity improvement of 44 percent when using gen AI with quality assurance measures, such as creating and automating tests to then enhance efficiency and code reliability.

## Where gen AI can advance the software development processes

Once PMs outline the requirement definition of gen AI use cases, developers can integrate these tools across the whole software development life cycle (Exhibit 2).

Incorporating gen AI into software development processes could save developers substantial time when innovating in the automotive and industrial sectors.

In the beginning of the software development life cycle, developers can use gen AI to understand business requirements and design architecture. For embedded systems, such as those in automotive control units or industrial machinery, the design should capture functional requirements while adhering to stringent hardware constraints and real-time performance needs. Gen AI analyzes extensive data sets to generate insights, helping developers capture and translate business needs into technical specifications more accurately, which reduces miscommunication. It assists in creating multiple software architecture designs, generating draft diagrams, and offering market solution comparisons, which speeds up the design phase and ensures robust, scalable architectures that meet the specific demands of embedded environments.

In the development stage, gen AI helps to write, translate, refract, and document code. It can draft code, autofill existing code, generate code from pseudocode prompts, and accelerate the coding process. For critical embedded software, such as advanced driver-assistance systems, gen AI can produce code optimized for limited memory and processing power while ensuring proper hardware interfacing; however, its impact in these settings tends to be more limited. Gen AI also translates code between programming languages, aiding in the modernization of legacy systems and enabling developers to address backlog initiatives without rewriting existing code bases. It automates the refactoring process by identifying and improving code areas, enhancing maintainability and readability while reducing technical debt. Moreover, gen AI automates the creation of documentation, including user manuals, API documentation, and inline comments, ensuring consistency and accuracy for easier comprehension by new developers.

Last, when it comes to finalizing products, gen AI can help write unit, integration, and acceptance tests. Note, though, that testing can also be an initial step in methodologies such as test-driven development, in which tests guide the coding process from the outset. For embedded systems, gen AI can help create hardware-in-the-loop and software-in-the-loop test environments to simulate real-world operating conditions, which can augment real-world data to reduce the amount of data that needs to be collected, further enhancing the testing process. In addition, it can generate test cases that consider hardware interactions, timing constraints, and real-time performance, identifying high-priority events and anomalies. These tests provide performance insights that enhance the reliability and stability of software applications, which is necessary for embedded systems that often operate in mission-critical environments. In such settings, gen AI can also assist in automating compliance testing to meet industry standards and regulatory requirements, further ensuring the robustness and safety of the final product.

Across use cases, companies need to manage the risks associated with using gen AI in critical and safety-relevant systems. While powerful, gen AI is still prone to nondeterministic behavior and hallucinations, which can pose significant risks in safety-critical applications. Nondeterministic behavior refers to the AI’s tendency to produce different outputs despite being given the same inputs, which can lead to unpredictable and unreliable results. Hallucinations occur when the AI generates information that appears plausible but is factually incorrect or nonsensical. To manage this risk, companies can implement redundancy and cross-validation mechanisms, in which multiple AI models independently analyze the same input and their outputs are compared to ensure consistency. In addition, companies should employ human-in-the-loop systems in which AI outputs are reviewed and validated by experts.

Across use cases, our research revealed that tasks requiring writing and understanding code benefit most from incorporating gen AI into the integrated development environment and the ability to work with the code base. First pilots for writing, translating, and documenting code revealed time-saving potential of up to 40 percent. Conceptual tasks that involved using gen AI as a brainstorming partner or assistant (in understanding business requirements, for example) also see time savings, although less significant, with early pilots indicating an impact potential of between 15 and 30 percent.

## The capability building required to use gen AI along the software development cycle

Recent McKinsey research outlines the array of new skills engineers and product managers will need to master to be successful with gen AI.5“The gen AI skills revolution: Rethinking your talent strategy,” McKinsey Quarterly, August 29, 2024.

To capture the full potential of gen AI, it is important that users are properly trained. Capability-building programs should cover foundational gen AI skills, such as prompt engineering techniques, setting context, and risk management, and should include practice opportunities with use cases, such as code generation, reviews, and documentation. Executives are often concerned about data protection and related legal issues when using gen AI, so these issues need to be proactively addressed by an adequate risk-management process for introduction and usage. Trainings should also cover topics that are more advanced, such as code translation and refactoring. For embedded software development, these trainings should emphasize the unique constraints and requirements of embedded systems, such as optimizing for limited memory and processing power, real-time performance, and hardware-software integration.

Once capability-building programs are rolled out, it’s important to track their progress and impact by using a set of predefined metrics. For example, one automotive organization rolled out an AI developer tool across about 10,000 developers by distributing licenses but without including a dedicated training program. By tracking the usage of this tool, they saw that licenses were being underutilized: only 20 percent of developers were actively using the tool, and less than 10 percent of that share were effectively using key features, such as chat functionality.

McKinsey conducted a pilot program with a European industrial software company with more than 40,000 developers. The study measured how gen AI improved selected software development use cases on a weekly basis, and it launched a capability-building initiative concurrently to ensure that the new tools were used effectively. As a result of these trainings, developers used gen AI 60 percent more often per week than when they didn’t have these programs. Not only did engagement improve, but after the trainings, 95 percent of developers also reported that gen AI has a positive impact on their developer experience (Exhibit 3).

## The tool chain required to maximize value from gen AI in software development

The strategic application of gen AI in software development typically involves a phased approach, starting with standard use cases and advancing to tasks that are more complex and specialized. To effectively harness the potential of gen AI tools in software development, organizations can consider four distinct stages.

The first stage, and a typical starting point, involves using off-the-shelf models and tools for standard use cases, such as code generation and documentation for popular programming languages such as Java, JavaScript, Go, and Python. This stage allows organizations to quickly realize the benefits of gen AI with minimal initial investment and complexity.

The second stage, which is less commonly pursued, involves fine-tuning these models on the organization’s own code base and potentially self-hosting them for standard use cases. For embedded software development, this stage might involve adapting models to understand and generate code for lower-level programming languages such as C or assembly. While this can offer solutions that are more tailored, it often requires significant effort and resources, making it less appealing for many organizations at the early stages of their AI journey.

The third stage involves using off-the-shelf models and tools for use cases that are more advanced. This could include complex tasks such as advanced code refactoring or integrating AI into embedded systems to manage signal transmissions between sensors. In the context of embedded software, this stage might also involve optimizing code for real-time performance and memory constraints and ensuring seamless hardware-software integration.

The final and most advanced stage is using fine-tuned models on proprietary code bases or self-hosting these models for highly specialized tasks. For example, in requirements engineering, tools can assist product managers with general tasks, but more companies are developing their own AI tools to produce better results, such as generating entity-relationship diagrams.

The right applications are crucial for maximizing the benefits of gen AI, whether in enterprise or embedded software development. Overall, gen AI can be applied to both enterprise and embedded software, albeit with some distinctions. While the integration process involves similar strategies, tools, and risk management processes, the impact tends to be higher in enterprise software because it has fewer constraints compared to critical embedded systems. Embedded software development often requires specialized testing environments such as hardware-in-the-loop and software-in-the-loop to ensure reliability and performance. Additionally, embedded software development benefits less from generic off-the-shelf AI tools and typically necessitates more-specialized solutions and custom setups to meet specific hardware and performance constraints. Lower-level programming languages used in embedded systems may also require additional fine-tuning or skill embedding to fully capitalize on gen AI’s capabilities.

Moreover, certain gen AI tools and large language models may be more suitable than others for developing embedded software. For instance, models that can handle the intricacies of real-time systems and provide support for low-level programming languages will be particularly valuable. These tools need to be adept at generating code that is not only functional but also highly optimized for the limited resources typical of embedded systems.

## Setting the foundation for success

For automotive and industrial leaders to properly integrate these capabilities, they must be intentional about how they roll out gen AI. To successfully integrate gen AI into software development, organizations need to establish three foundational steps: capability building and change management, impact measurement and value capture, and a multilever transformation approach.

The first step focuses on equipping developers with necessary skills and knowledge. Organizations should start with high-impact, easily implementable use cases, supported by a centralized governance structure for data and tooling. Training a group of coaches to drive the enablement program further ensures the sustainable growth of gen AI capabilities.

The second step involves defining and tracking metrics to measure the impact of gen AI initiatives. Critical metrics such as code quality and development velocity should be established to create a baseline to track progress against. Tools that track and analyze the performance of gen AI and monitor usage patterns across teams can provide valuable insights. Developing programs to realize financial value from the capacity unlocked by gen AI is essential for demonstrating tangible benefits.

The third step focuses on catalyzing a comprehensive transformation of the software development operating model. Remember, the gen AI integration is never just about the technology, so this stage involves changing processes, organizational structures, capabilities, and tools. Fostering a DevOps culture that emphasizes collaboration, communication, and shared responsibility between development and operations teams is also crucial for creating an environment conducive to allowing gen AI to thrive and for achieving higher developer velocity.

A logical progression is to consider the financial ramifications of this effort. Three methods are most often employed. First, organizations can accelerate their backlog by integrating banked efficiency gains into their planning processes, thereby enabling teams to handle more work with the same capacity. This approach requires meticulous alignment between efficiency improvements and project planning. Second, organizations can schedule future hiring efforts to coincide with the measured impact of gen AI. This approach would allow them to capitalize on the increased productivity of gen AI to maintain or even expand operations without additional head count. Last, organizations can reallocate the extra capacity generated by gen AI toward launching new initiatives. By ring-fencing or redistributing this capacity across various teams, companies can undertake new or incremental strategic projects with clear benefits, such as enhancing resilience and reducing technical debt. This approach not only leverages time savings for immediate operational improvements but also strategically positions the organization for long-term growth and innovation.

The integration of gen AI into automotive and industrial software development represents a significant leap forward in enhancing productivity, innovation, and operational efficiency. As companies navigate this transformation, it is crucial for them to adopt a holistic approach that includes capability building, strategic implementation, and continuous impact measurement. By fostering a culture of collaboration and adaptability, organizations can fully leverage the potential of gen AI to drive growth and maintain competitive advantage in an increasingly digital landscape. The journey toward mastering gen AI is complex, but with the right strategies and tools, the automotive and industrial sectors can achieve remarkable advancements in their software development processes.

## How relevant and useful is this article for you?

## About the author(s)

Dominik Hepp is a partner in McKinsey’s Munich office, where Michael Amroudi is a consultant; Martin Harrysson is a senior partner in the Bay Area office; and Mateusz Wozniak is an associate partner in the Warsaw office, where Lukasz Maslaniec is a consultant.

## Explore a career with us

## Related Articles

## Automotive R&D transformation: Optimizing gen AI’s potential value

## The economic potential of generative AI: The next productivity frontier

## When code is king: Mastering automotive software excellence","{""publication_date"": ""January 3, 2025"", ""word_count"": 3748, ""reading_time_minutes"": 19}",2025-03-14 12:40:51.429424
40,GSK’s Kim Branson on driving innovation with AI and machine learning,https://www.mckinsey.com/industries/life-sciences/our-insights/gsks-kim-branson-on-driving-innovation-with-ai-and-machine-learning,,"## GSK’s Kim Branson on driving innovation with AI and machine learning

In this episode of Eureka!, a McKinsey podcast on innovation in life sciences R&D, hosts Navraj Nagra and Alex Devereson speak to Kim Branson, senior vice president and global head of AI and machine learning at GSK. They discuss how these emerging technologies are being used to potentially reshape how drugs are developed and about the complexities AI and machine learning introduce in data management, cross-functional collaboration, and responsible innovation.

## Driving new approaches to pharmaceutical research and development

Alex Devereson: What is the primary focus of the work you’ve been driving at GSK?

Kim Branson: It’s across the discovery and development continuum. We use machine learning for genetic analysis, cellular and clinical imaging, and active learning. For clinical applications, we’re thinking a lot about building models to predict the effect of individual treatment and how to discover disease heterogeneity. We do a lot of work in computational pathology, where we’re increasingly doing a lot of multimodal models because there’s lots of information present. The dream is for our medicine to be the well-known blockbuster for all possible people. But the diseases we go after are quite complex, with sometimes narrow populations. So we’re looking for ways of identifying those people and building support.

## Extracting value from AI and machine learning

Navraj Nagra: Where have you seen the most value extracted from AI and machine learning?

Kim Branson: I’ll give you a good example, which is bepirovirsen. It’s a hepatitis drug that’s in development, and we ran a heavily instrumented phase two trial for it, collecting a lot of different blood-based biomarkers and things like that to work out what fraction of people will respond to it. You could have the best molecule ever, but you won’t see its clinical effect if it’s the wrong target population. And it’s machine learning that helps us bring all the data sources together and link them back to specific populations.

Alex Devereson: Are there different levels of understanding, willingness, and excitement to use these methods across the value chain?

Kim Branson: GSK decided machine learning was a core part of its strategy back in 2019. The first place where that really started to come together was oncology because there’s a large amount of data there, it has a lot of heavily sequence-driven methods, and it’s an area where people are quite familiar with the idea of precision medicine. But people are now realizing more broadly that performance matters. Other areas haven’t had companion diagnostics and things like that because there hasn’t been any investment in or data for them. But I think that commercial pressure is coming, particularly because we are affecting a lot of lifelong chronic conditions. That’s a macro trend everybody’s seeing: the idea of precision medicine moving beyond oncology to everyone else.

## Understanding the organizational implications

Navraj Nagra: How do you think about managing the scope of AI and machine learning capabilities and expertise needed to achieve your aim of treating the underlying disease pathway while prioritizing safety and efficacy?

Kim Branson: Multimodal data sets require deep expertise. Domain knowledge absolutely matters for assessing how the data is generated. So, for example, in clinical imaging, I have people who are PhDs, postdocs in clinical imaging, and machine learning people. You really need to know what’s going on as well as what you will collect. So we have people that are both machine learning people and deep experts in some of these domains.

The big thing for us was generating data with the explicit purpose of building models, because we believe that’s a source of advantage. We’re thinking about the data we need to collect and generate as well as the measurement technology we want to bring to bear. People forget that a machine learning organization is not a data engineering organization—these guys are not data engineers. That’s why we created an organization called Onyx to do the data engineering at scale. Some companies have partnerships, but we needed to build this muscle internally.

What separates tech bios from big pharma is scale. Big pharma can deploy capital rapidly, put a lot of capital across a lot of different disease areas at once, and generate data in humans. That’s key, because data with real-world outcomes is gold. You can do all of it theoretically. But if you haven’t got the outcome data from patients and can’t build that linkage model, it’s very difficult to calibrate and use it for discovery.

## Driving competitive advantage through data

Navraj Nagra: How do you ensure the organization is generating data that’s useful for you and for the models you’re building?

Kim Branson: There’s always competition for internal resources. And it’s a strange concept for some people when I tell them I need all possible data, and don’t stop generating it. It’s a huge mindset shift for sure.

Alex Devereson: Let’s imagine merging the big pharma and tech bio cultures. What would excite you most about that?

Kim Branson: It still comes down to data. What I’m excited by is the ability to add a lot more sensors through wearables and the like to collect a lot more diverse patient information. We collect a lot of data from medicine EHRs [electronic health records] that are for management and changing things, but it’s not for understanding a disease after you’ve been diagnosed. The explosion of collecting data at scale is going to be the most interesting thing, and I’m really excited by being able to integrate information from different disciplines, such as clinical imaging plus other things we have never combined before.

## Balancing innovation with ethics and regulation

Navraj Nagra: How do you ensure regulatory compliance with some of the cutting-edge AI technologies? And how do you think about the ethical implications of applying some of these approaches more broadly to patient well-being and health?

Kim Branson: We have a company-wide set of trainings, and we’ve been interfacing and integrating with regulatory bodies from the FDA [US Food and Drug Administration] and others to embed regulation from the start, such as standards that inform how we build machine learning models. For us, it’s about making sure we balance the return from machine learning with the risk while realizing there will be differential trade-offs.

Where we’re pushing on regulators is around how we can think a little bit differently and why the machine learning models are a little bit different than the pharmaceutical process. Traditionally, we take a medicine, run various stepped-up trials, and then do large-scale trials with a representative population to conclude that a drug seems to be reliable, safe, and effective. Now we’re asking how we can monitor predictions and outcomes in real time. We don’t do that right now for a lot of diagnostics once they’re certified and calibrated, but we easily could.

## How relevant and useful is this article for you?

## About the author(s)

Kim Branson is senior vice president and global head of AI and machine learning at GSK. Alex Devereson is a partner in McKinsey’s London office, where Navraj Nagra is an associate partner.

Comments and opinions expressed by interviewees are their own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement.

## Explore a career with us

## Related Articles

## AbbVie’s head of genomics research on the transformative power of AI

## How biopharmaceutical leaders optimize their portfolio strategies

## Advancing R&D for chronic diseases with AI: A conversation with Novo Nordisk’s CSO","{""publication_date"": ""March 4, 2025"", ""word_count"": 1262, ""reading_time_minutes"": 6}",2025-03-14 12:40:58.205390
41,A welcome change in lease-accounting rules,https://www.mckinsey.com/capabilities/strategy-and-corporate-finance/our-insights/a-welcome-change-in-lease-accounting-rules,30 percent to 60 percent (exhibit),"## A welcome change in lease-accounting rules

For decades, investors, credit-rating agencies, and analysts assessing the relative performance of companies with large portfolios of leases have capitalized off-balance-sheet leases as assets rather than expenditures.

Now, after much deliberation,1The Financial Accounting Standards Board and the International Accounting Standards Board have been discussing the rule change since 2006, seeking to align both sets of standards.  the rules are catching up to common practice: in 2019, all leases longer than 12 months will have to be recognized on the balance sheet as a “right of use” asset and a corresponding financial liability under both International Financial Reporting Standards (IFRS) and US generally accepted accounting principles (GAAP).

As a result, lease-intensive industries, such as retail, travel, and transportation and logistics, face changes. Reported debt for such players (and consequently, reported assets and invested capital) could increase by 30 percent to 60 percent (exhibit). No materially new information will be disclosed, but at a high level, the change in rules will make it easier for investors and analysts to compare performance across companies.

Some inconsistencies remain, however. For example, the International Accounting Standards Board and the Financial Accounting Standards Board both require that companies recognize the liability of future lease payments over initial lease periods, as well as an offsetting right-of-use asset for all leases. With some exceptions, such as the exclusion of small-value leases under IFRS, balance sheets should be comparable. The income statement, however, presents a new issue. Under IFRS, all lease payments will have to be split into depreciation and interest charges, neatly separating operating expenses and finance costs in both the profit-and-loss and cash-flow statements. By contrast, US GAAP will still recognize the concept of an operating lease, and companies will record lease expenses for them fully in the operating-expenses portion of the two statements.

As a result, investors and analysts wanting to compare companies’ return on capital, EBITDA, EBITA, margins, and enterprise-level multiples will still have to restate the data for businesses reporting under US GAAP. They will have to add back the implied interest cost to reported operating profits to make them fully comparable. This should not be a difficult task.

## Would you like to learn more about our Strategy & Corporate Finance Practice?

Clearly, financial analysts will also need to take care when benchmarking performance over longer time frames, making sure to restate pre-rule-change financial data as best as they can to be consistent with post-rule-change standards. This will be the only way to draw meaningful conclusions from analyses over long time frames.

For executives in industries with extensive leasing portfolios, the message is also clear: these changes in accounting rules, by themselves, warrant no shift of real-estate or financing strategies. As we’ve outlined in earlier research,2See Timothy Koller and Werner Rehm, “Why accounting rules shouldn’t drive strategy,” February 2007,  and Werner Rehm, “Leasing: Changing accounting rules shouldn’t mean changing strategy,” April 2011. accounting-rule changes that don’t require companies to disclose more information don’t reveal new insights that might lead investors to change their assessments of a company’s value. We’ve seen no revaluation when stock options were expensed or when goodwill accounting changed to then-new rules.

Investors understand that cash flows don’t automatically change when the rules do—and that’s what matters, ultimately.

## Stay current on your favorite topics

## How relevant and useful is this article for you?

## About the author(s)

Prateek Gakhar is a specialist in McKinsey’s Gurgaon office, where Jyotsna Goel is a senior analyst; Werner Rehm is a partner in the New Jersey office.

## Explore a career with us

## Related Articles

## Building a better income statement

## Why accounting rules shouldn’t drive strategy","{""publication_date"": ""November 27, 2018"", ""authors"": [""30 percent to 60 percent (exhibit)""], ""word_count"": 614, ""reading_time_minutes"": 3}",2025-03-14 12:41:05.968699
42,How can tech-enablement make capital projects win big?,https://www.mckinsey.com/capabilities/operations/our-insights/how-can-tech-enablement-make-capital-projects-win-big,pressing the Escape key or activating the close button,"## How can tech-enablement make capital projects win big?

This transcript has been lightly edited for clarity.

## What keeps capital project leaders awake?

• descriptions off, selected

• captions settings, opens captions settings dialog

• captions off, selected

This is a modal window.

Beginning of dialog window. Escape will cancel and close the window.

End of dialog window.

This is a modal window. This modal can be closed by pressing the Escape key or activating the close button.

This is a modal window. This modal can be closed by pressing the Escape key or activating the close button.

## Share:

## BrightCove Video

Ishaan Nangia: What we hear consistently from capital project leaders is that there is a huge amount of value attached to their capital management system. Between 2022 and 2027, about $130 trillion of capital will be spent, and that’s almost a 70 percent increase compared with the previous five years. Our research suggests that most large capital projects end up overrunning either cost or schedule by around 30 percent to 45 percent. These huge capital projects are very complex. They involve assembling teams of a multidisciplinary nature and collaborating across the whole ecosystem.

Jae Hoon Jung: I met a lot of the capex leaders in Asia. They have three questions. Question number one, how can they deliver the projects on time and with the cost that they promised? And then question two is, how can you get better people, how can you train them and then build the capabilities? And lastly, we also get questions about how we can deliver carbon-free projects.

## How can capital project leaders win in the new era through tech enablement?

Ishaan Nangia: Technology actually has the real ability to reduce that uncertainty and to ensure that capital projects are operating on the efficient frontier. There are three applications in particular that we think are making a huge difference. The first is using digital twins to optimize design and scope, creating an emulation and a simulation of the physical built asset as a way of making trade-offs and decisions. The second is generative scheduling, which is a way of using machine learning and advanced analytics as a way of simulating the build sequence and process and identifying potential errors or clashes in advance, as well as how to re-sequence and re-resource work. And third is the use of digital control towers, which can stitch together data and insights both backward looking and predictive, in a way that gives project leaders real-time insight into the performance and progress of a project and allows them to problem solve and correct the trajectory of a project before it gets out of control.

Jae Hoon Jung: For example, we recently applied generative AI scheduling to petrochemical and mining projects. In the old days, project managers only have a few scenarios, and then it takes a lot of time to generate even those few scenarios. But now with this gen-AI-based scheduling, they can generate thousands of scenarios within a few minutes and then can compare these scenarios to come up with better resource planning and a better work sequence. It is important that the project leaders understand the impact of these new tools and then find a way to deploy faster and [add more tools] to their portfolios.

Ishaan Nangia: A consistent practice that we see the leaders in capital projects adopt is, for every dollar they spend on tech enablement, they spend an equivalent amount on change management and capability building. We also see a lot of the leading organizations in capital delivery acknowledging and recognizing that capital project development and delivery is a competency in its own right and [therefore] creating tailored academies and internal skill-building journeys that train the next generation of their capital project leaders.

## How relevant and useful is this article for you?

## About the author(s)

Ishaan Nangia is a senior partner in McKinsey’s Melbourne office, and Jae Hoon Jung is a partner in the Seoul office.

## Explore a career with us

## Related Articles

## What is the playbook for scoring “triple wins” through product design?

## Where is procurement heading in the next ten years?

## Tech-enabling operations: What is the next unlock?","{""publication_date"": ""October 24, 2024"", ""authors"": [""pressing the Escape key or activating the close button""], ""word_count"": 707, ""reading_time_minutes"": 4}",2025-03-14 12:41:11.921475
43,The full spectrum of product management,https://www.mckinsey.com/careers/meet-our-people/careers-blog/aman,,"## The full spectrum of product management

June 18, 2020It was a cold November day in 2013 when I joined McKinsey’s Gurugram office. Though the weather was freezing, excitement was sky-high. The warm, friendly, welcoming team made me feel comfortable, and the anticipation of joining something big brought me joy deep within.

Before I joined the firm, I worked primarily with e-commerce start-ups. The Indian e-commerce market was taking off, and I was head of product for Rocket Internet’s biggest and fastest growing venture in India, jabong.com

McKinsey presented the chance to join an established, global firm, and the opportunity to work with top professionals in industries beyond e-commerce. I joined the firm as a product manager, and since then I believe I have grown as a professional and as an individual.

## Growing as a leader

I was a bit nervous in the beginning, but in just a few weeks I realized I belonged to a fast paced, super-talented team of high-performing colleagues. The team’s focus on delivering impact and the opportunity to create real client difference was exhilarating, and the scale of my projects was like nothing I had ever experienced.

The firm has given me an opportunity to solve problems in different industries and sectors that impact millions of people around the globe. Over my tenure at the firm, I’ve worked in agritech, healthtech, digital media, retail, e-commerce, automobiles, and heavy industries.

On one project, I built a health-tech ecosystem serving half a million doctors in India. On another, I led product conception and development on a team of more than 100 people to build one of the largest digital media platforms for a client in Southeast Asia with a user base of almost a third of the country’s population.

When I first joined McKinsey, the product management discipline was new to the firm and many of the non-digital native organizations we serve. We saw the digital media platform project as an opportunity to demonstrate the importance of integrating product management into our work. I had the chance to lead product management from the start, build the client’s capabilities, and act as interim head of product.

The project became a blueprint for how to utilize product management while building a digital business. Since them, product management as a function has become core to initiatives in Southeast Asia and India, including our Leap by McKinsey projects. Today I lead digital engagements, client development initiatives, diagnostic phases for digital builds and transformations, even design and technology teams during product design and build.

## Advice for candidates

McKinsey offers more than 12 clear career paths for technologists, and I was drawn to the freedom to be entrepreneurial and drive impact for our clients and the firm.

I lead regional product manager recruitment and help new product managers in India onboard and succeed at the firm. If you are considering McKinsey, be assured the possibilities and variety of work is endless and the impact we deliver is phenomenal.

## Outside of work

I’m an avid reader and traveler and love visiting wildlife sanctuaries. Being part of a worldwide firm has given me the opportunity to travel, work globally and experience different cultures. I’m also a proud father of a six year old, and fulfill all my childhood dreams through my little friend. The firm provides absolute flexibility to maintain my work life balance and the choice to pace my work.

Find a job like Aman's

Aman is a product manager in McKinsey’s Gurugram office. He has bachelor’s in electrical engineering from Kurukshetra University in India and a master’s in computer science from Marist College in the United States. Prior to joining McKinsey, Aman was a product leader with jabong.com & tradus.com, both e-commerce startups, a product manager with Aristocrat, an entertainment company, and a business analyst with GE Corporate and Western Union.

For more information on McKinsey's product management career paths, visit mckinsey.com/TechCareers.

## Never miss another post","{""word_count"": 657, ""reading_time_minutes"": 3}",2025-03-14 12:41:17.932160
44,Uncertainty in M&A: Postcards from the new normal,https://www.mckinsey.com/capabilities/m-and-a/our-insights/uncertainty-in-m-and-a-postcards-from-the-new-normal,"a single, simple depiction","## Uncertainty in M&A: Postcards from the new normal

Uncertainty in M&A has become the new normal. Under conditions of multiple, significant, and global macroeconomic shocks, companies and investors are becoming more purposeful about their deals. While there is still meaningful deal volume (approximately 80 to 90 percent of levels experienced a decade ago), we see a higher bar for ensuring value creation and a greater willingness to engage in alternative deal types, such as joint ventures (JVs) and alliances. The era of “opportunistic” deals has passed, as interest rates no longer hover near zero, disruptions have become constant, and uncertainties are profound and multifaceted.

## Six postcards, six takeaways

• Historical macroeconomic comparisons. The year 2024 followed a pattern similar to that of other periods of recovery and likely reflected uncertainties related to the US presidential election year.

• Deal metrics. Deal multiples are down more than seven turns amid the current uncertainties, far exceeding multiple compression during prior downturns.

• Cross-border M&A. Companies pivoted to gain access to the Americas, expecting growth exposure, and paid a premium for this access.

• Deal synergies. Announced synergies in 2024 were well above historical averages.

• Alternative deal types. Structures such as joint ventures and alliances are back in vogue.

• Private equity. Private equity remained largely on the sidelines in 2024, but conditions are ripening for more dealmaking.

Indeed, neither the scope nor the depth of uncertainties in M&A can be captured by a single, simple depiction. Instead, they can best be understood by examining them through multiple lenses that offer different and, in the aggregate, complementary snapshots—or what we call postcards—of the new normal (see sidebar, “Six postcards, six takeaways”). Taken together, these postcards offer insight into the shifts of the past few years and the challenges that dealmakers now confront. They also suggest a range of outcomes going forward, both for defense-minded strategies and potentially bolder moves.

## Postcards across dimensions

There are numerous lenses through which one can examine M&A dynamics. Among the most revealing, we found, are (1) historical macroeconomic comparisons; (2) analyses of key financial metrics, including deal counts, valuations, cost of funding, and numbers of IPOs; (3) geographical differences (including, importantly, M&A across borders and continents); (4) size of deal synergies; (5) frequency of alternative transactions (such as alliances and JVs); and (6) developments specific to private investors, particularly private equity (PE) funds.

## Historical macroeconomic comparisons

Our first snapshot is a historical macroeconomic comparison—that is, a look at what’s different and what’s similar between present macroeconomic developments and previous ones (Exhibit 1).

The key takeaway from this postcard? The year 2024 followed a pattern similar to many other macroshock periods of recovery and, though deal prices on a real basis have been broadly declining for about a decade, likely also reflected uncertainties related to the US presidential election year (Exhibit 2).

It’s tempting to call the past few years a “perfect storm.” But doing so suggests that the recent past represented a one-off happenstance that is now behind us and that more stable, predictable times are ahead. In fact, and more likely, a combination of forces and shocks is likely to endure through the foreseeable future.

M&A activity has always varied to some extent, of course, and downturns aren’t new; though each decline has been different, they share important commonalities. What’s similar about current developments compared with prior developments? Most prominently, the decreases in dealmaking we see today remind us of the oil shocks of the early 1970s—a combination of events and forces (an energy crisis, a severe strain on supply, the resurgence of inflation, rising geopolitical tensions, and a deceleration in productivity in developed markets) that wasn’t contained within a single or few industries and geographies.

## M&A Annual Report: Is the wave finally arriving?

That’s unusual. While most of the other past downturns (such as the Asian financial crisis in 1997, the dot-com bubble in 2000, and the global financial crisis from 2007 to 2009) were largely contained within specific regions or sectors, the pandemic and postpandemic shocks that dealmakers now confront reverberate across sectors and geographies. Moreover, today’s uncertainties are marked by a combination of changes happening at approximately the same time—even if those shifts don’t dominate the headlines.

Consider regulation: The rules that govern M&A within and across regions are undergoing some of their most consequential changes in decades. To take one prominent example, the United States experienced a dramatic spike in regulatory challenges to transactions, and new rules are going into effect that will substantially alter filing requirements—though whether those rules will endure is itself uncertain since the nature and extent of changes between the Biden and second Trump administrations are yet to be determined.

Or consider capital flows: In Europe, foreign direct investment is declining substantially in some of the region’s largest economies. Now, changes to tariff policy threaten to upset global markets even further. Nor, of course, are these dynamics the only sources of uncertainty. Strains on global supply chains are pronounced, geopolitical tensions are rising, and carbon constraints are becoming more urgent. The shocks are far more varied and, in some respects, much more intense than in previous crises (Exhibit 3).

## Deal metrics

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

Historical comparisons, while helpful, reveal only part of the story. Another critical lens is financial and deal metrics. Start with deal volume: The number of deals in recent years has decreased in the aggregate, but aggregate decline in deal flow is largely a function of deal counts, which are falling amid uncertainty.

The key takeaway from this postcard? Deal multiples are down more than seven turns amid the current uncertainties, far exceeding multiple compression during prior downturns. While overall deal multiples and top quartile multiples are currently within historical averages, the decline in the past few years is stark—and perhaps a reflection on the frothy median deal multiples seen early in the COVID-19 pandemic.

Deal multiples from 2021 to 2024 were slightly above the average of the second quartile of the past 25 years and slightly higher than multiples in prior, recent crises. But the data are not sufficient to identify a clear trajectory. A closer analysis reveals that M&A activity typically falls over time in the wake of economic shocks. Deals that had already been in the pipeline typically are completed, but new deal flow is constrained—hence the lag. Moreover, macroeconomic challenges are persisting. Customer sentiment is the lowest it has been in decades. In addition, the days of cheap funding that had marked economies before the COVID-19 pandemic are over, at least for the foreseeable future. For most of the 2020s, the cost of funding has been fluctuating, sometimes wildly, and the volatility is presenting a significant challenge to M&A. Finally—and not surprisingly, amid roiling uncertainty and shocks to capital markets worldwide—the number of IPOs has decreased sharply (Exhibit 4).

As of mid-November 2024, P/E multiples reached 35 times compared with less than 25 times in early 2022, and multiples of EBITDA to enterprise value climbed about 10 percent since the start of 2023. It’s important to note that these observations represent a global aggregate; different industries reflect varied dynamics, as do different geographies (and cross-border transactions) and categories of dealmakers (that is, financial versus corporate). These analyses, among others, are presented in more detail below.

## Cross-border M&A

The key takeaway from this postcard? Companies pivoted hard to gain access to the Americas, expecting growth exposure, and paid a premium for this access.

It would be reasonable to expect that uncertainty has had a similar, downward effect on deals across borders. Yet surprisingly, that’s not the case (Exhibit 5).

We define cross-border M&A in two ways: Deals across borders but within the same continent (for example, a company based in France acquiring a target in Germany) and deals that span continents (such as a US company acquiring a Netherlands-based business). With respect to both categories, cross-border M&A has remained steady despite global uncertainty, with roughly 25 percent of deal value being cross-border. Indeed, valuations for individual cross-border deals are increasing. The reasons are largely case-specific; for example, some companies have an immediate need to reposition their supply chains and secure beachheads in markets (especially with pending supply chain or tariff barriers), while others continually track to where the growth is—including new businesses and markets.

Drilling down further, we found that approximately 60 percent of intercontinental deal volume for deals larger than $500 million came from transactions between EMEA (Europe, the Middle East, and Africa) and the Americas, with the buyers and sellers almost evenly distributed between the two regions. That’s nearly double the size of the next largest category—Asia–Pacific (APAC) and Americas deals, which, at 26 percent, also split evenly between those two regions in terms of where the funds were flowing. The smallest category, APAC–EMEA deals (13 percent), was half the size of APAC–Americas deals; in that case, APAC initiated the larger share of intercontinental funding (8 percent versus 5 percent), though both are growing rapidly.

To recognize today’s new normal, it’s important to remember the key, counterintuitive nuance: Cross-border M&A is trending up, and cross-border deals are bringing higher valuations. These dynamics run decidedly counter to declining or flat trend lines within most individual countries and regions.

## Deal synergies

The takeaway from this postcard? Announced synergies in 2024 were well above historical averages. This reflects bullishness on cost, capital, and revenue, but also likely a need to justify premiums in an uncertain environment.

One might expect that massive uncertainties would have a negative effect on the size of deal synergies. After all, forces in flux could (and, one would expect, should) present a headwind for capturing postclosing value. Yet here again, closer analyses reveal surprises. Following the COVID-19 pandemic, the percentage of M&A transactions announcing cost or revenue synergies (or both) decreased, particularly for revenues. But for transactions that did announce synergies, on either or both the revenue and cost sides, the size of synergies increased significantly as a percentage of transaction value (Exhibit 6). We observe, moreover, that realized synergies are often considerably higher than what has been announced and consider not only combinational cost synergies but also sales and capital synergies.

Today, cost synergies are nearly double 2015 levels, and revenue synergies have, remarkably, risen eightfold over the same period. These clear, positive trends are hardly the indication of a decidedly down market. Instead, this postcard presents a more nuanced perspective of the current, uncertain new normal, with several forces at work. For example, because of pervasive uncertainty, many boards require more convincing for M&A and green-light only those deals that have more significant synergy potential or are less likely to involve prolonged and potentially costly legal review. It also indicates more proficient corporate acquirers, able to commit to larger value creation targets as they size a deal. In addition, with a higher cost of funding, a larger value creation envelope will be needed to meet the internal rate of return requirements of acquirers. No single or simple explanation fits every case; complexities leave open a fan of outcomes for deals to succeed, fail, or (for now) stay in neutral.

## Alternative deal types

The takeaway from this postcard? Alternative deal structures, particularly JVs and alliances, are back in vogue, reflecting earlier-stage acquisitions and a desire to access functional capabilities in developing areas such as artificial intelligence (Exhibit 7).

The current M&A environment also reflects a new normal in alternative deal types. The share of JVs and alliances has settled at a higher percentage compared with the period between 2004 and 2017. The rationale for alternative deal types can be particularly compelling in uncertain times; these structures allow dealmakers to potentially reduce dependencies on interest rate fluctuations and ride out a funding crunch until interest rates subside and then stabilize. Moreover, the share of minority investments has increased following recent shocks (for example, in 2020, 2022, and 2023). That dynamic, too, is consistent with uncertainty, as acquirers seek to adjust for funding gaps, decrease risk, and address potential regulatory concerns.

## Private equity

The takeaway from this postcard? Private equity (PE) remained largely on the sidelines in 2024. But as the length of time that financial buyers are holding businesses is reaching historical highs, PE funds are holding substantial levels of dry powder—and their share of deals is below historical highs (Exhibit 8). Those dynamics suggest increased pressure on PE firms to engage in more dealmaking.

Because M&A is driven by strategic and financial dealmakers, it’s helpful to disaggregate the two. Turning the lens on private investors reveals that they currently have an abundance of dry powder. Multiple PE funds face a defined timetable, an increasing pressure to exit, and an urgent imperative to deliver higher investor returns. After the share of PE transactions peaked in 2021 (27 percent of total deal volume), investors have been pushing for deals, even when that could lead to potential “must sell” situations.

For more than two decades, private investors’ share of all M&A deals has run between 12 and 22 percent of total deal volume, and because that percentage is a function not just of their own dealmaking activity but also those of corporate dealmakers as well, it’s uncertain whether the recent trajectory since 2014 will plateau at the lower end of that range, return to the higher end, or perhaps set new highs (or even lows). PE’s overall share of M&A activity nudged slightly upward in 2024 compared with 2023 (15 percent of deals worldwide in excess of $25 million, one percentage point higher than 2023, and two percentage points lower than 2022). These levels, too, are a postcard from today’s uncertainty.

## Assessing a range of outcomes

There are a range of outcomes in terms of how dealmakers, confronted with this new normal, could behave going forward. We observe that many companies are taking more defense-minded actions for M&A. That approach is certainly understandable given considerable unpredictability. Yet uncertainty also presents unique opportunities, and a more offense-minded approach could be highly attractive for those who dare.

## Purpose, not opportunism

Companies and private investors are adopting more cautious strategies to protect capital and are slowing down M&A activities across the deal life cycle. Several key themes are particularly evident.

First, we’re seeing a more limited appetite for risk. This is particularly (but not solely) the case for industries that are more exposed to exogenous factors such as election outcomes and climate change. Second, most dealmakers are taking a selective and cautious approach. While programmatic acquirers have maintained their acquisition pace—and demonstrated the resilience that allows them to better source deals, optimize organizational structures in integrations, and demonstrate greater success in retaining key talent—a large majority of acquirers are pumping the brakes on the number of deals they initiate and scrutinizing those under current consideration. Opportunistic dealmaking of the last decade has decreased, and more purposeful deals (with rationales that seek to ensure a clear fit with a defined strategy) now mark the M&A landscape (Exhibit 9).

Dealmakers are seeking to make more holistic deal assessments, particularly during the due diligence phase. They are conducting rigorous analyses to improve the confidence level of sellers and buyers alike and are committing to ensuring that each deal meets clearly defined strategic criteria. They’re also seeking to maintain their focus through the integration phase to capture synergies more quickly, particularly on the cost side, amid rising uncertainty.

The implications of their more deliberate approach are reflected in expectations of future M&A activity. The dealmakers we survey express that they expect to do fewer deals.

## Opportunities amid uncertainty

It’s understandable that intense uncertainty would lead dealmakers to adopt a more defensive posture. Yet the new normal offers new opportunities for those who adopt a bolder approach. A less active deal market allows them to take advantage of richer pipelines; buyers that maintain their commitment to M&A will have fewer contenders for targets and can achieve more value-accretive deals. In particular, they can be more proactive about potential deals with private investors facing pressure to sell assets held for longer holding times—and those on the lookout to buy as their dry powder increases. Dealmakers can also take advantage of new realities in creative deal structuring, using JVs and alliances to enable transactions in a context where more attractive funding may not be imminent. Ideally, too, they can capture higher synergy values as they put their customized playbooks into action.

Finally, it’s worth noting that, historically, companies that take a programmatic approach to deals are more likely in the aggregate to create value than companies that practice selective dealmaking, pursue large deals, or primarily pursue organic growth. Indeed, their success across several metrics has been particularly evident amid recent uncertainty. For one, they’ve demonstrated greater resilience, besting competitors by about ten percentage points in 2023 in aligning or even exceeding the number of deals articulated in their yearly strategic plan. Moreover, programmatic acquirers are winning across the deal cycle. Compared with 2021, dealmakers reported that they were markedly more likely in 2023 to hew to M&A playbooks for deal sourcing and due diligence, leverage integration to optimize organizational structures, and retain talent critical for sustaining a competitive advantage.

Uncertainty in M&A has indeed become the new normal. With interest rates no longer near zero, an array of macroeconomic shocks reverberating worldwide, and extraordinary unpredictability in regulations, geopolitics, and other key dimensions, dealmakers have become more purposeful and less opportunistic. There is a higher bar for delivering value creation, and an increased willingness to engage in more complex deal structuring. Yet purposeful M&A pays off, with higher excess TSR compared with other approaches. There are also no-regret actions that both offense-minded and cautious acquirers are deploying to create more value. Here, too, a full appreciation of the challenges and opportunities requires nuance, perspective, and a varied range of insights.

## Industry deep dives

## Advanced industries

## Financial services

## Consumer goods

## Global energy and materials

## Life sciences

## US healthcare

## Private capital

## Travel, logistics, infrastructure

## Technology, media, telecom

## M&A insights

## Retain, integrate, thrive: A strategy for managing talent during M&A transactions

## Gen AI: Opportunities in M&A

## CEOs in M&A: Five actions only the chief executive can take

## Why managing culture is critical for value creation in M&A

## What it takes to make separations a competitive difference-maker

## Dealmaking through challenges: Lessons from the automotive industry

## How relevant and useful is this article for you?

## About the author(s)

Jake Henry is a senior partner in McKinsey’s Chicago office, Mieke Van Oostende is a senior partner in the Brussels office, Tobias Lundberg is a partner in the Stockholm office, and Matteo Camera is an associate partner in the Milan office.

## Explore a career with us

## Related Articles

## Navigating the new geopolitical uncertainty

## Bubbles pop, downturns stop

## What programmatic acquirers do differently","{""publication_date"": ""February 19, 2025"", ""authors"": [""a single"", ""simple depiction""], ""word_count"": 3224, ""reading_time_minutes"": 16}",2025-03-14 12:41:25.087713
45,How the implementation of organizational change is evolving,https://www.mckinsey.com/capabilities/implementation/our-insights/how-the-implementation-of-organizational-change-is-evolving,the contribution of each respondent’s nation to global GDP,"## How the implementation of organizational change is evolving

Companies face different challenges today when implementing large-scale changes than they did in 2014, according to a new McKinsey Global Survey on the subject.11.The online survey was in the field from April 18 to April 28, 2017, and garnered responses from 1,528 participants representing the full range of regions, industries, company sizes, functional specialties, and tenures. Of them, 1,420 have personal experience with major change efforts in the past five years, at either their current or previous organizations—and 878 say the most recent change effort that they are familiar with involved the implementation of a digital solution. To adjust for differences in response rates, the data are weighted by the contribution of each respondent’s nation to global GDP.  In particular, digitization poses new obstacles to implementation, and digital transformations require executives to focus on different priorities and capabilities.

## Stay current on your favorite topics

Across all types of transformations, few survey respondents say their organizations’ change efforts have both improved performance and sustained those improvements. Since the previous survey, organizations have not become much better at executing the core capabilities and practices that support success in large-scale change programs. But in the case of digital transformations—which over half of respondents report as their organizations’ most recent change efforts—the results point to key practices that can improve the odds of success.

## The changing face of transformations

The latest survey results indicate that success remains elusive. Only 37 percent of respondents report successful implementations; we call this group “top implementers.”22.We asked respondents about the most recent major change effort at their organizations, and successful implementations are those that respondents describe as moderately or very successful at improving performance (measured by, for example, profitability, return on capital, market value, and/or lead-time reduction) and moderately or very successful at sustaining improvements over time, following the full implementation of the change initiatives.  The most common practices for supporting successful change efforts remain the same as in 2014. These include leaders owning and committing to the change being made, role modeling new behaviors, and devoting appropriate time and energy to supporting the change. But compared with the previous survey, smaller shares of respondents report leaders’ ownership of and commitment to change, effective processes for prioritizing change initiatives, and regular tracking of change efforts’ progress (Exhibit 1). When asked about organizational practices more broadly—beyond change efforts—respondents also report declining employee commitment. Fifty-five percent of respondents say employees spend most of their time on organizational priorities and value-adding activities associated with the transformation, down from 68 percent of respondents who said so previously.

These individual practices (out of 30 the survey tested) support seven core implementation capabilities that, in our experience and past research, are most critical to the successful implementation of change. Among top implementers, 85 percent agree that the change effort included all seven core capabilities, while only 41 percent of other respondents say the same.

## The digital challenges ahead

Over two-thirds of all respondents agree that implementation capabilities are more important to the outcomes of major change efforts than they were three years ago. But to complicate matters, the results suggest that the very nature of change efforts is evolving. More than half of respondents say their organizations’ most recent major transformations involved the implementation of digital solutions.33.In the survey, we defined a digital solution as any changes—either internal or externally facing—that involve the use of digital tools or technologies, such as automating formerly manual work, improving methods to track work with digital tools, or expanding the functionality of digital customer interfaces.  The results suggest that digitization poses new, and meaningful, disruptions to implementing organizational change. One such challenge is the scope and scale of digital transformations. Seventy-five percent of respondents whose companies have undertaken them say their change efforts span more than one business unit or function, compared with 64 percent who say the same about traditional transformations.

Digital transformations also require new skill sets and resources, but finding the right people for this work is a major hurdle. Just one in three respondents say it has been easy for their organizations to internally source the necessary piloting and rapid-prototyping skills for digital solutions. Even respondents from the top implementers are more likely to say their organizations struggle with sourcing skills than with any of the other digital-implementation practices we asked about.44.The survey asked about 28 practices related to the implementation of digital changes across four phases—setup, piloting, scaling and implementation, and sustaining changes—and the extent to which respondents agreed that each practice was followed by their own organizations.  Yet only 57 percent of respondents say that if their companies did not have the right skills in-house, they had a process for sourcing them externally.

Last, digital change efforts necessitate new approaches, particularly for assessment. Respondents are less likely now than in 2014 to say that their organizations regularly assess the impact of initiatives and changes once they have been implemented. But among the top implementers, those undergoing digital transformations are more likely to report this practice—along with testing major changes in smaller, controlled environments—than their peers involved in conventional change efforts. This result suggests that assessment is even more critical to the outcome of a transformation that involves digital solutions.

Of the seven capabilities, successful digital implementers most often report that their organizations plan for long-term sustainability and demonstrate commitment to the changes (Exhibit 2). The top digital implementers are more than three times likelier than others reporting digital transformations to say that from day one, their organizations planned for the long-term sustainability of the changes they made. Across the core capabilities, the top digital implementers are furthest ahead of their peers in effective program management.

## The keys to success in digital transformations

In addition to assessing the outcomes of the overall transformations, respondents whose organizations have implemented a digital solution were asked to evaluate their organizations’ execution of four phases of a digital transformation: setup, piloting, scaling and implementation, and sustaining changes. Notably, while following every practice within each phase correlates with more successful outcomes, the responses suggest that some practices in each stage are particularly critical.

## Setup

During the setup of a digital transformation, the results suggest that communicating clearly and establishing priorities are the most important practices for the successful management of that effort (Exhibit 3). When respondents agree that their organizations’ desired outcome for the digital solution was clearly communicated prior to its launch, they are 3.5 times likelier than others to report a successful transformation. When potential ideas for the digital solution are prioritized clearly, success is 2.7 times more likely. Expertise is also a success factor. Forty-seven percent of respondents report that implementation is successful when people with the most relevant expertise develop the business case for the digital solutions. When the business case was developed by others in the organization, such as the program-management office, just 18 percent of respondents report success.

## Piloting

Communication also is a differentiator for success among the piloting practices. Half of respondents report success when the timeline for implementation is communicated clearly; only 16 percent report success when it isn’t. Likewise, skills management has a strong bearing on transformation outcomes. Respondents are three times more likely to report success when piloting and rapid prototyping help to identify necessary new skills, and more than two times likelier to report it when their organizations have clear processes for identifying the necessary external skills.

## Would you like to learn more about McKinsey Implementation?

## Scaling and implementation

In 2014, respondents cited scaling and implementing as the phase most critical to a major change effort’s success. In the newest survey, responses point to the importance of key performance indicators (KPIs) to ensure that the solution is having the desired effects (Exhibit 4). Among respondents who say that their organizations monitor KPIs as part of implementation, 51 percent report success, compared with only 13 percent who report it where KPIs are not monitored. Success is also over three times more likely when organizations train employees to use the digital solution, establish clear processes for handing off solutions to specific business units, and enable employees to master solutions as soon as they are implemented.

## Sustaining changes

Finally, once a digital solution has been implemented, the most important practice for sustaining changes is embedding the solution’s KPIs (developed during setup and tracked during scaling and implementation) into the organization’s long-term processes. The responses suggest that organizations following this practice are seven times more likely than others to see successful transformations. Further, success is more than four times likelier when the organization focuses on two other practices: ensuring meaningful change in how the organization operates after the solution is implemented and allowing employees across the organization to improve and refine the new solution continually.

## Looking ahead

In response to challenges the survey results revealed, here are some steps executives and their companies can take to improve the implementation of major change efforts—and digital change efforts in particular:

• Stay engaged and be aware of blind spots. Given the importance of effective implementation, leaders of companies undergoing both traditional and digital transformations must be fully engaged in the effort. A lack of leadership engagement can put the success of any major change effort at risk. The most senior people can lead the way in a change effort by role modeling new behaviors the transformation requires, for example, and by being conscious of the organization’s ability—or inability—to execute in priority areas. It’s just as important to mind the blind spots and potential problems as it is to know an organization’s strengths of execution.

• Allocate time to finding the right skills. One challenge, even for the best organizations, is sourcing the right resources and capabilities for implementation. It’s critical that companies spend more time deciding which resources, skills, and even individual employees can best support the changes at hand. Once the right teams are on the ground, leaders and managers must allocate time to helping employees prioritize their work. With digital transformations spanning more business units (and often involving more initiatives) than traditional change efforts, it is even more difficult for employees to focus on the right activities. Leaders should be clear about their objectives and communicate early and often with employees to confirm that people focus on the right activities and that their work adds value to the broader transformation.

• Lead with agility. A digital transformation in particular calls for flexibility and agility from both leaders and teams. It’s critical that employees have targeted actions to take, but leaders need to assess progress more effectively and to make adjustments as needed. The reason to focus on KPIs during scaling, implementing, and sustaining changes in a digital transformation stems from the need to respond quickly to a rapidly changing environment. Leaders must be able and willing to assess their change programs continually and not be afraid to pivot to higher-value work when the KPIs tell them to do so.

## Stay current on your favorite topics

## How relevant and useful is this article for you?

## About the author(s)

The contributors to the development and analysis of this survey include Blake Lindsay, a senior implementation leader in McKinsey’s Denver office, as well as Eugéne Smit, a partner, and Nick Waugh, a senior implementation leader, in that office.

They would like to thank Mehmet Baser and Bruce Delteil for their contributions to this work.

## Explore a career with us

## Related Articles

## Disruption, friction, and change: The hallmarks of a true transformation

## Keeping transformations on target

## A roadmap for a digital transformation","{""publication_date"": ""February 5, 2018"", ""authors"": [""the contribution of each respondent\u2019s nation to global GDP""], ""word_count"": 1944, ""reading_time_minutes"": 10}",2025-03-14 12:41:31.223544
46,Lean management or agile? The right answer may be both,https://www.mckinsey.com/capabilities/operations/our-insights/lean-management-or-agile-the-right-answer-may-be-both,deploying Industry 4,"## Lean management or agile? The right answer may be both

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

Has there even been a time when customers were more demanding of the companies serving them? Industry 4.0 technologies—many barely imaginable only a decade ago—have already enabled genuine breakthroughs in cost, convenience, and customization, creating extraordinary value for buyers while raising the performance bar for producers ever higher.

And then there’s the volatility that never entirely disappears, flaring up in crises that can upend everything from supplier relationships to entire business models—all prevalent in today’s current landscape as Covid-19 creates widespread disruption. It complicates leaders’ efforts to make lasting changes in their organizations—efforts that historically have required years of sustained effort to take root.

Institutions ranging from aerospace manufacturers to tax authorities have nevertheless persisted, focusing their efforts on lean management and agile. Both methodologies have proven their worth as integrated systems for helping improve performance.

The mistake we find many leaders and organizations making is believing they need to choose between the two. In fact, that’s not true. Not only is choosing unnecessary, but the two methodologies complement one another in ways that increase the impact they generate, often by deploying Industry 4.0 technologies to speed transformation. Under this best-of-both approach, top-performing companies combine tools, ways of working, and organizational elements from each to form a custom solution that meets the company’s unique needs more completely and quickly than has been possible.

## Would you like to learn more about our Operations Practice?

## Lean’s legacy, agile’s momentum

Lean management has helped organizations create value for over 70 years. Starting in the 1940s with its roots in the Toyota Production System, lean management has spread from manufacturing to service operations and just about every other department and function at companies, governments, and non-governmental institutions around the world. Lean organizations seek to identify and eliminate activity that is not valued by the customer or end user. This systematic analysis of processes and value streams to reduce waste, variability, and inflexibility boosts performance in cost control, product quality, customer satisfaction, and employee engagement—often simultaneously. Moreover, these companies apply a mindset of continuous improvement and flexible working processes in which all employees contribute new ideas and suggestions, so that the organization becomes better over time. Freed from non-value-generating tasks, people focus more on what matters to customers.

Agile is more recent, originating in software development in the 1990s accelerating after the release of the Agile Manifesto in 2001. Over the past decade, agile has rapidly expanded into other industries, such as telecommunications and banking—and, more recently, heavy industries such as mining and oil and gas.

Rather than the traditional process of developing a new product or service—which used to be highly sequential and time-consuming—agile is much quicker and more flexible. Agile models call for iterative development that aims to get an early prototype of a new product or service out into customers’ hands as quickly as possible. Teams then capture feedback and iterate via quick cycles, refining the product or service over time. Agile approaches have since expanded beyond the realm of product development, and companies are increasingly organizing for agility across all their activities.

## Better together

A common misconception is that lean management and agile are mutually exclusive, based on fundamentally different principles and approaches and applicable for very different types of activities. Lean management is for routine, repeatable operations, this thinking goes, while agile only applies to projects or creative tasks. Therefore organizations, departments or functions need to pick one and focus on it exclusively.

However, that argument reflects a fundamental misunderstanding of both lean management and agile. In reality, both systems have been successful across a range of environments, and both share a similar set of foundational objectives: to deliver value efficiently for a customer; discover better ways of working to continuously learn and improve; transparently connect strategy and goals to give teams meaningful purpose; and enable people to contribute and lead to their fullest potential (Exhibit 1).

A cogwheel made up of four interconnected, circular arrows representing the four integrated disciplines of the lean management system.

The arrows are intended to “spin” in circles as a sign of “being alive” or working as they should, indicating that if one is not working, all others will stop as well.

The four disciplines are:

• 1: Connecting strategy, goals and meaningful purpose (middle, top of the wheel)

• 2: Delivering value efficiently to the customer (middle, bottom)

• 3: Enabling people to lead and contribute to their fullest potential (left, middle)

• 4: Discovering better ways of working (right, middle)

End of image description.

These objectives apply to any team or activity across an organization. There are, however, different ways of achieving them. Both lean management and agile provide team models, ways of working, and toolkits that can be deployed in any way that makes the most sense for an organization (Exhibit 2). The fact that the two systems build on the same foundational beliefs makes their elements highly complementary. Morever, operational excellence often cannot be achieved through lean management or agile exclusively but rather through the combination of both systems, using associated toolkits.

A table that compares Lean Management to Agile along three Levels. Level 1: “Team models”, level 2: “Ways of Working” and level 3: “Toolkit”. A statement to the right of the table reads “Team models” and “Ways of Working” are deployed as needed based upon the nature of the activity, while “Toolkit” is applicable everywhere across the organization.

The body of the table lists examples of Lean Management or Agile for each level, as follows:

• Level 1, Team Models: (A) Lean Management: Work cells, Expert choreography, Segregating variability, and Relationship service cells. (B) Agile: E2E (End-to-End) cross-functional squads, Flow-to-Work, Self-managing teams, and Specialist pools.

• Level 2, Ways of Working: (A) Lean Management: Lean Management practices, Kaizen / continuous improvement, Kanban / Visual workflow management, and Jidoka / self-monitoring automation. (B) Agile: Scrum, Extreme Programming, and Kanban.

• Level 3, Toolkit: (A) Lean Management: Stand-up / Daily performance dialogue, Value-stream mapping, Leader Standard Work, Root cause problem solving, 5S / workplace management, And Visual Management. (B) Agile: Daily Standup, Backlog, and Sprints.

Beneath the entire table, a call-out box states that all the above are “Underpinned by a common mindset and consistent set of principles”.

End of image description.

## Connect talent and unlock value

Team models are organizational constructs that bring together individuals in an operating model to deliver value. Lean management introduces team models such as work cells, in which teams work together to complete steps that previously happened separately and were vulnerable to delay. Meanwhile, agile relies on concepts such as cross-functional teams and flow-to-work pools, which follow the same underlying philosophy. Some ideas are similar across both systems but with different names. For example, lean management’s relationship service cells, an advanced type of work cell for longer-cycle projects, have many features in common with agile’s self-managed teams.

## New and better ways of working

Ways of working are approaches or processes that teams use to get work done over time. Lean management includes integrated management practices and continuous improvement, or kaizen, with agile adding “scrum” teamwork management and extreme programming, emphasizing short development cycles and frequent releases. Not surprisingly, some ways of working, such as visual management tools, appear in both lean management and agile.

Typically, when someone says, “Lean management is for routine, repeatable operations,” they are really talking about something like a lean work cell applying a methodology for continuous improvement. Similarly, an assertion such as “Agile is for creative product development” typically conflates agile with a cross-functional squad applying scrum, which requires a high level of communication for a team to achieve a common goal. Such statements fundamentally misconstrue both systems.

The right team model, way of working, and tools to use will depend on the nature of the activity being conducted (Exhibit 3). While lean management indeed was created for highly repeatable and predictable processes, over time it branched out to expert choreography, which coordinates complex interactions so that interdependencies are resolved before they become blockages, and relationship service cells, where processes center on a single point of contact with the customer. Agile found its origin in creative, customer-facing environments, but concepts like multifunctional and self-managed agile teams are now also being used in back-offices or call centers. The best selection of team models, ways of working and tools may be a combination from both lean management and agile.

A 2-by-2 matrix in which the Agile and Lean Management Team models are color-coded. Each Agile Team model references “Example activities” outside of the exhibit.

Matrix structure: X-axis = “Nature of the activity”: “Repeatable Operational” on the left-hand side, and “Creative, customer facing” on the right-hand side. Y-axis = “Nature of demand”: “Predictable” at the bottom, and “Variable” at the top.

Team models are visualized as:

• Work cells – X-axis left hand side, Y-axis bottom-half, meaning this team model is suited for “Repeatable Operational” activities with “Predictable” demand

• Expert choreography – X-axis in the middle with a strong tendency towards the right-hand side, Y-axis top-half, meaning this team model is suited for “Repeatable Operational”, but mostly “Creative, customer facing” activities with “Variable” demand

• Segregating variability – X-axis left hand side, Y-axis top-half, meaning this team model is suited for “Repeatable Operational” activities with “Variable” demand

• Relationship service cells – X-axis in the middle with a slight tendency towards the right-hand side, Y-axis bottom-half, meaning this team model is suited for “Repeatable Operational” and “Creative, customer facing” activities with “Predictable” demand

• E2E (End-to-End) cross-functional squad – X-axis on the right-hand side, Y-axis in the middle with a slight tendency towards the top-half, meaning this team model is suited for “Creative, customer facing” activities with “Predictable” and/or “Variable” demand

• Flow-to-work – X-axis on the left-hand side, Y-axis top-half, meaning this team model is suited for “Repeatable Operational” activities with “Variable” demand

• Self-managed teams – X-axis in the middle spreading across both options, Y-axis bottom-half, meaning this team model is suited for “Repeatable Operational” and “Creative, customer facing” activities with “Predictable” demand

• Specialist pool – X-axis in the middle with a slight tendency towards the right-hand side, Y-axis top-half, meaning this team model is suited for both “Repeatable Operational” but even more “Creative, customer facing” activities with “Variable” demand

Example activities for each agile team model are listed as:

• E2E (End-to-End) cross-functional squad: Developing asset plans, Feasibility studies, Project concept studies, Integrated planning, Facilities optimization, Energy management, Digital-factory, and M&A.

• Flow-to-work: HR Services (recruitment, learning), Data management, and Remote engineering and design support.

• Self-managed teams: Production operations and maintenance, Support-function platform tasks (accounting and reporting, procurement), Performance management, and Resource accounting.

• Specialist pool: Business partnering, Engineering support, and Quality assurance.

End of image description.

## Transform the whole business, not just parts

## The value of two

A growing number of companies are getting better results under a best-of-breed model than they could by applying either lean management or agile systems on their own. Consider the following two case studies.

## Financial institution dramatically improves customer service

A financial services provider was struggling with customer service. Its contact center was taking far too long to resolve inquiries—up to eight weeks in some cases—in part because the specialist teams were overwhelmed by the sheer volume of customer requests. Worse, the firm had no designated owner for the entire customer-service journey. Instead, it operated under a traditional structure in which requests were passed from one function to another. Each function operated independently, tracking performance metrics only for their own slice of the process. No one was looking at the entire experience from a customer’s perspective.

The company used a combination of lean management and agile tools to improve. From the lean management toolkit, it used value-stream mapping and design thinking to completely rethink and restructure the customer experience for a given transaction or process. It also revamped key performance indicators to better reflect specific goals—for example, how fast a customer could get his or her issue resolved. From agile, the company created self-managing, cross-functional teams to improve collaboration and foster accountability. The new self-managing team enabled employees to handle all types of customer requests from end to end. Management also established a single point of contact for each process to reduce the number of internal handoffs and improve customer engagement.

Collectively, this approach led to a 90 percent reduction in the average time required to resolve a customer issue. Not surprisingly, customer satisfaction scores increased by 30 percent, as did employee engagement. The reorganization means that teams are no longer bogged down by bureaucracy and instead can see how their individual contributions have a direct result on the customer experience—and thus on the company’s overall performance.

## A mining company creates a new operating system

In the second example, a global mining company had been deploying lean management tools among frontline units for more than a decade with significant success. Frontline operations at a mining site have several attributes—physical operations, a constant workflow, predictable customer specifications and repeatable processes—that make them ideal for lean approaches like six sigma.

However, commitment and progress had stalled in recent years. To jump-start gains, the company began to apply some agile tools, ways of working and team models. Even in a process industry like mining, many activities require cross-functional collaboration and operating in variable environments, from developing new strategies and engineering process improvements to deploying innovative technologies. Agile team models such as the cross-functional squad are ideally suited to that kind of work and delivered impressive results: dedicated improvement squads increased engineering velocity by 200 percent, and a cross-functional “fuel and energy” transformation squad identified and delivered $10 million of value within months.

More broadly, the company found that the agile transformation could be the banner to improve and reinvigorate the existing lean management program among frontline units. The company selected a few specific tools from the agile toolkit and integrated these into daily, lean management-led operations.

The company established four-week sprint cycles—a time period that aligned with the rotation of workers at the front line. At the beginning of each sprint, teams gather to look over the plan for the upcoming four weeks and identify key events, such as major projects, visits by leaders, or onboarding of new employees, along with one or two themes where they want to explicitly focus their improvement activities. Similarly, at the end of each sprint, teams hold a retrospective session to analyze their performance against the objectives for that sprint and identify how they can work together more effectively in the future.

This relatively simple change—combined with a renewed focus on daily standups and visual management—led to a significant increase in engagement among the workforce with over 90 percent of frontline teams actively owning improvement initiatives and approximately 130 incremental improvements delivered within the first three months.

As these two examples show, lean management and agile are both powerful systems, and companies don’t need to choose between them as either-or options. Rather, companies can apply this all-of-the-above approach, choose the tools and applications that are most relevant for their needs, and thus generate even greater improvements across the entire organization.

## How relevant and useful is this article for you?

## About the author(s)

Stefan de Raedemaecker is a partner in McKinsey’s Brussels office, Christopher Handscomb is a partner in the London office, Sören Jautelat is a partner in the Stuttgart office, Miguel Rodriguez is an expert in the Barcelona office, and Lucas Wienke is an expert in the Hamburg office.

## Explore a career with us

## Related Articles

## Jump-starting resilient and reimagined operations

## Reset and reallocate: SG&A in the next normal

## Unlocking enterprise efficiencies through zero-based design","{""publication_date"": ""July 14, 2020"", ""authors"": [""deploying Industry 4""], ""word_count"": 2703, ""reading_time_minutes"": 14}",2025-03-14 12:41:37.736698
47,How cities can adapt to climate change,https://www.mckinsey.com/capabilities/sustainability/our-insights/how-cities-can-adapt-to-climate-change,"assets, people, and services because of climate change","## How cities can adapt to climate change

Cities are on the front lines of the growing physical risks associated with climate change.1“Physical risks associated with climate change” refer to the direct and indirect losses expected to be incurred by assets, people, and services because of climate change. They are home to more than half of the world’s people, and by 2050, that figure is projected to rise to 68 percent.2“68% of the world population projected to live in urban areas by 2050, says UN,” United Nations, May 16, 2018, un.org. Urban areas are often located in places of particular climate risk, such as on coastlines, floodplains, and islands. Moreover, modern urban infrastructure and its operating systems are closely connected. A failure in one part of a network can affect another, multiplying the damage. Flooded roads, for example, can damage links to public transport. Storm surges and extreme heat can lead to power outages that knock out the technology systems critical to homes, hospitals, and industries.

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

Given existing greenhouse-gas emissions, some climate change is already locked in, making such risks unavoidable. To protect the lives and livelihoods of urban residents, the imperative is to adapt—and to start now. Climate change could increase the severity and frequency of extreme heat, flooding, drought, and wildfires—the specific hazards addressed in this report.3The future we don’t want: How climate change could impact the world’s greatest cities, a joint report from Acclimatise, C40 Cities Climate Leadership, Global Covenant of Mayors for Climate & Energy, and Urban Climate Change Research Network, February 2018, c40.org. More than 90 percent of all urban areas are coastal; by 2050, more than 800 million urban residents could be affected by sea-level rise and coastal flooding.4Based on analysis of 2,586 global cities by C40 Cities Climate Leadership. In addition, 1.6 billion people could be vulnerable to chronic extreme heat (up from 200 million today), and 650 million could face water scarcity.5The future we don’t want, February 2018.

Because different cities face different climate risks and have varying levels of vulnerability, adaptation options that are effective in most may not be feasible in others. To manage that complexity, cities can concentrate on actions that play to their strengths (in resources, physical features and assets, and jurisdictional control) and offer a high return in risk reduction. Identifying such high-impact adaptations can be daunting, given the steadily developing nature of the climate threat and the dizzying array of adaptation options available.

This report, cowritten with C40 Cities Climate Leadership, a network of large cities that are committed to addressing climate change, seeks to help leaders set priorities and choose courses of action. It identifies a starting list of 15 high-potential actions that can work for many types of cities. The actions were chosen on the basis of three main sources: C40 Cities Climate Leadership and McKinsey analysis, consultation with adaptation experts and city leaders, and an extensive literature review.

There are two parts to the report. The first sets out the 15 actions. Four of them build systemic resilience, meaning they strengthen all kinds of cities. The other 11 are hazard specific, meaning they target particular physical climate risks. Some of the 15 actions, such as building barriers to protect coastal areas and retrofitting infrastructure, are complex and expensive. Others, such as planting trees next to streets and initiating behavioral-change programs to conserve water, aren’t. Examples from all over the world, in both advanced and developing economies, demonstrate what’s possible.

The second part of the report describes, in broad terms, how cities can implement the actions. We suggest that they begin by defining the most relevant hazards and by understanding the risks those hazards pose to their communities. On that basis, cities can then conduct detailed analyses of the risk-reduction impact, costs, and feasibility of different actions.

Several important themes emerge from the research. First, nature-based solutions—such as planting trees next to streets, river-catchment management, and sustainable urban-drainage solutions—are among the most attractive actions because of their impact on reducing risks and their feasibility. Nature-based solutions also often provide benefits beyond adaptation in areas such as decarbonization, economic growth, and health.6Adapt now: A global call for leadership on climate resilience, Global Center on Adaptation, September 13, 2019, gca.org.

Second, cities can invest in actions that increase resilience systemically, in addition to adapting to specific and immediate hazards. Systemic resilience includes increasing awareness of physical climate risks, incorporating risk awareness and preparedness into city processes, optimizing emergency responses, and enhancing financial and insurance programs.

Third, there’s an important equity element to climate-risk adaptation. Vulnerable populations, such as children, the elderly, low-income communities, some minority groups, people with disabilities, and women, may be at higher risk for climate-related damage. For example, continued rapid urbanization is leading to increased populations in informal settlements.7Aromar Revi et al., “Urban areas,” Climate change 2014: Impacts, adaptation, and vulnerability, Part A: Global and sectoral aspects, Intergovernmental Panel on Climate Change, 2014, ipcc.ch. They often lack the resources and adaptive capacity to withstand major events, such as floods and extreme heat.

Climate risk directly affects people (health, livability, and workability), assets (businesses, homes, and hospitals), and services (energy and food supply). This report can serve as a starting point to help cities develop their agendas for adaptation. Leaders will need to go deeper as they work out their strategies. Local knowledge is critical to success.

At the same time, climate adaptation is one of many competing priorities, and urban resources are limited. By identifying the most effective and feasible actions, cities can focus on executing them well and build momentum to do more. This report is a call to action—focused action. We hope that it will help cities play an important role in making swifter, surer progress toward a healthy and sustainable future.

## How relevant and useful is this article for you?

## About the author(s)

Brodie Boland is a partner in McKinsey’s Washington, DC, office; Elizabeth Charchenko is a consultant in the New York office, where Shivika Sahdev is a partner; and Stefan Knupfer is a senior partner in the Stamford office.

## Explore a career with us

## Related Articles

## A strategic approach to climate action in cities—focused acceleration

## Can coastal cities turn the tide on rising flood risk?

## Will infrastructure bend or break under climate stress?","{""publication_date"": ""July 20, 2021"", ""authors"": [""assets"", ""people"", ""and services because of climate change""], ""word_count"": 1118, ""reading_time_minutes"": 6}",2025-03-14 12:41:45.017608
48,Agile funding: An investment management approach to funding outcomes,https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/agile-funding-an-investment-management-approach-to-funding-outcomes,,"## Agile funding: An investment management approach to funding outcomes

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

Over the past decade, many organizations have shifted to an agile mode of delivery, fueled by the need to increase their “metabolic rate” and build new ways of working to allow teams to continuously test, learn, and adapt.1“The journey to agile: How companies can become faster, more productive, and more responsive,” McKinsey, October 5, 2020. They’ve reorganized people and work, with a focus on agile portfolios that align with profit-and-loss (P&L) or business line priorities—also known as tribes, domains, or value streams. These agile portfolios include user journeys, products and shared platforms, and embedded agile roles (such as product owner or agile coach). The benefits are evident: persistent, mission-based and cross-functional agile portfolios can respond more quickly and precisely to market shocks and changing customer needs—not only during crisis situations but also systematically.

Yet as these agile portfolios reach scale, C-suite executives struggle to align them with enterprise goals and continually adjust investments as those goals evolve. What they need—and what only a small handful of companies have truly applied—is an approach akin to that commonly used by investment companies:

• The executive committee sets top-of-the-house goals and assigns a fixed budget to each agile portfolio (at least for the coming year) based on aligned expectations for the outcomes that each portfolio will deliver to meet these goals.

• Agile portfolios then direct the prioritization and execution of work by the agile teams to maximize outcome delivery while operating within the allotted budget.

• The portfolio lead continually measures outcomes delivered against the target—including any P&L impact—and actively drives decisions about how to deploy available capacity toward the highest-value work.

• The executive committee maintains the flexibility to assess and reallocate the budget—for example, if enterprise goals shift or certain portfolios are not delivering expected outcomes.

Supporting agile delivery in this way calls for fundamental changes in finance and strategy that can seem daunting, especially to large legacy incumbents that have rigorous, long-standing financial processes embedded in their organizational DNA. However, if agile transformation is an intentional journey for organizations committed to fundamentally changing their ways of working, then it is time to take the next step.

This article describes why traditional funding inhibits, rather than promotes, agility and explains the four shifts companies should consider making to effectively fund outcomes.

If agile transformation is an intentional journey for organizations committed to fundamentally changing their ways of working, then it is time to take the next step.

## Traditional funding models are at odds with agile principles

Traditionally, funding has been an important vehicle for C-suite leaders to exercise control and ensure alignment on enterprise goals. However, traditional funding contradicts the fundamental principles of agility in several respects:

• It favors large-scale initiatives that are extremely well detailed at inception and then held constant. Agile, in contrast, emphasizes continuous discovery and testing of outcomes through minimal viable products (MVPs), with teams empowered to adjust their approach based on market feedback.

• It does not proactively reallocate resources based on interim outcomes. Agile, on the other hand, is anchored in the ability to quickly pivot resources to the highest priority as needed.

• It often assesses financial and operational outcomes post-mortem, once the project is done and the budget consumed. Agile uses these outcomes as a yardstick to test the efficacy and impact of work as it is being delivered.

To create truly agile enterprises, corporate leaders must overhaul traditional funding principles—the next major step in the agile journey for the large incumbents across industries that have piloted agile in the past few years. According to McKinsey analysis,2Gregor Jost, Deepak Mahadevan, David Pralong, and Marcus Sieberer, “How COVID-19 is redefining the next-normal operating model,” McKinsey Quarterly, December 10, 2020. organizations leveraging advanced agile practices, including agile funding, were able to react to changes driven by the COVID-19 pandemic up to twice as fast as the national average (Exhibit 1).

## Four shifts support the switch to agile funding

By focusing on making four shifts, organizations can transition to a funding approach that supports their agile aspirations and maintains enterprise-wide alignment with strategic goals.

## From funding transitory projects to funding persistent portfolios

Traditionally, during the annual “budget season,” funding and planning committees spend up to six or eight months determining the size and scope of projects to fund in the next year, with a high degree of precision regarding their business cases. Projects then kick off throughout the year, often with little prioritization. Projects that start later in the year may even need to go back to funding and planning committees for reapproval, especially if the budgeted resources are not naturally available due to overruns or scope changes with projects already in flight. Many of these projects never get under way and are carried over to the next year. In short, how the year starts and how the year wraps up are markedly different, despite the extensive planning effort invested up front. As an example, prior to implementing agile funding, one North American financial institution realized that up to 50 percent of its funding was getting absorbed into unplanned or lower-priority work, leading to a failure to launch many of the top planned priorities.

By contrast, agile organizations shift from funding projects to funding persistent portfolios, each with a discrete mission (Exhibit 2). These portfolios define and strictly prioritize their target outcomes for the year—sometimes referred to as objectives and key results (OKRs)—and determine the fixed number of agile teams needed to achieve the intended outcomes. Each agile team is also typically a fixed-size unit comprising six to nine dedicated individuals with cross-functional skills from business, IT, and any other supporting function needed to complete the mission.

The funding sought by each portfolio is a function of the number of teams they need and any nonlabor expense estimates, such as licensing costs. Once approved, the team capacity is assumed to be fixed—at least for the fiscal year—and the funding envelope is allocated to the portfolio as a combination of capital expenditures and operational expenditures. The portfolios kick off work immediately, with their allocated teams starting on a backlog prioritized to deliver the top-priority outcomes per their target timelines.

Allocating funding to these portfolios with strictly prioritized outcomes has allowed the financial institution mentioned earlier to deliver on more than 80 percent of the top enterprise priorities outlined at the start of the year. It has also brought a higher degree of predictability to business planning and change execution as a result.

Prior to implementing agile funding, one North American financial institution realized that up to 50 percent of its funding was getting absorbed into unplanned or lower-priority work, leading to a failure to launch many of the top planned priorities.

## From funding long-range efforts to funding iterative outcomes

Traditionally, funds are allocated to projects for their entire duration based on their intended outcomes. As a result, the fund distribution across projects is anchored in the effort needed to deliver on each, rather than on their ability to demonstrate early value. Thus, organizations often find that massive investments can become locked in to low-performing projects while mission-critical needs remain queued up and awaiting execution.

A situation such as this may give the appearance that C-suite leaders are not paying attention to project outcomes, but this is untrue. In fact, project leaders take pains to estimate ROI and internal rates of return when submitting their business cases. Instead, such queues occur because funding gets committed based on long-term outcomes with no way for executives to assess how these projects are performing along the way. OKRs play a key role in shifting investment decision making toward measurable outcomes.

C-suite leaders set enterprise goals or OKRs annually in close collaboration with portfolio leaders and use them as a vehicle to drive strategic alignment on priorities across the company. Portfolio leaders, in turn, work with product owners to create portfolio-level OKRs that guide work for the next 90 days and that eventually become enterprise OKRs (Exhibit 3). Multiple portfolios often work together to achieve enterprise OKRs, which helps to break silos and allows colleagues to collaborate beyond their specific portfolio. A product owner from a leading telecom company based in Asia–Pacific endorsed this approach, saying, “In my 25 years at this company, I have never seen strategy this close and context this clearly.”

OKRs not only provide a tight feedback loop between C-suite leaders and the agile teams driving day-to-day execution, but they also allow funding to be anchored to iterative tranches of outcomes. The portfolios publish the specific outcomes they will drive during the year, with a deep view into which parts will be measurable in the next three to six months. As a result, the up-front funding allocation at the start of the year has a more concrete and near-term yardstick to calibrate investments and ensure that the highest-value outcomes receive adequate capacity early on.

## Would you like to learn more about McKinsey Digital?

## From immovable monolithic investments to fluid funding allocations based on performance

Many traditional organizations struggle to pause or stop initiatives that are not achieving their intended objectives because they don’t review outcome delivery until a project is completed, which often is too late. In fact, substantial effort goes into governing project schedules and spending, yet none goes into assessing whether the project is expected to yield the value promised in the up-front business case. Similarly, they are unable to dynamically allocate talent, such as a high-performing data scientist or marketer, to maximize returns because these team members are isolated and “protected” within project silos.

Agile companies create transparency into portfolio performance and have the flexibility to shift priorities and talent through a quarterly business review (QBR) process.3For more on the quarterly business review process, see McKinsey Organization Blog, “Quarterly Business Review: How to extract benefits beyond transparency,” blog entry by Quentin Jadoul, Akos Legradi, and Dániel Róna, McKinsey, October 5, 2020. During the QBR, executive teams and business unit portfolio leaders come together to check progress against outcomes from the previous quarter, assess priorities for the next quarter, and reallocate resources accordingly. Pivoting resources is a common practice (Exhibit 4).

A global retail client implemented QBRs and introduced a prioritization approach that evaluated performance and established a “kill rate” metric to track the percentage of low-value-added work stopped or paused every quarter.

## From finance as a control function to finance as a strategic business partner for continual value capture

Traditionally, finance is seen as a control function, asking questions and conducting audits of project costs and schedule overruns. Project leaders see financial reporting as overhead, given that not much of the reporting informs day-to-day decisions. Worse yet, applying this reporting approach to agile portfolios creates significant friction because continuously evolving agile backlogs don’t conform to the model.

With the shift to agility, the accountability for managing outcomes against spending falls more heavily on portfolio leaders. Each portfolio leader (and each product owner within the portfolio) functions as a “mini CEO” responsible for continuously monitoring progress. Finance (or a dedicated financial planning and accounting partner) plays a pivotal role in providing timely, relevant insights on spending and financial outcomes to the portfolio leader, who can then decide how to shift capacity toward higher-priority outcomes. To enable this, portfolio leaders and their teams would ideally receive real-time reporting on the following:

• progress on results (OKRs), including P&L metrics from finance, such as impact on revenue (for example, through improved retention or renewal rates) and cost (through operational improvements)

• resource consumption tracked against the budget envelope, including an integrated view of capital expenditure and operational expenditure utilization (including enterprise-level allocations such as hardware costs) per agile sprint; this information would be provided by finance

• agile-delivery metrics such as progress on backlog execution (for example, using burn-up or burn-down charts that show, respectively, how much work is completed or remaining), team engagement, time to market, and quality

Finance plays a critical role in standing up a unified infrastructure that makes this information accessible and acts as a problem-solving partner to portfolio leaders, helping them translate insights into action and demonstrate the value of the portfolio to the enterprise. This fundamental change in finance’s role depends as much on a shift in mindset as it does on investments in new processes and tools.

## Planning in an agile organization

## Getting started

As with everything in agile, the best way to try a large-scale effort is to start with a high-level vision and blueprint of the target state, pilot the new methodologies, and then continually refine the nuances based on the results.

One approach is to work backward from the next funding cycle in three phases:

• Phase one. Start early in the year, and use the first and second quarters to give key executives time to align on the high-level blueprint. Outline what will be new, what will get phased out, and what will be retained in the future-state operating model.

• Phase two. During the second and third quarters, run two batches of pilot QBRs to provide training on the fundamentals, including, for example, OKR-based prioritization and reporting at QBRs. This will help the portfolio come up to speed on shifting to outcome-based planning and decision making—in time to apply these tools in the upcoming annual funding cycle.

• Phase three. Shift to the new, persistent outcome-backed funding model in the fourth quarter for portfolios that have completed pilots. Complete the rollout over the next few quarters as remaining portfolios come up to speed.

## Pitfalls to avoid while shifting to agile funding

Organizations can bolster their chances of success when designing the new funding operating model by avoiding a few common pitfalls:

Not aligning agile portfolios to the way business is structured. Too often, portfolios mirror IT architecture instead of the way the business and customers operate. This makes it challenging to align funding neatly to business outcomes given that almost all outcomes may end up getting fragmented across multiple portfolios. Outcome-based planning and funding becomes much more effective if the portfolios mirror business priorities, enabling one-to-one mapping of portfolios to outcomes and outcomes to funding.

Running old and new models concurrently for too long. Even if the organization has a mix of agile and nonagile teams, it is important to adopt a single funding and planning model, including leveraging concepts like OKRs and QBRs, to harmonize governance and investment decision making. Maintaining two funding models creates additional overhead and makes it difficult to consistently integrate new approaches, define roles and responsibilities, and align on shared language and tools.

Insufficient automation of tracking spending and outcomes. Absent a sufficient level of automation, manual overhead increases, as does the likelihood of human error. It becomes an impossible challenge for portfolio managers to continually track work and outcomes. As a result, ongoing conversations about outcomes—during annual planning and funding cycles or during QBRs—might remain suboptimal, diluting the confidence of senior executives.

Leaders micromanaging teams and failing to adapt to outcome-driven decision making. Leaders should engage and share direction on target outcomes and milestones at a strategic level while allowing teams to chart their own course for how to best deliver on those goals. Executives who are overly involved in backlog-level work may lose sight of overarching enterprise goals, preventing teams from making informed, nonbureaucratic decisions based on their ground-level facts and observations.

Pivoting to agile funding can be extremely challenging for CFOs because funding and budgeting mechanisms are ingrained in most organizations—and rightfully so, given their role in P&L and financial risk management. However, the idea is not to uproot the financial rigor that financial planning and accounting functions need to maintain from a risk, regulatory, and business management perspective. Instead, it’s to refine the way that change portfolios are funded and tracked to allow greater transparency and control into how investments are being consumed. Designing the shift to agile funding, therefore, requires careful decision making along multiple parameters. Courage and commitment to the new approach from senior leaders can help agile practitioners and finance professionals come together to truly improve planning and funding methodologies and mindsets and to prepare their organizations for the future.

## How relevant and useful is this article for you?

## About the author(s)

Santiago Comella-Dorda is a partner in McKinsey’s Boston office, and Marami Kar is a partner in the New York office, where Arun Sunderraj is an associate partner.

The authors wish to thank Mishal Desai, Christopher Handscomb, Michele Tam, and Konstantin Tyrman for their contributions to this article.

## Explore a career with us

## Related Articles

## Agility to action: Operationalizing a value-driven agile blueprint

## The journey to an agile organization

## The five trademarks of agile organizations","{""publication_date"": ""October 7, 2022"", ""word_count"": 2868, ""reading_time_minutes"": 14}",2025-03-14 12:41:51.575892
49,Will generative AI hurt middle managers—or help them?,https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/will-generative-ai-hurt-middle-managers-or-help-them,"Lucia Rahilly, Roberta Fusaro","## Will generative AI hurt middle managers—or help them?

Bogged down, bothered, beleaguered: Many middle managers have it bad—and they can also have a bad rap. In Power to the Middle: Why Managers Hold the Keys to the Future of Work (Harvard Business Review Press, July 2023), McKinsey talent experts Bryan Hancock and Emily Field sought to correct that misperception, clarifying the vital role the best middle managers play in competitive outperformance. And then, in walked generative AI (gen AI)—which middle managers can convert to their advantage. In this episode of The McKinsey Podcast, originally aired on McKinsey Talks Talent, the authors revisit the book one year on, talking with global editorial director Lucia Rahilly about the downside of leadership programs, how to identify and understand different managerial styles, and how middle managers can use gen AI to support their teams more effectively—and update their image while they’re at it.

The transcript has been edited for clarity and length.

The McKinsey Podcast is cohosted by Lucia Rahilly and Roberta Fusaro.

## How relevant and useful is this article for you?

## Related Articles

## Managing in the era of gen AI

## Rethinking the role of the middle manager

## Middle managers are the heart of your company","{""publication_date"": ""August 23, 2024"", ""authors"": [""Lucia Rahilly"", ""Roberta Fusaro""], ""word_count"": 208, ""reading_time_minutes"": 1}",2025-03-14 12:41:58.695032
50,"Operations management, reshaped by robotic automation",https://www.mckinsey.com/capabilities/operations/our-insights/operations-management-reshaped-by-robotic-automation,,"## Operations management, reshaped by robotic automation

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

Few technologies rival the latest advances in automation in their anticipated ability to enhance organizations’ performance, regardless of industry. The potential adoption rate is stunning by any measure: the McKinsey Global Institute estimates that, using demonstrated technologies, more than 81 percent of predictable physical work, 69 percent of data processing, and 64 percent of data-collection activities could feasibly be automated.

## Stay current on your favorite topics

These three categories describe much of the work handled in operations centers, which we define as organizations that manage equipment and services remotely, or that manage human forces in the field (field forces). Examples include telecom and electrical utility network-operations centers (NOCs), IT operations centers, remote resolution centers, contact and call centers, and dispatch centers.

Indeed, the early stages of automation have already begun. Our colleagues’ late-2018 automation survey found that three-quarters of respondents had either embarked on an automation journey, or would do so in the coming year (exhibit). And in our recent studies supporting the introduction of automation technology to operations centers, we’ve witnessed first-hand the extent to which automation can transform the technological paradigm of front-office operations management.

## The automation journey

Robotic process automation (RPA) has been a particular focus of attention, having been widely adopted in organizational support functions—initially in shared-service centers (SSCs) that had taken much of the responsibility for many companies’ HR, finance, procurement, and IT functions. These environments were ripe for the introduction of RPA because many processes were standardized; RPA could therefore be applied to reduce costs (which had been rising) and improve accuracy.

RPA technologies have significantly improved in recent years, providing the high levels of quality and stability required for sensitive, customer-related processes in operations centers. Following the successful implementation in SSCs, organizations started expanding the application of RPA to operations centers in hopes of radically accelerating the automation of operational processes, while also cutting costs.

## What RPA offers operations centers

In most industries, operations centers have used traditional forms of automation for many years. But these came with serious limitations. For example, custom software managed interfaces with multiple backend systems, but these implementations took several years to complete, and were expensive and quite rigid.

By contrast, new automation techniques, such as RPA and cognitive technologies, are having transformative impact. By automating manual and repetitive tasks, successful operations centers are reducing costs by 30 to 60 percent while increasing delivery quality.

## Would you like to learn more about our Operations Practice?

We see three fundamental differences between RPA and traditional automation technologies:

• Accelerated implementation. Like traditional automation techniques, RPA achieves high impact by both lowering costs and increasing the quality of manual tasks—but it does so much faster. Many of the improvements that may have required months, or even years, to achieve can be replicated with RPA technologies in a matter of weeks. This rapid timeline results from RPA’s low barriers to entry and out-of-the-box controls. For example, a telco wholesaler used automation to reduce cycle times in one of its back-end processes by 99 percent. This automation solution took two developers just four days to implement.

• Low barriers to entry. Traditional automation technologies require multiple technology stakeholders, developer teams, user-experience designers, and system instructors. In contrast, RPA can be overlaid on an existing IT infrastructure. It is developed by mirroring the user’s inputs, while customization requires only a minimal programming background. Consequently, training RPA developers typically takes just two to four weeks, compared with more than a year for software engineers. An industrial-services company needed only about a month to train more than 20 remote-center engineers on RPA, combining a one-week training course with three weeks of teaming the trainees with experienced RPA developers.

• Enhanced control. RPA applications come with out-of-the-box monitoring, reporting, and system controls in place. Standard RPA controls include scheduling customization, queue creation, email notifications, and response-triggered actions. The same level of controls and monitoring for software automation must often be developed from scratch.

## What’s best to automate?

Although RPA’s value proposition is attractive relative to traditional technologies, companies must stay focused on feasibility. Within operations centers, there are a few common activities where we have seen RPA add significant value.

Network monitoring. By correlating network events, RPA can generate alarms for multiple standardized (pre-defined) issues.

Remote troubleshooting and resolution. RPA can support issue tracking, data gathering, ticket analysis, and remote reset. Intelligent incident-management systems can detect similar issues and resolve them—such as at a telco that uses RPA to improve its responses to network-equipment failures. The RPA bot executes steps according to a codified troubleshooting guide, leaving human agents to resolve only those issues not yet fully documented.

Automated dispatching. Companies can use automation to dispatch jobs from operations centers to field agents, to handle exceptions in workforce allocation by load-balancing, and to optimize transportation routes for dispatched jobs. These steps help reduce time-to-resolution and increase the amount of time spent on judgment-based work.

Self-help facilities. For routine level-one and level-two requests, RPA can automate ticket logging, routing, and replies, which form the basis of self-help tools for customers. By minimizing the need for in-person call-center support, these solutions improve not only incident tracking, but also customer experience. Automatic analysis of customer call logs enabled one telco provider to reduce call-center agents’ handle times by 10 percent for an entire family of service issues.

## It’s all about impact

Successful RPA-led transformations have focused on capturing value by starting small, exploring select use cases, and scaling up over time. This methodical approach has yielded a wide range of performance improvements at operations centers.

• By automating performance-indicator monitoring and increasing remote-problem resolution, a large managed-services provider reduced its NOC and field-force costs by 20 to 30 percent.

• One large telco provider has automated 80 percent of its resource scheduling, resulting in a 10 percentage-point reduction in escalations and a 15 percent reduction in cycle time and field costs, while another telco used automation to reduce NOC operational costs by 55 percent.

• Automation helped a technical call center reduce its costs by more than 40 percent, while increasing quality of service.

## How lean is your field force—really?

## What are the imperatives for success?

For robotic automation to achieve its full potential across a business, organizations must proceed with care. The leaders’ success stories all rested on a few critical factors, each requiring substantial attention.

## Re-skill your organization

New skills will be essential to ensure smooth execution of the automated processes and create sustainable impact. Among the most critical are the identification, quantification, prioritization, and mapping of new processes that should be automated. Next, solution design, programming, and execution will all involve significant new capabilities, as will the monitoring and management of automation once it is in place.

## Rethink business–IT collaboration

When robotic-automation projects run into problems, a crucial reason is often misalignment between IT and business leaders—who will need a deeper level of cooperation than has historically been typical. Because business users understand the processes and are responsible for operations performance, they must identify which processes to automate, and should participate closely in RPA development. For its part, IT must contribute its advanced technical knowledge and experience in running production-level quality systems, and ensure end-to-end performance of the bots. Close collaboration is also required whenever there is a change in the application, so that bots can be updated appropriately.

## Support the transformation with a CoE

A center of excellence (CoE) is vital both as a source of expertise and to define priorities. This central team, with responsibilities cutting across operations and other functions, leads the organization’s transformation, identifies opportunities for automation, and helps scale up current automation programs. The CoE’s areas of expertise should include attended bots (for call centers), chat bots, advanced analytics, and cognitive agents.

The role of the CoE evolves over time. In the short term (usually the first six months), the CoE’s diverse support responsibilities will include identifying the potential for automation; prioritizing opportunities; managing early proof-of-concept testing; codification of learnings; recruitment of CoE team members; training of business people; and oversight of existing transformations.

In the long term, the CoE’s primary role evolves. Activities include managing the entire transformation from end to end (including prioritization of initiatives and funding), providing technical support for more complex issues, and establishing best practices. The CoE also supports initiatives of varying sizes across the company, seeds subject-matter experts and advocates where needed, and provides thorough coaching to team members. Additionally, the center can give light support to business-led initiatives.

In most situations, we have found it better not to have a separate CoE for operations, but instead to have a single automation CoE for the whole company. Such a CoE will not only be responsible for RPA, but will also serve as an interface with other parts of the organization involved in technologies such as advanced analytics, chat bots, and virtual agents.

The CoE’s support should be guided by four main principles:

• Establish an agile way of working through cross-team collaboration and knowledge sharing. Agile automation follows the “scrum” method as its basic framework. Typically, each use case is addressed in “sprint” cycles lasting two to three weeks. A cycle starts with mapping user stories. It moves on to process analysis and developing a process map at the task level. The final step is technical design and development.

• Drive standardization by ensuring a consistent automation approach and reusability of components across different sprint teams.

• Coordinate with IT for automation delivery and execution.

• Continuously introduce emerging technologies beyond RPA. Because the technology landscape for automation is continuously evolving, organizations must master complementary technologies to apply automation successfully. Beyond RPA, several additional automation technologies are already showing promise. For example, by combining RPA, cognitive agents, and artificial intelligence for image processing, a multinational recently reduced the cost base for one of its operations centers by more than half.

## Focus on creating impact

For a successful transformation, a company needs a comprehensive, end-to-end view of the automation opportunity. It should prioritize automation activities by business value, ease of implementation, and risk. Usually, prioritization is more effective when done within functional “domains” comprising 50 to 200 people rather than on a process-by-process basis—so, for example, for the HR domain as a whole rather than just for the employee-onboarding process. Typically, domains with high business value and high ease of implementation can be quick wins for automation.

In addition, leaders must think through how they will redesign the organization to take advantage of the capacity increases that usually result from successful automation. Moving people promptly to higher-value work helps multiply automation’s impact—but the higher-value work must be identified and available for the people to do. That often means restructuring the organization at the same time that the automation solution is being designed and implemented, so that judgment-heavy tasks flow through to the right teams once the automation is in place.

It is time for companies to transform their operations centers using RPA and other automation technologies. Such a transformation needn’t take long—and can generate tremendous value if done correctly.

## Stay current on your favorite topics

## How relevant and useful is this article for you?

## About the author(s)

Ian Didion is a senior digital analyst in McKinsey’s New York office, where Kobi Masri is a consultant; Pablo Hernandez is a partner in the Madrid office; and Avani Kaushik is a digital expert in the Southern California office.

## Explore a career with us

## Related Articles

## How lean is your field force—really?

## Smarter, faster asset allocation for more coverage at lower cost

## Four success factors for workforce automation","{""publication_date"": ""December 6, 2019"", ""word_count"": 2023, ""reading_time_minutes"": 10}",2025-03-14 12:42:04.528701
51,A practical approach to supply-chain risk management,https://www.mckinsey.com/capabilities/operations/our-insights/a-practical-approach-to-supply-chain-risk-management,,"## A practical approach to supply-chain risk management

In the last decade, a number of organizations have been rocked by unforeseen supply-chain vulnerabilities and disruptions, leading to recalls costing hundreds of millions of dollars in industries ranging from pharmaceuticals and consumer goods to electronics and automotive. And multiple government organizations and private businesses have struggled with cybersecurity breaches, losing critical intellectual property due to failures in the supplier ecosystem.

## Stay current on your favorite topics

At the heart of these crises is a common theme—the lack of robust processes to identify and successfully manage growing supply-chain risks as the world becomes more interconnected. New threats, such as cyber-ransom attacks, are emerging alongside more traditional and longer-acknowledged supplier risks, such as supplier bankruptcy.

The challenge of supply-chain risk management has been exacerbated by globalization, where even sensitive products like defense systems use raw materials, circuit boards, and related components that may have originated in countries where the system manufacturer did not even know it had a supply chain. This increased complexity has brought with it more potential failure points and higher levels of risk.

Yet progress in addressing these risks has been slow. In our 2010 survey of 639 executives covering a range of regions and industries, 71 percent said their companies were more at risk from supply-chain disruption than previously, and 72 percent expected those risks to continue to rise. In 2018, the United States government stood up multiple agencies and task forces to better address supply-chain risk (including the Critical Infrastructure Security and Cybersecurity Agency in the Department of Homeland Security and the Protecting Critical Technology Task Force at the Department of Defense), and the private sector continues to seek a uniform and proven methodology for assessing and monitoring risks in a way that truly minimizes business disruption.

We believe public- and private-sector organizations have struggled to progress significantly on this topic for several reasons:

• Supply-base transparency is hard (or impossible) to achieve. In modern multi-tier supply chains, hundreds or thousands of suppliers may contribute to a single product. Even identifying the full set of suppliers from the raw-material sources to a final assembled system can require a significant time investment.

• The scope and scale of risks is intimidating. The probability and severity of many risks is difficult to ascertain (How likely are certain weather patterns? How often will a supplier’s employee be careless in cybersecurity practices?), and therefore difficult to address, quantify, and mitigate.

• Proprietary data restrictions impede progress. In complex products, Tier 1 or 2 suppliers may consider their supply chains to be proprietary, limiting visibility at the purchaser or integrating-manufacturer level.

Rather than admiring the problem and these difficulties, we suggest organizations begin to tackle issues in a structured way, cataloging and addressing known risks while improving the organization’s resilience for the inevitable unknown risk that becomes a problem in the future.

## Would you like to learn more about our Operations Practice?

## A structured approach to supply-chain risk management

We recommend that organizations start by thinking of their risks in terms of known and unknown risks.

Known risks can be identified and are possible to measure and manage over time. For instance, a supplier bankruptcy leading to a disruption in supply would be a known risk. Its likelihood can be estimated based on the supplier’s financial history, and its impact on your organization can be quantified through consideration of the products and markets the supplier would disrupt. Newer risks such as cybersecurity vulnerabilities in the supply chain are also now quantifiable through systems that use outside-in analysis of a company’s IT systems to quantify cybersecurity risks.

Organizations should invest time with a cross-functional team to catalog a full scope of risks they face, building a risk-management framework that determines which metrics are appropriate for measuring risks, “what good looks like” for each metric, and how to rigorously track and monitor these metrics. This team can also identify gray areas where risks are hard to understand or define (e.g., tiers of the supply chain where no visibility exists). This analysis can dimensionalize the scale and scope of unknown risks.

Unknown risks are those that are impossible or very difficult to foresee. Consider the sudden eruption of a long dormant volcano that disrupts a supplier you didn’t know was in your supply chain, or the exploitation of a cybersecurity vulnerability buried deep the firmware of a critical electronic component. Predicting scenarios like these is likely impossible for even the most risk-conscious managers.

For unknown risks, reducing their probability and increasing the speed of response when they do occur is critical to sustaining competitive advantage. Building strong layers of defense combined with a risk-aware culture can give an organization this advantage.

## Managing known risks

Organizations can use a combination of structured problem solving and digital tools to effectively manage their known-risk portfolio through four steps:

Step 1: Identify and document risks

A typical approach for risk identification is to map out and assess the value chains of all major products. Each node of the supply chain—suppliers, plants, warehouses, and transport routes—is then assessed in detail (Exhibit 1). Risks are entered on a risk register and tracked rigorously on an ongoing basis. In this step, parts of the supply chain where no data exist and further investigation is required should also be recorded.

Step 2: Build a supply-chain risk-management framework

Every risk in the register should be scored based on three dimensions to build an integrated risk-management framework: impact on the organization if the risk materializes, the likelihood of the risk materializing, and the organization’s preparedness to deal with that specific risk. Tolerance thresholds are applied on the risk scores reflecting the organization’s risk appetite.

It is critical to design and use a consistent scoring methodology to assess all risks. This allows for prioritizing and aggregating threats to identify the highest-risk products and value-chain nodes with the greatest failure potential.

Step 3: Monitor risk

Once a risk-management framework is established, persistent monitoring is one of the critical success factors in identifying risks that may damage an organization. The recent emergence of digital tools has made this possible for even the most complex supply chains, by identifying and tracking the leading indicators of risk. For example, a large organization operating in a regulated industry identified 25 leading indicators of quality issues at its plants and contract manufacturers, ranging from structural drivers including geographical location and number of years in operation to operational performance metrics, such as “right first time” and deviation cycle times. These 25 indicators were carefully weighted to develop a quality risk-exposure score, and then tracked on a regular cadence.

Successful monitoring systems are customized to an organization’s needs, incorporating impact, likelihood, and preparedness perspectives. Hence, while one organization may track deviations on manufacturing lines to predict quality issues, another may follow real-time Caribbean weather reports to monitor hurricane risk at its plants in Puerto Rico. Regardless, it is critical to have an early warning system to track top risks to maximize the chances of mitigating, or at the very least limiting, the impact from their occurrence.

## Deliver on time or pay the fine: Speed and precision as the new supply-chain drivers

Step 4: Institute governance and regular review

The final critical step is to set up a robust governance mechanism to periodically review supply chain risks and define mitigating actions, improving the resilience and agility of the supply chain.

An effective supply-chain risk-management governance mechanism is a cross-functional risk board with participants representing every node of the value chain. It typically includes line managers who double-hat as risk owners for their function, giving them ownership of risk identification and mitigation. In most cases, the risk board receives additional support from a central risk-management function, staffed with experts to provide additional guidance on identifying and mitigating risks.

An effective board will meet periodically to review the top risks in the supply chain and define the mitigation actions. The participants will then own the execution of mitigation actions for their respective functional nodes. For example, if the board decides to qualify and onboard a new supplier for a critical component, the procurement representative on the board will own the action and ensure its execution.

Additionally, in many organizations the risk board will also make recommendations to improve the agility and resilience of the supply chain, ranging from reconfiguring the supply network, finding new ways of reducing lead times, or working with suppliers to help optimize their own operations. Increasing supply-chain agility can be a highly effective mitigation strategy for organizations to improve their preparedness for a wide range of risks.

## Managing unknown risks

Unknown risks are, by their nature, difficult or impossible to predict, quantify, or incorporate into the risk-management framework discussed above for known risks. In our experience, mitigating unknown risks is best achieved through creating strong defenses combined with building a risk-aware culture.

Building strong defenses

Strong defenses, from request-for-proposal (RFP) language to worker training, all contribute to an organization identifying and stopping unknown risks before they affect operations. Exhibit 2 outlines typical layers of defense organizations employ to defend against unknown risks.

Building a risk-aware culture

A risk-aware culture helps an organization both establish and maintain strong defensive layers against unknown risks, as well as respond more quickly when an unknown risk surfaces and threatens operations.

• Acknowledgement. Management and employees need to feel empowered to pass on bad news and lessons from mistakes. This openness fosters an environment where it is okay to voice and deal with issues. Culturally, it is critical that the organization not get discouraged or point fingers when a risk event occurs, and instead works harmoniously towards a rapid resolution.

• Transparency. Leaders must clearly define and communicate an organization’s risk tolerance. Risk mitigation often has an associated incremental cost, and so it is important to align on which risks need to be mitigated and which can be borne by the organization. An organization’s culture should also allow for warning signs of both internal and external risks to be openly shared.

• Responsiveness. Employees need to be empowered to perceive and react rapidly to external change. This can be enabled by creating an ownership environment, where members feel responsible for outcome of actions and decisions.

• Respect. Employees’ risk appetites should be aligned with an organization, so that individuals or groups do not take risks or actions that benefit themselves but harm the broader organization.

## The road ahead

Global supply chains are irreversible, as are the supply-chain risks that globalization has brought with it. Our experience suggests that it is critical for organizations to build robust programs for managing both known and unknown supply-chain risks. Leaders should also recognize that risk management is not merely about setting up processes and governance models, but also entails shifts in culture and mind-sets. By employing these approaches, organizations increase their chances of minimizing supply-chain disruptions and crises, while capturing the full value of their supply-chain strategies.

## Stay current on your favorite topics

## How relevant and useful is this article for you?

## About the author(s)

Tucker Bailey and Edward Barriball are partners in McKinsey’s Washington, DC office. Arnav Dey is an engagement manager in the Boston office, and Ali Sankur is a senior practice manager in Chicago.

## Explore a career with us

## Related Articles

## The route to no-touch planning: Taking the human error out of supply chain planning

## The automation imperative

## Right product, right time, right location: Quantifying the semiconductor supply chain","{""publication_date"": ""March 8, 2019"", ""word_count"": 1924, ""reading_time_minutes"": 10}",2025-03-14 12:42:11.713730
52,"Residential solar: Down, not out",https://www.mckinsey.com/industries/electric-power-and-natural-gas/our-insights/residential-solar-down-not-out,,"## Residential solar: Down, not out

Worldwide, 2024 was a difficult year for the residential solar market. After several years of 30 percent annual growth in installations, 2024 saw a decline: fewer panels were installed in many markets, and companies’ valuations declined. This led to large capital injections, major bankruptcies, and job losses.

## About the authors

This article is a collaborative effort by Bruno Esgalhado, Jason Finkelstein, and Scott Perl, with Charles Riesenberg and Miguel Lopes, representing views from McKinsey’s Electric Power & Natural Gas Practice.

Although these conditions might appear bleak—a delay on the path to net zero and yet another setback in an industry that has taken decades to take off—our analysis suggests a more promising outlook. Residential solar might be down today, but its long-term prospects remain solid. We see that residential solar is poised for steady growth, especially for companies that take the right steps now in preparation to enter the next phase.

In this article, we explain some of the key factors behind the industry’s recent decline, offer three reasons why we believe the market’s fundamentals are solid, and suggest what players can do to lead as the market moves into a new period of steady growth.

## Three insights into what has happened so far

Our analysis of industry indicators has led us to these underlying insights.

## The run-up was not sustainable

Even with the tremendous growth journey the industry has been on over the past decade (see sidebar, “The solar boom”), what we observed between 2020 and 2023 was simply not sustainable. A confluence of factors led the market worldwide to its new heights, with growth rates of 30 percent per year (Exhibit 1). One factor was gas supply disruptions in Europe caused by Russia’s invasion of Ukraine; a 2021 McKinsey survey found that the majority of Germans saw installing solar panels as a critical matter of national security. Another was policy incentives such as Italy’s Superbonus, which offered homeowners the opportunity to deduct 110 percent of the expenses incurred for installing residential solar. In the United States, interest rates were low, and California’s consumers were motivated by the impending end of the state’s net energy metering (NEM) 2.0 policy, which paid higher rates to consumers for home energy generated by solar.

## The solar boom

The solar industry has made significant headway in recent years, particularly in Europe and North America. Here are a few examples:

• United States. As of this writing, nearly 40 gigawatts of residential solar capacity have been installed in the United States. This is almost half of US nuclear capacity and roughly 20 percent of total coal capacity. Even in 2024, marked by declining installations in the residential solar market,1“Solar market insight report,” Solar Energy Industries Association, December 4, 2024. the industry will have added roughly five gigawatts of new capacity—an amount equal to the expected new gas capacity. Nearly 20 percent of Hawaiian homes were projected to have rooftop solar by the end of 2024.

• The Netherlands. Over 30 percent of Dutch households are now powered by solar energy, which is by far the largest source of new-energy generation for the country. Rapid adoption has led to network congestion at the distribution level; grid operators now charge residential solar owners annual fees ranging from €100 to €697, depending on the household’s system size. In addition, the Netherlands government coalition announced it would phase out the country’s net-metering scheme, which paid consumers for renewable energy delivered to the grid by home solar panels, on January 1, 2027, to prioritize the management of grid congestion issues instead of further rooftop solar installations.

• Germany. Residential solar played a critical role in helping German households avoid even more significant energy price increases at the outset of Russia’s invasion of Ukraine. Consumer interest in lower-cost options—coupled with the country’s floating feed-in tariff designed to reduce price volatility and encourage the adoption of renewable energy solutions—led German residential solar deployments to top seven gigawatts in 2023. Germany has emerged as a leader in energy storage as well; an estimated 80 percent of the country’s residential solar setups have battery attachments.

Together, these factors encouraged consumers to install solar panels at record numbers. Meanwhile, enticed by the possibility of continued 30 percent annual capacity growth, many companies expanded beyond their means and lost the flexibility to quickly respond to changing market conditions.

## The drivers of decline are now well understood

Interest rates, a critical bellwether in this industry of heavily financed products, tripled between 2021 and 2023. Policy reform in many markets was already in the works: Just as Italy’s incentives drove huge numbers of households to install solar, the discontinuation of those incentives was going to cause installations to plummet. The business boom caused by the anticipation of decreasing incentives enshrined in California’s NEM 3.0 policies was going to end when NEM 3.0 actually went into effect in April 2023. Electricity tariffs in Europe, which had reached all-time highs because of gas supply disruption in the winter of 2022, tapered as countries found alternative sources of energy.

Our analysis shows that across countries, incentives lead to peaks that drop off—sometimes precipitously—when the incentives expire (Exhibit 2). A number of these regulatory shifts took place in 2024, exacerbating the worldwide slowdown already underway with rising interest rates.

## The fall was hard, but there was solid ground below

Much has been made of the “crash” in the global residential solar market, and although the fall hurt, there was solid ground to land on. Many markets, including most US states, France, and the United Kingdom, have continued to grow, albeit at a slower pace than before (Exhibit 3). Even with total new capacity down approximately 15 percent in 2024, most large markets are still demonstrating growth of around 20 percent per year over the past five years.

Nevertheless, this year’s declines have had painful consequences. Companies that planned for 30 percent growth but instead saw 20 percent declines essentially face having 60 percent more of everything they need: equipment, labor, and supplies. This situation has led many to realize that their variable cost structure is not as variable as they thought it was. The public and private capital being invested into the market has also created more competition among better-funded players, which has, in some regions, increased the cost of customer acquisition. As more marketing dollars chased fewer customers, project profitability eroded.

## The future of residential solar remains bright

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

While forecasting outcomes in the residential solar industry has never been easy, our analysis of the industry’s fundamentals suggests a more stable outlook.

## Rooftop solar is still competitive

In many markets, households can still generate savings by installing rooftop solar. Including all costs of installing a solar rooftop, the electricity generated over its lifetime—the unsubsidized levelized cost of energy (LCOE)1The levelized cost of energy is the lifetime cost of an energy generation source divided by the amount of energy it produces over its lifetime.—is still cheaper than comparable grid electricity in many markets. In the United States, electricity prices rose approximately 5 percent in the past year. California, Colorado, New York, and North Carolina—states where the sun or the incentives are strong—saw increases between 10 and 20 percent. In Europe, residential system prices have been declining relative to their peak between 2022 and 2023, but they still allow for payback times below eight to ten years, a benchmark that we know leads to significant adoption of distributed generation.

The increasing demand for batteries as part of residential solar installations—providing backup power and a source of renewable energy at peak evening times—could help unlock additional value. Overall, in most markets, rooftop solar is likely to continue to be a competitive source of green electricity.

## Costs are likely to keep coming down

While the cost reductions of the past decade were primarily enabled by declining equipment costs—which we expect will continue to a certain extent—there likely will be other opportunities for cost savings. The boom of the past five years pressured companies to rapidly ramp up sales and installation teams, leaving plenty of room for operational excellence to increase efficiency. Streamlining installation, improving sales team productivity, embedding management best practices, and implementing digitization and gen AI tools can yield cost savings.

## Customer interest is at an all-time high

Rooftop solar is no longer a niche product for customers who value sustainability and reliability. Surveys repeatedly show strong consumer interest. In a 2022 McKinsey survey in the United Kingdom, 59 percent of people without a residential solar system said they definitely would install one or were likely to consider it in the next few years. A recent Forbes Home survey found that approximately 90 percent of residents with solar panels are satisfied with them and more than 80 percent would recommend them to others.2Geraldine Orentas, “Nearly 90% of Americans are happy they installed solar panels on their homes,” Forbes Home, March 15, 2024.

Based on our analysis, the global residential solar market is likely to stabilize between 2026 and 2030 at around 35 gigawatt deployments per year, still above 2022’s install rate (which was already roughly 40 percent higher than 2021 and 80 percent higher than 2020). This would restart a growth trajectory after a forecast decline in 2024 and 2025. In this scenario, residential solar’s cumulative installed capacity would more than double relative to today by the end of the decade. The growth could be further enhanced by increased national decarbonization commitments or rooftop solar support packages similar to Solar for All in the United States, REPowerEU, or the Energy Performance of Buildings Directive in Europe.

## How can companies position themselves to capture the coming growth?

As the residential solar industry moves into a phase of steady but more moderate growth, what will separate the leaders in this market from those who fall behind? What will it take to capture a disproportionate share of the market going forward? And why will the coming growth provide steady gains? We have identified five factors likely to be the main differentiators.

## Innovation in customer acquisition

Customer acquisition costs (CAC) have long been a thorn in the side of the residential solar industry. In the United States today, they can amount to almost $10,000 per sale, which can be 25 percent of the total cost of an installation. This cost is 13 percent higher than it was two years ago.

However, CAC remains the most compressible element of the cost stack in this industry. Opportunities exist across marketing, sales, and operations to reduce the CAC by as much as 70 percent (Exhibit 4).

In the industry’s next horizon, pursuing new business models will be essential. Several players are already deploying successful approaches, including bank partnerships to integrate financing into the sales process; omnichannel sales and marketing across mobile, web, and showroom; and AI deployed at every stage to identify customers, automate design, and improve customer experience. The right approach will vary for each company, but the process of acquiring customers ought to be consistently iterated and improved to reduce costs.

## Integrating digital tools and gen AI into all business processes

Residential solar businesses are complex. Installers design and run thousands of simultaneous small construction projects in different regions, often with differing rules. The best performers will be those that digitize across the solar journey. Tangible examples of gen AI integration we are beginning to see include the following:

• Marketing. Gen AI creates personalized offers and quotes, as well as initial system designs, which can accelerate the process of bidding to customers and reduce customer acquisition costs.

• Project design. Algorithms automate and optimize project design, speeding up the design step and minimizing waste.

• Project management. AI tools generate automated checklists and validate critical-path items across design, site audit, permitting, and installation to improve quality assurance and streamline approvals.

• Customer engagement and scheduling. AI coordinators reach out to customers to schedule home visits and update the daily branch schedule accordingly to optimize routes and sales force productivity.

## Active workforce and talent management

End-to-end solar rooftop deployment can involve managing more than 50 roles, often spread across locations. Ensuring that all of this is running smoothly—in an environment where employee turnover is high and market needs are changing—is hard. Rooftop solar companies often encounter bottlenecks in a specific task while other steps have slack, delaying completion times and costing millions in profits. To grow the workforce needed for success, companies can implement workforce best management practices: professionalizing their workforce, investing in workforce training and retention, and identifying talent sources, particularly for roles in tight labor markets, like electricians.

## Seamless product bundling

Customers are increasingly interested in a full spectrum of climate-friendly energy products—including heat pumps, batteries, and home electric-vehicle charging—and they want these systems to work seamlessly. In a recent McKinsey survey of customers who purchased more than one of these solutions from different vendors, more than 40 percent said they would have preferred to deal with a single entity.

For rooftop solar companies, taking a multiproduct approach may significantly increase the price they charge for each project, shrinking relative customer acquisition and installation costs and unlocking additional synergies on energy usage. For instance, customers may need or want more panels if they also install a battery or heat pump.

This opportunity does not come without challenges. While deploying batteries may require minimal changes to implement, adding products like heat pumps may require entirely new capabilities, such as plumbing. Customers will also likely have different needs or motivations: While a solar rooftop customer typically wants to reduce electricity costs or increase independence from the grid, heat pump customers are more likely to buy during home construction or renovations or when they need to replace their heating system. The complexity of adding products is substantial and may not be for all players, but it could unlock significant additional value pools for those who take it on.

## Localized operating model agility

The volatility of the residential solar market—including changes in economics, regulations, and operational practices—has earned it the nickname “solar coaster.” To manage this volatility, companies will have to closely monitor material pipelines and changes in trends, economics, and regulations and then make fast, strategic moves. This means being able to adjust operating models and cost structures at the local-market level—for instance, identifying where to invest in crews or owned media and marketing and where to leverage contractor partnerships.

In our experience, developers’ portfolios typically have wide disparities in profitability per project, often with a sizable chunk of projects that don’t make money. The ability to respond nimbly to variability—for example, by closing unprofitable channels and rejecting or repricing installations—could help ensure profitability. As incentives and competition change, players will need to continuously refine their local channel strategies and footprints. Developers may need to move fast and react on short loops, rather than wait for yearly strategy reviews.

The residential solar market is down, not out. Our analysis indicates that the market is likely to revert to more stable long-term growth over the next several years on the back of strong fundamentals. Almost certainly, surprises will pop up along the way; the industry is not called the solar coaster for nothing. The leaders in the market are likely to be those that can compress cost through innovation and operational efficiency, incorporating digitization and artificial intelligence at every step; expand the scope of their offerings through product bundling; and remain agile, able to capitalize on local market differences. These leaders may be able to get off the solar coaster and take a steadier ride.

## How relevant and useful is this article for you?

## About the author(s)

Bruno Esgalhado is a partner in McKinsey’s Madrid office; Jason Finkelstein is a partner in the Bay Area office, where Charles Riesenberg is an associate partner; Scott Perl is a senior partner in the Washington, DC, office; and Miguel Lopes is a senior asset leader in the Lisbon office.

The authors wish to thank Chris Dawson and Humayun Tai for their contributions to this article.

This article was edited by Jessica Marshall, a senior editor in the Seattle office.

## Explore a career with us

## Related Articles

## Global Energy Perspective 2024

## Building a green energy ecosystem: Lessons from zolar

## Build together: Rethinking solar project delivery","{""publication_date"": ""February 3, 2025"", ""word_count"": 2796, ""reading_time_minutes"": 14}",2025-03-14 12:42:18.612724
53,Reshaping IT management for turbulent times,https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/reshaping-it-management-for-turbulent-times,"spurring innovation, growth","## Reshaping IT management for turbulent times

Despite decades of increasingly intensive use of information across industries, IT has remained a black box for many executives. Too often, the link between spending and performance has been unclear, if not problematic. As a result, leaders felt that their only course of action was to hire a competent CIO, throw increasing amounts of money at IT, and hope for the best. The economic disruptions of recent years, however, have tightened budgets and placed a premium on action, forcing companies to rethink IT’s fundamental role.

In most organizations, IT began as a support function, leading to a one-dimensional management approach. However, technology-enabled products, interactive communications, and an “always on” information environment have thrust IT to the forefront, with critical implications for business growth and customer engagement. In addition, established practices, such as lean-management techniques, have highlighted the value of IT in reducing waste and increasing productivity.

This deeper recognition of IT’s potential has given rise to a new management model consisting of two categories: “Factory IT” and “Enabling IT.” Factory IT encompasses the bulk of an organization’s IT activities, applying lessons from the production floor—scale, standardization, and simplification—to drive efficiency, optimize delivery, and lower unit costs. Enabling IT is focused on helping organizations respond more effectively to changing business needs and gain a competitive advantage by spurring innovation and growth.

This approach goes beyond simply relabeling functions to include broader leadership, governance, and organizational changes, and IT leaders will need very different skills to manage each model. Business leaders will have to engage with IT in new ways. For instance, while IT standardization and consolidation increase responsiveness, speed to market, and cost effectiveness, managers may have fewer options to customize solutions. Likewise, more transparency and better metrics may come at the expense of unrestricted choice for configuration and architecture. In return, business leaders would get a new type of IT partner to support innovation, with skills to deliver IT-enabled capabilities quickly that drive both top- and bottom-line growth. But they’ll need to treat such IT staff as full members of their group, offering incentives and rewards for exceptional performance.

## Factory IT: More efficient IT services

The core elements of the typical IT function have changed radically over the past decade, and this evolution has enabled the Factory model. Ten years ago, a company might have felt compelled to create its own software to manage the supply chain and other activities; today, many configurable products can meet those needs. Similarly, expensive, single-purpose servers and the dedicated support staff they require can be replaced by commodity servers, often managed from half a world away.

Moreover, these standardized platforms can now be coupled with mature processes for managing broad swaths of IT, including basic infrastructure and many of the business applications. Under this configuration, IT activities can be restructured and continually improved much as any other business process, using a combination of lean techniques, automation, and outsourcing or cloud computing to drive down costs and improve quality. Results from our latest technology survey11.
The online survey was in the field in October 2010 and includes responses from 864 IT and non-IT executives, from a range of industries, regions, and company sizes. 
   demonstrate how companies have already begun to implement some of these practices (Exhibit 1).

There are three key components of the Factory model:

## Industrialized IT—applying traditional business-management techniques to IT

Standardization decreases the resources and specialized development needed to support IT, allowing organizations to apply proven management methods from large industrial settings to reduce IT costs. Lean-management techniques have evolved well beyond manufacturing and are applicable to the types of skilled services found in IT. A company can typically create 20 to 30 percent or more in additional IT capacity by streamlining processes, automating routine functions, and eliminating redundancy. Major sources of IT waste include unnecessary functionality (for example, gold-plated systems with extra, noncore functions), work flow bottlenecks caused by inadequate cross-training, and frequent rework from bugs or constantly changing requirements.

Companies can benefit significantly by replacing customized systems with highly standardized offerings (for example, a Web server or e-mail platform that includes common hardware, applications, and support levels) and service catalogs (essentially à la carte menus that specify the cost of each service). These improvements increase cost transparency and highlight clear opportunities for further efficiency while also giving individual business units the freedom to customize certain features and functions.

Organizations should also recognize that not all processes have equal value and should set service and support levels accordingly. For instance, one bank applied the same exacting levels of support and performance for its critical core banking applications to an in-house employee service portal. By increasing the service portal’s allowable downtime to five days a year, from just five hours, the bank saved hundreds of thousands of dollars in hardware, software, and staff expense.

In our experience, these measures often double workforce productivity by redeploying or reducing staff. A standardized IT environment also allows companies to select from a wider array of vendors whose scale and skills can further reduce costs and improve delivery. In addition, by avoiding customized hardware and operating systems, companies can more readily take advantage of a technology cost curve that has been dropping by 4 to 5 percent annually.

## Flexible IT factories—building IT that’s more responsive to changing business conditions

IT tends to operate on a very long-term investment cycle consisting of large, multiyear projects, extended outsourcing deals, and durable infrastructure assets. As the pace of business change accelerates and organizations respond to shifting market conditions or more frequent M&A, IT leaders are often constrained by these investments. IT departments are starting to adapt in two ways:

The cloud: Cloud computing offers access to information, processing, and storage through the network or an external service provider. This mode of delivery allows companies to purchase computer processing as a service, rather than making up-front investments in IT capacity and in-house support staff. The New York Times, for example, digitized and catalogued more than 100 years of archived articles for its Web site in a 24-hour period by using Amazon.com’s cloud offering, avoiding the need to configure and operate a set of servers for a onetime effort.

Agile software development. IT programmers are flocking to approaches that emphasize the very fast, iterative development of systems through close interactions with users, allowing continual feedback and programming refinement. This agility can deliver new systems and capabilities in a matter of weeks or months instead of years. A frequent iteration cycle also keeps IT developers and business users in sync on requirements and priorities. Agile development may not be right for every project. However, since this approach is most effective when business needs are shifting, it is gaining favor among many IT departments.

Together, the cloud and agility can make the IT factory more nimble, with lower costs and faster delivery.

## Holistic business cases—cutting complexity through improved planning

For most companies, IT complexity increases gradually, as systems slowly evolve beyond their initial purpose, or through acquisitions, when new, sometimes duplicative systems are built for individual business units. Performance suffers over time, as ineffective IT slows product introductions, hampers customer interactions, and often makes postmerger integration more difficult.

IT leaders recognize the adverse effects of complexity, but replacing these systems involves a substantial commitment of resources: hardware, new applications, and staff and vendor time. The economics are difficult to justify given the short time horizons of many tough-minded CFOs, particularly since tangible benefits are often realized only in the longer term.

To manage complexity, companies are starting to employ a more holistic business case model that goes beyond the traditional, IT-centric versions. This model includes realistic, verifiable cost–benefit analysis to assess the impact of new systems on the entire organization. Critically, such plans also require a road map for how future projects might build on the investment. At one company, for instance, the business case to deliver a unified view of all customer data showed how better information management could enable follow-on projects for marketing systems, enhancing cross-selling opportunities.

## Implementing Factory IT

While a Factory IT model does not require radical restructuring, it does involve targeted changes in talent, organization, accountability, and governance. IT leaders should use this opportunity to streamline the IT function and create a new baseline that balances the measurable improvement of both cost effectiveness and delivery. To succeed, the model must achieve these goals:

• Ensure that external customers don’t see a material degradation of their experience and that business users begin to see tangible results in return.

Ensure that external customers don’t see a material degradation of their experience and that business users begin to see tangible results in return.

• Deliver through a transparent process, with clear, relatable metrics for all involved.

Deliver through a transparent process, with clear, relatable metrics for all involved.

• Verify that planning for the IT information environment accounts for a range of business needs and is aligned with larger market trends.

Verify that planning for the IT information environment accounts for a range of business needs and is aligned with larger market trends.

• Engage IT executives who have experience in applying lean techniques and driving continuous improvement and the right temperament and skills to form effective partnerships across the business.

Engage IT executives who have experience in applying lean techniques and driving continuous improvement and the right temperament and skills to form effective partnerships across the business.

The benefits of these business cases are twofold. First, they ensure that the simplification of processes and systems is a starting point for new project investments. Second, better visibility can show how seemingly small IT projects can deliver a high return on investment by improving standardization and service levels across the entire business (see sidebar “Implementing Factory IT”).

## Enabling IT: Supporting innovation and delivering business value

As the market-facing complement to the Factory model, Enabling IT focuses on creating new sources of value. This emphasis on innovation requires three things: ready access to relevant information, a willingness to test and learn, and close collaboration. Enabling IT supports these activities by developing the processes and technologies to launch a new sales channel, design a tech-enabled product feature, or increase customer retention through online offerings.

Where Factory IT is housed centrally, Enabling IT’s employees function as an IT SWAT team for new initiatives or business imperatives and are often closely integrated with—or even embedded in—business units. The performance of these employees is rated on metrics such as responsiveness and flexibility rather than on their ability to deliver low unit costs. And where Factory IT focuses on long-term projects and on-time delivery, Enabling IT is typified by rapid prototyping and iterative development. Our survey results show that companies deploy Enabling IT to support innovation and growth in three ways (Exhibit 2):

## Turning raw data into insight

The increasing volume of data is taxing the ability of companies to track, filter, and analyze information and turn it into useful, actionable insights. Organizations that build effective information systems can take advantage of emerging opportunities and respond more quickly to unseen market changes. With the rise of electronic health records and prescription data, for example, pharmaceutical companies need systems to structure and mine this information for trends on patient compliance or drug efficacy.

Resolving these issues requires a cross-functional group of IT experts, statistical analysts, and business leaders. IT must develop new technical capabilities to manage the massive amount of information, and IT leaders will need to collaborate more closely with management teams to extract its full value.

## Supporting rapid experimentation

Where lean manufacturing and Factory IT seek to avoid errors, Enabling IT’s mind-set tolerates (and even encourages) the mistakes that result from experimentation and iteration as long as they happen quickly, the outcomes are measured, and the lessons are incorporated into the team’s thinking. More companies are embracing rapid experimentation as a way to develop, refine, and upgrade their services or products. Capital One and Google, for example, have been at the forefront of this trend with their credit cards and online services, respectively. That wave is spreading to traditional players: P&G’s Vocalpoint, a network of mothers, provides feedback on new product ideas. Similarly, a leading fast-food company is using IT systems and analytics at test sites to gauge the impact of new menu choices on store-level revenue, operations, and customer experience.

Such experimentation requires the right set of technical capabilities and a flexible IT environment. Managers must employ tools to define, build, test, and improve new products quickly, integrating feedback from both internal stakeholders and a set of users or customers. Responsive IT support is a vital component of this effort. By assembling a team to work hand in hand with the managers on these new business offerings, IT provides essential support to help build and modify business processes and systems rapidly.

## Web 2.0—fostering new interaction models

IT has historically focused on automating high-velocity transactions for enterprise resource planning (ERP), supply chains, and customer relationship management (CRM). That focus is now shifting to lightweight Web 2.0 tools22.
Michael Chui, Andy Miller, and Roger P. Roberts, “Six ways to make Web 2.0 work,” mckinseyquarterly.com, February 2009. 
   to support the more diverse transactions and more complex interactions that shape, review, and inform innovation.33.
Bradford C. Johnson, James M. Manyika, and Lareina A. Yee, “The next revolution in interactions,” mckinseyquarterly.com, November 2005.
   Tools range in complexity from simple executive blogs to more robust portals where users can collaboratively access and analyze data sets.

Often, these newer forms of knowledge sharing require little additional investment, since the content is largely user generated and the tools rely mostly on existing applications and infrastructure. In fact, these tools usually augment existing transactional systems rather than replace them, thus increasing the value of IT investments while holding down costs. Since users often drive the development of these collaborative tools, strategies that complement users’ work practices and styles are most effective. Although such an endeavor is challenging, the payoff can be substantial.

## Enabling IT: Bringing it together

Enabling IT can help support an organization’s innovation culture. To work well, the model requires three components:

• Nimble, flexible, and focused work groups embedded in the business and responsible and accountable to both the business unit leader and CIO (in contrast to a highly standardized and structured organization).

Nimble, flexible, and focused work groups embedded in the business and responsible and accountable to both the business unit leader and CIO (in contrast to a highly standardized and structured organization).

• A more qualitative approach to measuring performance—focused on the IT team’s contribution to the business unit and its overall results—rather than enterprise-wide goals for costs or efficiency.

A more qualitative approach to measuring performance—focused on the IT team’s contribution to the business unit and its overall results—rather than enterprise-wide goals for costs or efficiency.

• Credible, deeply knowledgeable IT leaders and team members who are seen as an integral part of the functions and businesses they enable.

Credible, deeply knowledgeable IT leaders and team members who are seen as an integral part of the functions and businesses they enable.

Innovation is seldom neat, and these collaborative systems are no exception. Successful initiatives usually start as small side projects or tests that gain critical mass rapidly, often with little regard for corporate technology or security standards. IT leaders can play a critical role by selecting and validating platforms, setting policies, and promoting capabilities to potential participants. Because Enabling IT staff members already work within business units, they can help guide these projects, giving executives some degree of control and assurance on compliance with critical security and data standards. The result is a smoother transition to the Factory IT environment when the systems reach maturity (see sidebar “Enabling IT: Bringing it together”).

While leading companies may implement these principles differently based on their business needs and culture, we believe there is no turning back. Factory IT’s potential to increase efficiency and reduce costs can finance the next wave of Enabling IT’s innovation. The combination of functional productivity and business value creation will likely be a major competitive differentiator; the first step in delivering this value is to ensure companies have the right leaders in place for each effort.

## How relevant and useful is this article for you?

## About the author(s)

Roger Roberts is a principal in McKinsey’s Silicon Valley office, where Hugo Sarrazin is a director; Johnson Sikes is a consultant in the New York office.

## Explore a career with us

## Related Articles

## Data to dollars: Supporting top management with next-generation executive information systems

## Clouds, big data, and smart assets: Ten tech-enabled business trends to watch","{""publication_date"": ""December 1, 2010"", ""authors"": [""spurring innovation"", ""growth""], ""word_count"": 2790, ""reading_time_minutes"": 14}",2025-03-14 12:42:25.441336
54,Viewing change as opportunity: An interview with Western Digital’s David Goeckeler,https://www.mckinsey.com/industries/semiconductors/our-insights/viewing-change-as-opportunity-an-interview-with-western-digitals-david-goeckeler,,"## Viewing change as opportunity: An interview with Western Digital’s David Goeckeler

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

David Goeckeler took on the role of CEO at Western Digital on a Monday in March 2020. That Wednesday, the World Health Organization declared the COVID-19 crisis a pandemic.

“I have a very clear recollection of bringing my new leadership team together that day,” recalls Goeckeler, who previously headed up Cisco’s networking and security business. “The first decision we made was to send everyone that we could home.”

It was the right decision to make—and well-executed. Keeping employees safe was the number one priority for the nascent CEO. Number two was keeping the business running amid exploding demand for the company’s storage and hard disks, although it was unclear when workers might return safely to factories. “Trying to balance those two things in the first couple of months was an interesting experience,” Goeckeler says.

While challenges remain, new opportunities have emerged as the digital era spurs unprecedented increases in data storage. McKinsey’s Eric Kutcher and Abhijit Mahindroo recently interviewed Goeckeler about leading through these tumultuous times, the democratization of technology innovation, the myriad challenges in the technology manufacturing ecosystem, and the upsides of uncertainty and change. An edited transcript of their conversation follows.

## David Goeckeler biography

Earned a BS in computer science and mathematics from the University of Missouri-Columbia, an MS in computer science from the University of Illinois Urbana-Champaign, and an MBA from the Berkeley-Columbia Executive MBA Program

Western Digital
(March 2020–present)
Chief executive officer

Cisco
(2017–20)
Executive vice president and general manager, networking and security

(2016–17)
Senior vice president and general manager, networking and security

(2014–16)
Senior vice president and general manager, security

(2012–14)
Vice president, product and platform engineering

• Chosen for CRN’s list of Top 25 IT Industry Disrupters in 2019

• Received Frost and Sullivan’s Excellence Award for Engineering Operations in 2012

• Sits on the board of directors of ADP and the Semiconductor Industry Association

• Serves as vice chairman of the US–Japan Business Council at the US Chamber of Commerce

• Sits on the University of Illinois College of Engineering Board of Visitors

Eric Kutcher: We’re more than two years into the pandemic. In some ways, the world has moved on. In others, it hasn’t. What are you most proud of having managed? And what, in hindsight, would you have done differently?

David Goeckeler: Any time you come into a company, it’s a lot of fun because you get to learn a new business. But, more important, you get to learn a new team. That team aspect was a challenge because we couldn’t spend any time together. To this day, I haven’t been to any of our facilities around the world. We built these relationships in a virtual environment.

## Leadership lessons in the pandemic

Yet one thing we did really well was balancing the priorities of keeping the business moving and keeping our team safe. The amount of innovation needed to do that was incredible—to make sure we could get people into the factories, into the facilities, into the fab [fabrication plant], and keep things going. I’m really proud of the way the team responded to this situation while caring for the employees.

We have started to restructure the company in a way that I think will allow us to execute better. We’re delivering better for our customers. Our innovation road map is rekindled and moving forward.

But there are some things we might have done better. For instance, if we had known the pandemic would persist for two years, could we have anticipated all the supply chain and logistical issues? Maybe we would have reacted to some of those in a slightly different way. But all in all, we’ve made the best of a difficult situation. Quite frankly, the company is anticipating great opportunities.

Abhijit Mahindroo: It’s an exciting time to be in the memory business. How do you see the prospects and the challenges ahead?

David Goeckeler: I think it is a very exciting time to be in any business associated with data. At Cisco, I got to see what was going on around the globe. I saw from my vantage point that the world had created a new technology platform: the cloud, powering intelligent devices connected by high-speed networks. That technology architecture came into existence because each of those pieces has evolved independently.

## Managing through complexity

I remember when the iPhone came out on 3G. Now look where we are: 5G and going beyond. You have ever more intelligent devices. Now, we’re all talking about the metaverse and VR [virtual-reality] headsets. You have the cloud, where the largest, most powerful, and most innovative technology companies are driving unprecedented innovation.

I started out as a software developer. In the past, if you wanted to build software, you had to hire a whole bunch of people like me. It was complicated and messy. Now, you have the cloud, and every couple of months you have new capabilities available—the most advanced capabilities in the world—because somebody else is pouring innovation into that.

It’s the democratization of technology innovation—it’s available to everybody, every company, and every industry. There are a lot of people innovating on top of that platform. Every time that happens, it drives more demand for storage, both at the end point and in the cloud.

Abhijit Mahindroo: What do you see Western Digital as, a horizontal company or a vertical company?

David Goeckeler: We can play in both areas, but I think it’s most powerful if you play in the horizontal first. This is what’s so exciting: there are a whole bunch of people out there innovating and figuring out ways to use this platform that will drive more data and more storage. We benefit from that. Then, if there are ways that we can accelerate that architecture and specific verticals by building specific products or specific adaptations of our technology, we’ll absolutely do that if it makes sense. Then, whatever you do on top of that is going to drive demand for that horizontal platform.

It’s the democratization of technology innovation—it’s available to everybody, every company, and every industry. There are a lot of people innovating on top of [the cloud].

Abhijit Mahindroo: Through your acquisition of SanDisk, Western Digital has continued a long-term joint venture with Toshiba [now Kioxia]. How do you make such large, complex partnerships work?

## Partnering for success

David Goeckeler: First, the transaction has to be part of a larger strategy; it can’t be the strategy itself. It is really important to have a lot of clarity about that going into it. In this case, it gives us scale in R&D and manufacturing in an industry where scale is very, very important. It gives us a strong cost position and R&D road map. It gives us a position as the largest merchant NAND [flash memory technology] supplier in the world, which is a really good spot to be.

To make a partnership of that scale that successful for that long, it has to work for both parties. When you’re inside the company, you can see why it works because the teams are very close. The engineering teams work hand in glove, day to day. It’s been a little harder during the pandemic, but people have made it work because the relationships are deep and strong. And the value in the outcome is really important for both of us.

You have to make sure you spend a lot of time on cultural fit. The teams coming together have to see it as their shared future. It can’t be us versus them. It can’t be winners versus losers. It can’t be, “We’re taking over.” It has to be, “We’re coming together.” The dynamic of the team and getting that right is where the magic is.

## The opportunities for Western Digital

Eric Kutcher: Something everyone is dealing with today is the “Great Resignation.” How do you think about that?

David Goeckeler: I’ve made a career of going into new organizations, and this question always comes up: How are you going to attract talent and retain all the great people that are here? The answer is to create an environment they want to be a part of. I have a core belief that people want to be part of something bigger than themselves.

Now, we have the pandemic, which poses a challenge. We’ve got to keep the business going, but the business isn’t going to work unless the people are taken care of. So with everyone working remotely, how do we create the sense that our employees are a part of something? If you can create that, you will get tremendous loyalty.

You have to make sure you spend a lot of time on cultural fit. The teams coming together have to see it as their shared future. It can’t be us versus them. It can’t be winners versus losers.

Eric Kutcher: What has it been like managing through two other forces that are squarely top of mind today: global supply shortages and the inflation that accompanies that?

David Goeckeler: I think of the supply chain issues along three dimensions. First, we’re a manufacturer. At the beginning of the pandemic, it was hard to get enough people in to keep the factory running, especially when you had this demand boom. We’ve worked through that, but it’s something we still keep very close tabs on.

Second, we have to get enough components from our own suppliers so that we can build what we need to build. That has become increasingly difficult. Lead times are out to over a year for some of our components. That’s a constant—day to day, week to week, we are making sure we can get as much as possible to deliver to our customers. We are clearly in a situation where we can’t meet true demand.

## Reflecting on a diverse career

Third, we have customers in the same situation—where they can’t get all the pieces that they need to assemble everything they want to meet true demand. We’re starting to figure out lead times and how to manage within that, how to manage demand a little bit better, how to keep everything running. However, it continues to be a very difficult situation, and it looks like we’re going to be in it for quite a while.

On top of this, the logistics of getting what we need around the world has been a major issue. A lot of freight goes on commercial air traffic. When there’s no commercial air traffic, it has to go another way.

All of this leads to inflation. That means staying on top of what’s happening on a very dynamic basis, being very agile, and working with your customers.

At some point, the world will readjust. With a high fixed-cost business and high levels of investment, it won’t change overnight. But it will change. The world will adapt, and we’ll get back to whatever the new normal is.

Eric Kutcher: Do you have an idea if we will return to the old demand for storage or if this is a permanent step up?

## Career lessons and advice

David Goeckeler: The most powerful technology companies the world has ever known are making a technology platform available to every company, every government, every institution in the world to absorb and build a better business, deliver better service, and make people’s lives better. That process is going to continue to accelerate and accelerate. So I think it’s a step up, and then the slope will tilt up.

Eric Kutcher: What advice would you give a young technology professional?

David Goeckeler: A lot of people will tell you, find something you love to do. But I would add something: make sure you’re good at it. Find something you have talent in, because then it’s not so hard.

If you’ve chosen to be in the technology world, it’s driven by change. You may hear people say, “change is hard” or “embrace change.” I think you have to move beyond that. At some point in my career, I realized that change is opportunity. If nothing ever changes, then nothing will change for the better. If you can be the person who is the most comfortable with the most uncertainty, that’s a premium skill set. Sometimes I say the person who can live with the most uncertainty the longest, wins. If you can think about being the one who can take something uncertain and drive it to more certainty, that is a tremendously helpful mindset. Then you evolve from avoiding change to looking for change.

## How relevant and useful is this article for you?

## About the author(s)

David Goeckeler is the CEO of Western Digital. Eric Kutcher is a senior partner in McKinsey’s Bay Area office, and Abhijit Mahindroo is a partner in the Southern California office, and Anupama Suryanarayanan is an associate partner in the Silicon
Valley office.

Comments and opinions expressed by interviewees are their own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement.

## Explore a career with us

## Related Articles

## The semiconductor decade: A trillion-dollar industry

## Navigating the semiconductor chip shortage: A control-tower case study","{""publication_date"": ""April 14, 2022"", ""word_count"": 2281, ""reading_time_minutes"": 11}",2025-03-14 12:42:32.240468
55,"Disruption, friction, and change: The hallmarks of a true transformation",https://www.mckinsey.com/capabilities/rts/our-insights/disruption-friction-and-change-the-hallmarks-of-a-true-transformation,,"## Disruption, friction, and change: The hallmarks of a true transformation

Transformations are difficult undertakings and come with a high likelihood of failure. But with a focused plan and dedicated leaders, a company’s executives can turn around the business and achieve meaningful success. In this episode of the McKinsey Podcast, McKinsey partner Michael Bucy and senior partners Stephen Hall and Doug Yakola, leaders in the RTS Practice, speak with McKinsey Publishing’s Tim Dickson about what it takes to truly transform a business and bring about lasting change.

## Disruption, friction, and change: The hallmarks of a true transformation

## Podcast transcript

Tim Dickson: Hello and welcome to this edition of the McKinsey Podcast. I’m Tim Dickson, an editor with the McKinsey Quarterly. Today we’re going to be talking about transformations: big, organization-wide change programs with the potential to really change the trajectory of a company.

These are historically very difficult and remain difficult. So how can executives increase their chances of success? Joining me today to discuss this and other issues are Michael Bucy, a partner in McKinsey’s Charlotte office; Stephen Hall, a partner in the London office; and Doug Yakola, a partner in our Boston office. All three are members of McKinsey’s RTS Practice. Mike, Stephen, and Doug, thanks so much for joining. Now, Doug, you have said in a recent article that “transformation” is, and I quote, “The most overused term in business.” When you talk about transformations, what’s different? What’s new?

Doug Yakola: Transformations, the way that we think about them, are organization-wide and completely holistic. This is something that you don’t do with just the top five executives in the company in a top-down exercise. It’s not something where you transform a small piece of the business. But a transformation happens when you get the entire organization involved  in something that is bigger than themselves.

The way that we think about it is, it needs to be hugely aspirational. A transformation takes place where the people don’t understand the breadth and depth of what they can do until they get involved in it. It’s truly about the full potential of the company and not just an incremental bump here and there.

Tim Dickson: Anything you’d add to that, Stephen?

Stephen Hall: One of my clients likes to talk about the need to go against the grain. A true transformation is disruptive. It doesn’t just work with the existing governance, the existing processes, the existing budgeting cycle, the existing ways of doing things. It is going to disrupt. And it’s going to create challenge and tension and friction in the organization. We view those characteristics as being necessary co-travelers to delivering a true transformation of the company.

Doug Yakola: Because it is so disruptive, it’s also a top priority of the organization. This is not something that can be third or fourth down in the CEO’s list of things he or she must do. The way we talk about it is, it’s the number one or number two priority past safety that you need to be thinking about.

Tim Dickson: What is the context you’re finding for these transformations? Is it primarily technology and technological disruption that are causing companies to undergo these big change projects?

Doug Yakola: No, not at all. This runs the gamut. You can have a company that has been performing poorly for many years and needs to step back, take stock, and undergo a fundamental transformation of their business model. There’s technological disruption, as you point out. There is disruption as it relates to the revenue growth plan, and we work with many companies that have been in high growth for the last, say, five, six, seven years, and, suddenly, that growth is starting to tail off.

We are working a lot with B2C companies now that have a technological disadvantage in that they’ve been brick and mortar or they’ve been working a lot in print, and now they need to go to much more digital media. That has also been a big area of transformation.

These are companies that look at where they are now, and they look in the future, and they know that they need to do more than just an incremental improvement year over year in order to stay ahead of their competition.

Tim Dickson: Historically, a lot of these big transformation projects have failed. Stephen, in your experience, why is that? What sort of patterns do we see?

Stephen Hall: First of all, I think executives are right to be skeptical about this term “transformation” and the opportunities that it can offer. The research that we’ve done and the research that academics have done and many of our competitors do show a consistently, very high failure rate of these programs as reported by the companies themselves.

Around 70 percent or so are routinely cited as being the likely rate of failure of these kinds of programs. It’s not surprising, when you think about it, that it’s the case. A company [undergoing a transformation] is going to be in a situation where it is trying to change many things, in parallel, to a significant degree.

What we find, of course, is that the resistance—both the resistance in the broader workforce in a company but also, frankly, in the extended leadership team itself—is often very high to making those kinds of changes. What we try to do is to take a company through a process by which it builds commitment to an agenda, to a set of aspirations, and, ultimately, to a set of plans that will allow it to move beyond the status quo.

## Would you like to learn more about  RTS?

It requires a set of steps, a disciplined approach, which many companies are simply not set up to do for themselves. They don’t necessarily have the patent recognition in terms of what needs to be achieved.

Tim Dickson: You all have been working with a lot of companies that have succeeded in their transformation programs. Michael, what would you say are the essential ingredients for those that get it right?

Michael Bucy: It’s all about avoiding leakage. So at the aspiration stage, folks don’t go for their full potential. They go for seven out of ten of it. And then in the planning and execution, they let some things slide. They don’t see some things all the way through. And they do seven out of ten of it.

Then, finally, they don’t build in the changes that are necessary for the initiative to be sustained. They get it seven out of ten right. Well, if you multiply that together, those sevens out of tens, you quickly get to about a 30 percent success rate. That’s what we’ve seen, again and again. You have to, at each step of the process, go for the 100 percent and be able to realize the full potential of the business in order for the transformation to be successful.

Tim Dickson: Let’s talk a little bit more about that target setting. This is one of the initial steps that’s obviously important to get right—to go for what the potential really is, rather than what people think it is. How is that possible in practice that people could so underestimate the potential? Mike?

Michael Bucy: All executives are familiar with the typical budget cycle of a company. Managers throw out very lofty targets and then have discussions with the other executives about what they’re willing to commit to. You say it’s going to be 100. The executive comes back and says, “No, I can give 20.” You settle on a number of 30 to 40 or 50.

Our process starts with setting the bar at the full potential of the business. What can managers do to achieve that 100 percent? And being uncompromising in saying, “We’re going to go after that 100 because here’s the fact base that supports it.” The rest of the executives have to suspend disbelief for a bit because they’ve operated in an environment where they’ve never been able to achieve 100. They’ve been able to achieve 20, or 30, or 50. It takes that suspension of disbelief to start going on the process, to start developing the initiatives, to start talking to their teams, and to start setting a new target to allow people the space to think differently and to realize their full potential.

Doug Yakola: There is a real value to having an independent perspective. Many times the management teams—highly, highly qualified management teams—have been living with a plan and living in the business for a long time, and they developed paradigms. Those paradigms sometimes are unknown to them. Bringing in someone who has a fresh perspective and is very independent is powerful in making these happen well.

Tim Dickson: Let’s just talk a little bit about the chief transformation officer, which is another of the important ingredients of success in these programs. Stephen, what’s your perspective on that?

Stephen Hall: Our view is that the chief transformation officer role, or CTO, is absolutely critical to driving a transformation program. Very often, companies that have been through change processes will have appointed someone to be the head of the PMO—the program management office—or something of that nature. It’s generally a midlevel executive who is reporting upward to an executive team.

That’s often what they expect when we show up. We push for something that feels very different to that. We insist on there being a chief transformation officer, someone who will report directly to the chief executive, who will sit on the executive management team as a peer to all of the other executives who might be leading large businesses or leading functions, and someone who’s not going to have profit-and-loss responsibility for the outcome but who’s going to have responsibility for the quality, the rigor, and the pace of the transformation program. This comes down to quite subtle things. It’s less about the mechanics. It’s more about the degree of challenge that goes on in those early conversations.

Very often, we’ll have a CTO say to the chief executive, “I’m going to pick some battles here. I’m going to pick a few fights with members of your team, and you have to back me on each of those battles. If you don’t back me and you don’t give me the independent authority to drive this process and to challenge your team, then we’re not likely to be successful here.”

That constructive tension that gets set up, in the best of these programs, is one of the things that allows an organization to go further and faster than it would do under a “business as usual” governance approach.

Tim Dickson: Some people listening to that will say that the constructive tension could become unconstructive conflict. Do you have any thoughts about how to avoid that, Doug?

Doug Yakola: This is where you need the experience. We often say that the skill sets you need to run a company are very different than the skill sets you need to transform a company. Finding someone either internally at the client, then with heavy coaching, or using an experienced chief transformation officer is really, really important.

You do have to pick your battles. You can’t fight every fight. The trick here is to get people to understand that you’re acting almost like a personal trainer. You are pushing them so that they can get better. It’s best if you can develop those relationships early on and make connections, personal connections, with people, so they can see you as a CTO, as a person just trying to do the best for the organization.

Michael Bucy: And to Stephen’s point, it also takes the one-on-one conversations between the CTO and the CEO and with the other leaders to work through, to orchestrate these conversations, to get on the same page, to form the personal relationships that are going to be the foundation for driving the trains forward. Don’t underestimate how powerful those personal relationships need to be in order to have the tough conversations in the more public settings.

Tim Dickson: We’ve talked about the importance of the senior people in these programs. But underlying a transformation is the transformation office. Mike, can you tell us a bit more about what that is and what it looks like?

Michael Bucy: First and foremost, it cannot be a PMO. It can’t be how you traditionally think of a program management office that is tracking initiatives, that’s counting the dollars, that all it is doing is keeping score. The transformation office has to add more value, and it adds more value by recentering the conversation.

The focus needs to be on the initiative owners—the hundreds, the thousands of folks around the organization that are trying to drive the change across the business. The transformation office has to focus on them and figure out what it can do to help those initiative owners get things done where they have failed in the past. Driving action is the heartbeat of the transformation office, and then creating a cadence throughout the organization, a relentless cadence, to drive action again and again and again in order to move the organization forward.

Stephen Hall: One of the best transformation offices that I ever saw was in a large, basic-materials company. It set up the transformation office—it was a big, circular room—right in the heart of the organization. It was a place that people would naturally come past and come through.

There were no chairs in the room. All it had was stand-up space. And it had whiteboards all the way around the walls. On every whiteboard was a separate major work stream and the underpinning initiatives and what the progress on each of those were. The company had the work-stream leaders, the sponsors, and the underpinning initiative owners come in every week and give an account of the progress that they were making, talk about where they were falling behind, and drive it through to a very, very pragmatic set of must-dos, so-whats, in terms of removing barriers, moving things faster, finding ways to fill gaps that have occurred, and so forth.

At the top of this room was  a gradation all the way around the room, which described the overall target that the [transformation owners] were headed for. They called it “the snake.” Every week, the snake progressed another half meter or meter around the room. In the end, that snake went around the room, I think, two and a half times. That’s how much more they achieved versus what they initially set themselves as an aspiration.

## Transformation with a capital T

Tim Dickson: The transformation office is about getting that cadence right, the processes right, and marshaling the energies of the employees of the company. But a lot of it, I know from your work, is about getting the mind-sets of employees pointing in the right direction and encouraging that mind-set. Mike, would you talk about how you go about changing mind-sets when they’re not going in the right direction?

Michael Bucy: Equally as important as the specific initiatives, the “what,” as we talk about it, is the “how”—how is the transformation going to be executed? And even more broadly, how are we going to change how the organization is run? In every situation I’ve been a part of, there have been deeply held roadblocks or mind-sets that are holding the organization back from its full potential.

Sometimes it’s folks within the organization who are just waiting to be told. Sometimes the organization is so siloed that it is prioritizing and optimizing for a specific function or business unit, rather than the tribe as a whole.

It’s finding what those are. It’s what the individual mind-sets are in a given company situation and the culture that’s grown up over time, in unlocking that and calling that out and then figuring out how you’re going to change that that really allows the organization to go from a performance level that’s good or OK to great and, most importantly, sustainable.

Doug Yakola: Adding to what Mike has said, we have a very strong belief that you just don’t think differently and then everything’s OK. You have to actually put quality effort behind changing mind-sets, which then change behaviors in the organization going forward.

The way I like to talk about it is, what you need to do in a transformation is to get people to act differently. When people begin to act differently, they will begin to think differently. The transformation office and the way that Stephen was describing the big round room and getting people to go around, those are examples of getting people to act differently and, therefore, think differently.

One of the best examples I saw was a situation where we walked into a company that thought it needed about $100 million of overall improvement, this was both on revenue and cost. After doing an independent look at it, we came up with a number that was six times that that it could go after. Watching the executives  get their heads around the fact that there was six times more value than they originally thought, and then the courage that it took for them to say, “We’re going to go after it, and we’re going to go after all of that,” was very inspiring.

We put a whole program toward doing that, toward going after the peak that they never thought they could attain. This company built confidence. The people in the company built confidence as they started to climb that mountain. When they got done with that $600 million, they went back to the well again, and they found another $400 million.

Tim Dickson: One of the most difficult things, and I think your experience backs this up, is to sustain the impact of that transformation beyond that first six to nine months and to avoid a situation where people just get tired and go back to their bad old ways. I’d like to ask you all to reflect on that.

Stephen Hall: I think that, beyond the mind-set changes we’ve talked about, it is retooling capabilities that is critical to being able to sustain a transformation after the formal highly focused program has run its course.

People need to learn to work in different ways. They need to learn different skills. They need to learn how to connect differently with their customers. They need to learn how to work differently with their supply chains. These are all areas where I think that there’s much more for us to do and, indeed, for the companies themselves to do, to ensure they’ve got a workforce that’s going to take them forward, not just back to the old equilibrium, as you described it before, Tim.

Tim Dickson: Doug, is it capabilities as you see it? Are there other things, in your experience, that drive sustainability when it goes well?

Doug Yakola: It’s absolutely about capability. But I also think that there’s something to be said for the discipline of a cadence. One of the things that we enforce early on in a transformation is that there is complete transparency and accountability for the type of initiatives that people are working on.

It will be expected that they’re going to come in every week and they’re going to talk about how they’re doing against that. That begins to get people to form a habit. Somewhere out there is a truism that is, you do anything for three weeks and it becomes a habit. In this case, we’re doing this for a year. You engrain this habit into people that is a sense of accountability and a sense of discipline with how they go about their daily jobs, and I think that makes it sustainable as well.

Michael Bucy: Agreed on both Stephen and Doug’s points. I would add two things. One is that the transformation can’t be separate from the financials and the financial processes. It has to be part and parcel. Therefore, the initiatives that are delivered are baked into the budget, into the forecast.

Then the annual cycle that the business goes on, where the next budget is set, has to have the same transformational thinking in it so that the organization has learned, as Doug was saying, a habit of going after value. Then in the next budget cycle, the executives set another ambitious goal and go after that and go put that value to the bottom line.

Then the second thought is changing how the company runs, how the company operates. If the company feels the same on day zero and on day 365 or in two years, you probably haven’t changed the company so that the transformation will be sustainable. You have to change how the company identifies, makes, and executes decisions at its core.

Tim Dickson: So it’s permanent revolution or a permanent new way of working. How would you best characterize it, Mike?

Michael Bucy: This is the new way of business for our clients and for the business community at large. Transformation is here to stay because, at the end of the day, transformation is about reaching your full potential, and I think that’s what all businesses are going to start to think about more often.

Stephen Hall: One of my clients uses the phrase “constructive dissatisfaction.” That’s a wonderful way of describing the kind of ethos that you want to see in a company that’s going to continue to improve. From the CEO down to people at the frontline level, they’re all constructively dissatisfied with their current level of performance and are always looking for ways to take the next hill, to move things forward, to improve, to extend.

That mind-set ultimately is what distinguishes companies that continue to lead and that thrive in what are increasingly turbulent and high-change environments, versus those that ultimately get through a process but collapse, exhausted at the end of it.

Tim Dickson: I’m afraid that’s all we have time for today. Thank you, Doug Yakola, Stephen Hall, and Michael Bucy, for making the time to speak with us. To learn more about McKinsey’s thinking on transformations and other hot topics in business and management, please visit McKinsey.com.

## How relevant and useful is this article for you?

## About the author(s)

Michael Bucy is a partner in McKinsey’s Charlotte office, Stephen Hall is a senior partner in the London office, and Doug Yakola is a senior partner in the Boston office. Tim Dickson is deputy editor in chief of McKinsey Quarterly and is based in the London office.

## Explore a career with us

## Related Articles

## Transformation with a capital T

## The ‘how’ of transformation

## The four building blocks of change","{""publication_date"": ""October 17, 2017"", ""word_count"": 3807, ""reading_time_minutes"": 19}",2025-03-14 12:42:38.354387
56,Using generative AI to transform customer experience,https://www.mckinsey.com/capabilities/growth-marketing-and-sales/our-insights/using-generative-ai-to-transform-customer-experience,text,"## Using generative AI to transform customer experience

At 112 years young, Holcim is proving that age and innovation can go hand in hand. With headquarters in Switzerland, a presence in 70 countries worldwide, and $27 billion in net sales, the construction building materials company is using cutting-edge technology to help the customer ordering process run more smoothly. To transform what was once a manual system into something speedier and easier to use, Holcim recently began experimenting with a generative-AI (gen-AI)-enabled mobile solution that allows customers to place cement orders quickly through a messaging app. This frees up Holcim’s sales staff to focus on higher-touch, more complex orders. As part of the C-Suite Growth Talks series from McKinsey’s Growth, Marketing & Sales Practice, Juan recently sat down with McKinsey’s José Carluccio to talk about the great promise this pilot is showing. The following is an edited version of their conversation.

José Carluccio: What does the journey look like for a customer when they want to order cement?

Juan Beltrán: Traditionally, it’s been very straightforward. If someone wants cement, they call a sales rep and ask them, “Hey, can you please send me another truck of cement?” And that’s all. The sales rep looks at the contract, the materials available, and the address where the company needs to deliver this order. They have a conversation with the customer. Then we ship it. It’s very simple.

José Carluccio: How do you make a simple process even simpler with gen AI?

Juan Beltrán: We want to allow customers to order by text. We’re doing that by going to a well-known, well-adopted solution for many people. That’s WhatsApp. And we’re using gen AI to try to understand the customer’s natural language when they speak, because when they order, they may not use SKU numbers or product names.

José Carluccio: What has your experiment looked like?

Juan Beltrán: We conducted a pilot last year in Spain to test an AI-enabled copilot customer ordering solution. Instead of picking up the phone to make a call, a customer can open up WhatsApp and request a cement truck. Our tool recognizes the customer, brings up their order history, and makes proposals for the next order. The AI model uses natural language when responding to the customer and makes suggestions for products to order. The customer can then make modifications to the order, including the number of trucks, the delivery time, the type of material, and where we should ship the cement. Then they can confirm the order. Then we ship it.

We wanted to see if this was something our customers would like. We got amazing feedback. They said it’s been very convenient for them. It’s made it a lot easier to place their orders anytime, from anywhere.

José Carluccio: What have the results been?

Juan Beltrán: With this AI-enabled pilot, around 66 percent of our first-order proposals were accepted because they’re accurate and reflect what customers want. There’s also been increased adoption with this tool compared to other customer portals; we managed to move from a 25 percent adoption rate to a 93 percent adoption rate.

José Carluccio: We see a lot of hype around gen AI. Getting value out of it is not easy. What have been some of the challenges on your journey so far?

Juan Beltrán: The use case is straightforward, but generative AI is quite new and there’s not a ton of expertise around.

During testing, sometimes our gen-AI-enabled tool could be too chatty, or overexplain things, or even recommend products that weren’t part of our product portfolio. These are the main challenges. We need to handle them by restricting possible answers to queries.

Latency is also very important. The customer expects a human-like interaction. They expect to receive a message like someone is writing it. They don't expect the message or product proposal to appear too fast. They expect that it takes a little bit of a time lag. But the response from us also needs to be quick enough. If it takes five or ten minutes, the customer is going to abandon the process. These are some of the tricky things we encountered during our testing.

José Carluccio: Can you give an example of something the gen AI tool got wrong during testing?

Juan Beltrán: During testing, one customer tried to see if he could order a famous Spanish cold tomato soup called gazpacho through this copilot tool. The tool identified gazpacho as a new SKU and proposed sending a truck full of gazpacho soup. It was funny. But no, we didn’t deliver a truck full of soup.

José Carluccio: What’s your secret sauce to get such high adoption rates?

Juan Beltrán: It’s critical to meet customers where they are and offer a solution with tools they’re already using. In this case, it’s WhatsApp because we know our customers are already using it. They don’t need to learn how to use something new. They don’t need to select products from a catalog. They don’t need to overthink. They just need to use what they use already. It’s also important to let them use natural language.

José Carluccio: How do you inject your AI models with a human touch?

Juan Beltrán: We try to make things as human as possible. Humans decide the tone of voice to be used for the interactions and the kinds of messages we send. Humans define the whole process. There are some cases where customers only need to interact with the copilot tool to get their needs met. But there can also be cases where they need more help. The LLM (large language model) may not handle certain queries effectively. That’s why we always offer customers the option to interact with a human agent.

José Carluccio: For this project, there are a lot of moving parts. There’s a messaging platform, a CRM (customer relationship management) system, a cloud provider, and more. How do you manage the complexity of a project like this when there are so many different systems?

Juan Beltrán: It’s not always smooth. Sometimes we work in parallel with two different models that are providing intelligence to the tool. But we make sure everyone knows what their roles and responsibilities are in the project. We try to provide clear accountability and transparency. And someone from our Holcim team took the lead in the project, jointly with McKinsey, making sure we were moving in the right direction and aiming toward a clear goal, which was to provide a fantastic customer experience. Everyone was very committed. Excitement makes collaboration easier.

José Carluccio: How long did this pilot project take? What was it like to prepare, set up teams, and stand up the proof of concept?

Juan Beltrán: The most consuming part of the whole project was the prework: looking at the requirements, finding the right partner, and understanding where the technology stands. It took some time to determine if the right technology existed to provide the solution we needed. This took around seven months. The actual development of the solution was quite fast. It took two to three months in total. The project took more time to find the right technology than to develop the solution itself.

José Carluccio: You now have proof of concept in Spain. How are you envisioning the next wave of AI-enabled ordering?

Juan Beltrán: We’re rolling out this solution to all regions in Spain. We want to make sure it works. We want to capture customer feedback, fine-tune the solution, and make sure it’s valuable for customers. Then in 2025, we’ll expand to other countries. We’re starting in Europe, then we’ll go global. This is an easy business line compared to others. We have more complex ones where there are many more products, many more SKUs, and many more ship-to addresses. Finally, we want to expand to other channels. WhatsApp is, of course, one of the most used channels, but phone calls are still popular with our customers. It’s a very industrial business, and when customers need cement, they don’t wait for someone to ask them. They pick up the phone, they call straight away, and say, “Hey, I need cement for today or tomorrow.” We need to find a way to add this technology behind phone calls and emails as well. LLMs will need to handle much more complexity. That’s next for our road map, and it’s very exciting.

## How relevant and useful is this article for you?

## About the author(s)

Juan Beltrán is digital manager of global sales excellence at Holcim. José Carluccio is a partner in McKinsey’s Lisbon office.

Comments and opinions expressed by interviewees are their own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement.

This interview was edited by Christine Y. Chen, a senior editor in the Denver office.

## Explore a career with us","{""publication_date"": ""February 6, 2025"", ""authors"": [""text""], ""word_count"": 1481, ""reading_time_minutes"": 7}",2025-03-14 12:42:43.802243
57,Inbal Shani on maturing your product leadership in the age of AI,https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/inbal-shani-on-maturing-your-product-leadership-in-the-age-of-ai,"dissecting it into smaller, accessible problems","## Inbal Shani on maturing your product leadership in the age of AI

In this episode of McKinsey on Building Products, a podcast dedicated to exploring software product management and engineering, McKinsey partner Rikki Singh speaks with Inbal Shani, chief product officer (CPO) at cloud communications company Twilio. Topics of discussion included leading with cross-functional empathy, anchoring product development in customer value, and executing effective change management during the transition into a new era of AI. This interview took place in August 2024. An abridged version of their conversation follows.

## Leading with cross-functional empathy

Rikki Singh: Inbal, tell us about your background and how it has shaped your product philosophy.

Inbal Shani: I have been with Twilio for four months, and I am excited about the journey ahead. I have many years of experience in both machine learning and AI. I started my career as an aerospace engineer working on navigation and control systems. I did my master’s in mechanical engineering with a focus on control systems, and I was using what was at the time called “genetic algorithms.” Really, it was the beginning of machine learning. Ever since then, I have spent my time across the stack, from building robots to working in the cloud.

The biggest thing that has shaped my thinking is my experience as a systems engineer early in my career. It helped me develop end-to-end thinking—how to solve a big problem by dissecting it into smaller, accessible problems.

My time at Amazon and AWS shaped my product thinking because customer obsession became part of my DNA and my continued focus. Last, learning how to think big picture helped me to focus not only on the details but also on how everything comes together.

Rikki Singh: You have had multiple CPO experiences. How do you define the role of a chief product officer, and what makes CPOs successful?

Inbal Shani: Across the industry, there is no single definition for a CPO—they can play different roles. For example, some are more heavily focused on the product, while others are focused on managing R&D. In my time at GitHub, I also managed product marketing and strategy. It really depends on the company, but CPO is a versatile role.

Renee Niemi, resident CPO of Products That Count, said, “A CPO is the only seat in the C-suite, next to the CEO, that touches every single function of the organization.” That is really the role of a CPO, and that is the biggest difference between a CPO and a senior vice president [SVP] of product. The SVP of product will define the focus of the product, the product strategy, what the team needs to build, and the product vision. A CPO needs to think about the entire product development life cycle, from ideation to when a product is in the hands of customers, and make sure that it is working well. CPOs also work closely with marketing and sales teams to make sure the product is landing the way it needs to.

Through that lens, one success measurement for a CPO is collaboration. How well are you able to establish collaboration with your peers, and how well do you help the company connect the dots?

Most important, the success of a CPO is based on the success of their products. So what does success look like? Do customers love the product? Do they adopt the product? When the product hits the market, does it have the right quality? How does that product translate to a go-to-market strategy? You can build the most successful product in the market, but if you are unable to position it right, encourage customers to use it, or enable the sales team to sell it, then you have failed to do your job as a CPO.

Rikki Singh: What is the most effective training ground for this role?

Inbal Shani: Through my different roles, I spent a lot of time building an overarching thinking to understand all the functions, all the stakeholders, and all the customers that I need to interact with. It is important to spend time with customers, the sales team, the marketing team, analysts, and investors to figure out what the market needs. Understanding the entire end-to-end experience is what gave me the best tools to do my role.

## Building AI-led products

Rikki Singh: How is your role changing as AI becomes more core to products?

Inbal Shani: AI has created a need for a specific skill set. For me, AI has forced me to use holistic thinking. It is important to understand all the aspects of a product, and a lot of that is the user experience. Today, AI is at the forefront of productivity, automation, and consumer delight and engagement. Historically, especially in the SaaS [software-as-a-service] world, product managers would think more about the back end and the data but less about the user experience. AI flips a lot of that thinking. You need to know when to use AI and for what because it is expensive. You need to ask if it is really giving the customers the ROI they expect from the tool.

AI also forces product managers to understand data. If your data is not where it needs to be, then AI is not an effective tool. Privacy and security become more important, too. AI has increased fraud, spam, phishing, and voice theft. For product managers, it is important to think about preventing vulnerabilities in the code.

Rikki Singh: What AI-centric product have you built that required you to think about these aspects?

Inbal Shani: Six or seven years ago, when I was working for Microsoft, we were building a conversational agent for digital customer support, focusing on the consumer world. At that time, customers did not want to chat with a chatbot. They wanted to talk to a human. But the volume of tickets that needed support made it impossible for employees to give customers the best service, so we needed to create a conversational agent.

The technology was quite new, and it was not easy to integrate—it did not feel like a human. We spent a lot of time trying to understand the customer because this service was also a change for them. We wanted to have most traffic come through the chatbot because it could solve problems, troubleshoot, suggest actions, and provide documentation. We had to figure out how to take customers through that change management phase so they could move past their initial inclination to pick up the phone or send an email.

That AI-centric project was centered on customer engagement. We asked, how can we get customers more involved and more excited to have a conversation via a chatbot versus a human being? How close can we get that chatbot to sounding and looking like a human without being one? How can we take all the information that came from a chat and summarize it if an issue needs to be escalated to an agent?

That project required us to focus on the customer and work backwards to understand the change management that the technology required.

Rikki Singh: How did you involve other functions? Did you have to engage the product marketing team and others to learn what they have done in the past or how they have seen behavior shift?

Inbal Shani: We engaged product marketing and the team that was building that foundational layer of AI, collaborating with them to improve the models based on customer feedback. We also worked closely with the support agents because they were the ones at the end of the line catching all the conversations the chatbot could not solve. Through them, we could figure out how we were improving customer support engagements and making the chatbot more visible.

Rikki Singh: You mentioned that one of the key aspects of being successful as a CPO and building products is figuring out the metrics for success. Do success metrics of AI-centric products look different? Have they evolved?

Inbal Shani: In the past few years, there has been a shift to measuring outcomes more than traffic. Measuring traffic is not enough in the world of AI, and yet outcomes are difficult to define. I think measuring outcomes is complementary to metrics we have always used, such as adoption, engagement, churn, and time to value. But we are shifting from measuring speed to focusing on time to value, and that is a much better representation of return on investment.

We used to think that reducing time to production was enough, but the bar for customer expectations has become much higher. Now companies think more about the value customers are getting and the effort required to get that value. These additional measures help determine the success of a product. At the same time, you need to measure the things that already have a general baseline. We are still baselining these outcome-based measurements as we go to get the sense of what “good” looks like.

Rikki Singh: How have the roles and responsibilities across product and engineering teams shifted with AI-centric products? Are there new “must have” skills that were not considered previously?

Inbal Shani: More than ever, thinking critically is the number one priority. You need to understand AI and the problems you are trying to solve because the technology is very complex, despite being accessible. It comes with a lot of limitations and guardrails. For example, you need to create privacy and trust and understand the cost. While you can experiment more freely, taking AI-centric products to production requires you to be grounded in critical problem-solving as well.

You also need to understand the data you’re using. It’s not just about creating out-of-the-box experiences: it’s about connecting automation and a system of data to get desired outcomes.

Product managers are adopting “cost thinking” more and more, too. When the migration to the cloud started, many companies went full in—they were willing to spend money to modernize their stacks. Then there came a time when everyone started to reconsider how much they were spending and realized it was more expensive than they had imagined.

## Navigating the hype around AI

Rikki Singh: What key challenges do companies face when they build more AI-centric products? How should they adapt to these challenges?

Inbal Shani: Change management is difficult—and it’s even more complex right now because it has to happen across the entire company, not just within product and engineering teams. Companies must be intentional when they decide to pursue an AI transformation for their products and experiences, because there is a learning curve. You need to build the right skills in your team, and it’s possible that these skills did not exist before because you’ve never incorporated AI or similar tools in your stack.

Companies also need to understand how to think about data, privacy, and security. How are you adopting even more of a security mindset on your R&D team? And how are you translating that to marketing positioning? As we said, outcomes-based measurements are not that deterministic. So how do you translate these metrics into a go-to-market strategy and into marketing campaigns to show the value you are offering? And how do you train your sellers to talk about the things customers care about? Historically, sales teams have not focused on outcomes. They are focused on adoption, usage, and integration rather than on selling an outcomes-based experience to a customer.

There also is a lot of hype around AI, but AI is not a silver bullet. It is a tool, and we need to use it responsibly to solve the right problems for customers. Companies need to be grounded in the products they are building and solutions they are providing.

A lot of companies are jumping into AI without understanding the tech. The barrier to entry has gotten lower, making AI more accessible for everyone, but companies should not incorporate a technology stack without truly understanding it. You are responsible for these experiences, so as an R&D organization, you need to spend enough time understanding the risk and the complexity of everything being incorporated into the solution.

Rikki Singh: What tools do you use to differentiate a hype cycle from a real opportunity in the AI space?

Inbal Shani: In general, when people talk about AI, they are talking about using large language models. Before, I used AI systems to fine-tune common filters and control systems. Then we moved to the world of predictive AI. Now we are in the world of generative AI to complete code, write essays, and generate content. AI is a wide spectrum of technology.

I usually try to compare new AI systems to what we had before, determine what the evolution was, and understand the purpose these new tools serve. It is not going to replace everything we have done before; it just provides us with updated capabilities and additional advantages.

Rikki Singh: What advice do you have for product leaders who want to dabble more in AI?

Inbal Shani: Take a step back. There is a lot of pressure, hype, and expectations around AI today. Really understand the customer and anticipate their future needs in this fast-moving transformation. Think about AI as a means to an end, not the end. Remain grounded in the problems you are solving, think holistically about the components you are using, and understand how to take your people through this journey.

Change management is also key. This is a big change for your organization and your customers. And if you are ever in doubt, always go back to the customer.

## How relevant and useful is this article for you?

## About the author(s)

Inbal Shani is chief product officer at Twilio. Rikki Singh is a partner in McKinsey’s Bay Area office.

The authors wish to thank Aditi Chawla, Akul Vijayvargiya, Chandra Gnanasambandam, Martin Harrysson, Melanie Duzyj, Stratos Botis, and Tanya Firman for their contributions to this article.

Comments and opinions expressed by interviewees are their own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement.

## Explore a career with us

## Related Articles

## Trisha Price on leveraging data to build great products

## Ya Xu on building AI and machine learning products

## Kareem Yusuf on building sustainability products for your customers","{""publication_date"": ""September 30, 2024"", ""authors"": [""dissecting it into smaller"", ""accessible problems""], ""word_count"": 2389, ""reading_time_minutes"": 12}",2025-03-14 12:42:49.867089
58,The Great Reset: North American asset management in 2022,https://www.mckinsey.com/industries/financial-services/our-insights/the-great-reset-north-american-asset-management-in-2022,20,"## The Great Reset: North American asset management in 2022

Global markets hit an inflection point in 2022. A decade of relative calm following the global financial crisis—including two years of supernormal returns after the initial shock of the pandemic—gave way to a new reality of supply-side disruptions, geopolitical tensions, and surging inflationary pressures. These factors have triggered a fundamental reset of macroeconomic policy and a fading away of the familiar backdrop of rapidly globalizing trade and capital flows, lower-for-longer interest rates, expanding central-bank balance sheets, and accommodative fiscal policy (Exhibit 1).

As the persistent—and, some would argue, secular—nature of these shifts became apparent, asset owners and asset managers alike have recalibrated their assumptions about pricing risk across the investable universe. The reset button has been hit for nearly every major asset class. Equities retreated from their historical highs in late 2021, with the S&P 500 declining by 20.6 percent over the first six months of 2022, its worst performance since 1970. Fixed income, once a reliable ballast against market downturns, suffered a 10 percent decline in the same period in the face of inflationary pressures—by some accounts the worst half-year performance by bonds in over 200 years. The greatest reversals were inflicted on some of the ostensible winners of the pandemic era: the high-flying technology sector and emerging asset classes, with valuations of some prominent tech unicorns subject to drastic down rounds and cryptocurrency valuations more than halving as investors decided to “get real” with tangible cash flows and hard assets. Despite the recent bounce-back in asset prices over the early summer months, significant uncertainty remains.

This great reset of macro, market, and policy assumptions has had three major impacts on the North American asset management industry:

• After two years of record growth and profitability, the industry hit a speed bump in its near-term economic trajectory, and significant questions remain as to which elements of its slowdown will be part of a new normal.

• The industry’s clients—institutional and retail alike—are under pressure as they cope with reopened funding gaps and anemic asset class return forecasts, and they are questioning previously reliable recipes for portfolio construction and long-term investing (Exhibit 2).

• The Great Reset of 2022 has loosened some of the foundational assumptions behind several of the past decade’s defining trends, including the internationalization of products, clients, and capital sources; rapid growth of risk-on and leverage-oriented business models; and a wave of commoditization borne out of the surging demand for bulk beta—assumptions on which the North American asset management industry had built its growth trajectory.

## How relevant and useful is this article for you?

## About the author(s)

Pooneh Baghai is a senior partner in McKinsey’s Toronto office, Andrew Gerba is an associate partner in the Summit office, and Philipp Koch and Ju-Hon Kwek are senior partners in the New York office.

The authors wish to thank Carlos Beltran, Edgardo Bonilla, Kevin Cho, Manraj Singh Dhillon, Victoria Nguyen, Sebastian Patino, Raksha Pant Tuladhar, and Henri Torbey for their contributions to this report.

## Explore a career with us

## Related Articles

## Wake up and see the women: Wealth management’s underserved segment

## Crossing the horizon: North American asset management in the 2020s

## The value of personal advice: Wealth management through the pandemic","{""publication_date"": ""October 28, 2022"", ""authors"": [""20""], ""word_count"": 548, ""reading_time_minutes"": 3}",2025-03-14 12:42:56.823357
59,Fostering better decisions through holistic ROI estimates,https://www.mckinsey.com/capabilities/strategy-and-corporate-finance/our-insights/fostering-better-decisions-through-holistic-roi-estimates,,"## Fostering better decisions through holistic ROI estimates

Recent volatility has added new layers of complexity to a topic that already challenges business leaders: prioritizing investments.

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• McKinsey Quarterly: 60th birthday edition

• M&A Annual Report: Is the wave finally arriving?

• Women in the Workplace 2024: The 10th-anniversary report

• The critical role of strategic workforce planning in the age of AI

When executives want to understand the trade-offs between different initiatives, they typically compare the projects’ net present values (NPVs)—the measure of an investment’s worth over its entire lifetime discounted to today. In theory, these analyses should balance near-term and long-term financial viability. In practice, however, that’s increasingly difficult to do because uncertain macroeconomic, regulatory, and geopolitical environments make future outcomes hard to predict. Additionally, business leaders tend to make many implicit but untested assumptions—and sometimes chains of assumptions—in the discounted-cash-flow calculations that inform NPV, multiplying the chances of getting unreliable results.

We believe the solution lies in supplementing NPV analyses with metrics that cover other priorities the investments aim to advance, such as resilience, adaptability, and sustainability. In theory, NPV calculations take these factors into account, but separately analyzing the nonfinancial value drivers (which we will call complementary factors) can help business leaders think through their assumptions and can potentially reveal hidden biases or misconceptions. Furthermore, assessing these factors in a rigorous way gives management teams a fuller picture of how a given combination of investments can help them achieve strategic imperatives. For public sector organizations, such an approach can be particularly useful given their mandates may not prioritize financial returns (see sidebar, “Expanded ROI in the public sector”).

## Expanded ROI in the public sector

For public sector organizations that often lack clear financial metrics for evaluating the ROI of investment decisions, an expanded ROI approach can be particularly valuable. Assessing how potential investments influence various organizational priorities helps decision-makers put analytic rigor behind what can otherwise be intuitive judgments.

For example, a government agency had to weigh the high up-front cost of a new digital technology that offered nonquantitative benefits against a lower-cost traditional system. The leaders first defined a set of complementary factors, such as system performance and production availability, in addition to net present value. They then modeled the impact of these complementary factors based on how significant stakeholders considered each factor to be. Other considerations were also taken into account, such as how the organization might phase each system’s implementation and the different acquisition timelines.

In addition, the decision-makers conducted several sensitivity analyses, which helped them derive an “advantage per dollar” metric rooted in the organization’s ideal outcomes. As a result, the organization chose to pursue the digital technology because, despite its higher up-front cost, it would deliver a greater advantage per dollar in the long term. The analysis also informed how the new system should be phased in to reduce risk and facilitate adoption while ensuring production availability.

To be sure, some of these complementary factors are difficult to measure, especially those that are qualitative in nature. This reality makes it essential for management teams to agree on what metrics best capture the information they need to make investment decisions. Additionally, many complementary factors often don’t correlate with near-term economic performance. For example, investing in onshore manufacturing capacity to boost operational resilience may not create an immediate financial benefit but could prove critical to a company’s ability to adapt to future external shocks and sustain long-term cash flows.

Organizations can take a multistep approach to get comprehensive ROI projections of different investment options. Calculating NPV remains the bedrock on which investment decisions are based but is supplemented by identifying the complementary factors that are material to the investment decision and selecting metrics to measure them. Finally, management should review the results to ensure they align with the organization’s priorities. This process forces business leaders to make their implicit assumptions explicit—both in terms of the relative importance of organizational priorities (and the trade-offs they may require) and how different investment options would influence them. The steps for the approach are as follows:

• Calculate NPV. NPV is the primary measure by which each potential project is assessed. Once business leaders have spelled out their assumptions and calculated all the NPVs, they can rank the investment options based on their potential for financial value creation.

• Define complementary factors. In parallel, leaders should define the nonfinancial factors that matter most to the organization. These could include operational resilience, innovation, sustainability, or agility in adapting to changing market conditions. Management teams should then decide which factors are the most significant contributors to strategic priorities before zeroing in on a handful that they incorporate into their broader analysis.

• Define the metrics for each complementary factor. Next, leaders should decide how they will measure each complementary factor (table). Some key performance indicators may be easy to identify—days of inventory for supply chain resilience, for example, or Scope 1 carbon emissions for sustainability. Other scenarios, however, may require relying on proxy metrics.
Business leaders should align on the best metrics for assessing the complementary factors, which can be quantifiable or qualitative. For example, when a luxury-fashion company was developing a decarbonization strategy, the leaders first ranked each project based on profit and cash impact, then added quantifiable nonfinancial metrics in the form of a marginal abatement cost curve to estimate potential reductions in carbon emissions from each project’s implementation. This helped them identify the trade-offs for each investment and the options with the best mix of cost-effectiveness and sustainability impact.
Organizations can also find proxies for qualitative nonfinancial metrics. Marketing ROI, for example, typically combines qualitative metrics with quantitative measures of impact on brand reputation, such as viewer impressions, changes in buying behavior, and loyalty.

Define the metrics for each complementary factor. Next, leaders should decide how they will measure each complementary factor (table). Some key performance indicators may be easy to identify—days of inventory for supply chain resilience, for example, or Scope 1 carbon emissions for sustainability. Other scenarios, however, may require relying on proxy metrics.

Business leaders should align on the best metrics for assessing the complementary factors, which can be quantifiable or qualitative. For example, when a luxury-fashion company was developing a decarbonization strategy, the leaders first ranked each project based on profit and cash impact, then added quantifiable nonfinancial metrics in the form of a marginal abatement cost curve to estimate potential reductions in carbon emissions from each project’s implementation. This helped them identify the trade-offs for each investment and the options with the best mix of cost-effectiveness and sustainability impact.

Organizations can also find proxies for qualitative nonfinancial metrics. Marketing ROI, for example, typically combines qualitative metrics with quantitative measures of impact on brand reputation, such as viewer impressions, changes in buying behavior, and loyalty.

• Assess each project against complementary factors. To compare a range of complementary factors, the respective metrics can be normalized to a score. This can be done by attributing a relative significance to each factor, as well as identifying the point of limited return. For example, a business may decide that cybersecurity is more critical to operational resilience than supply chain security—up to a point beyond which incremental gains don’t significantly contribute to resilience. This kind of analysis can help the team understand the impact of each project on strategic priorities.

• Rank the projects. Once leaders have combined the NPV and complementary factor analyses, they can rank the projects under evaluation across all the metrics to get a comprehensive view of projected investment outcomes. For example, a project could generate a large financial return but detract from operational resilience or sustainability goals, resulting in a midrange total score.

• Assess the results against organizational priorities. The ultimate goal of this exercise is to facilitate objective, transparent leadership discussions and decisions. Leaders can use the calculated scores to compare projected performance of projects across the different value drivers and determine which investments to pursue.

## Adding complementary factors to an ROI analysis requires identifying the best metrics.

• $/tCO2e1Metric tons of CO2 equivalent. abatement

• Liters of water/unit produced

• Community engagement

• Human rights support

• Share of employees from underrepresented backgrounds

• Funds donated to community engagement

• Share of suppliers audited for labor practices

• Corporate governance

• Projected impact on scores from governance rating agencies

• Supply chain resilience

• Impact on supplier lead times

• Penetration test resilience

• Service delivery efficiency

• Product reliability and durability

• Average service delivery time

• Impact on product defect rate

• Impact on service uptime

• Technological innovation

• Number of new products/services in development

• Impact on R&D pipeline

To see how this process works in practice, consider the experience of a chemicals company with a portfolio of approximately 300 capital improvement projects it needed to prioritize. About 60 percent of the projects were related to maintenance to keep facilities working, an additional 30 percent would improve margins through reductions in costs or energy use, and the final 10 percent focused on growth. In analyzing the benefits of each investment, the management considered three corporate priorities beyond financial performance: reliability of chemical processes, supply chain resilience, and sustainability, which would enable it to tap demand for green offerings.

When the team assessed each project’s NPV and its contribution to the three complementary priorities, it realized that some margin-related projects also improved plant reliability by modernizing the infrastructure. They then ranked the projects according to the combined ROI, based on which they decided to shift more than 50 percent of the spending to investments that would both improve margins and foster growth.

To get a full picture of the value that different investments can deliver, business leaders can combine an ROI analysis with assessments of nonfinancial complementary factors that matter most to the organization. By aligning on which complementary factors are most important and how to measure them, management can decide which investments will make the biggest contribution to strategic priorities.

## How relevant and useful is this article for you?

## About the author(s)

Chris Griggs is a partner in McKinsey’s Washington, DC, office, where Mary Helen Matthews is an associate partner; Kate Siegel is a partner in the Detroit office; and Matt Banholzer is a partner in the Chicago office.

The authors wish to thank Bernardo Azevedo, Joey Abla, Matt Cherry, and Tim Koller for their contributions to this article.

This article was edited by Joanna Pachner, an executive editor in the Toronto office.

## Explore a career with us

## Related Articles

## Tying short-term decisions to long-term strategy

## Matching the right projects with the right resources

## Capital allocation starts with governance—and should be led by the CEO","{""publication_date"": ""January 29, 2025"", ""word_count"": 1820, ""reading_time_minutes"": 9}",2025-03-14 12:43:03.013242
60,"“You have to manage the short, medium, and long term simultaneously. If you have the right strategy and you’re investing for the future, it positions you well to do that.”",https://www.mckinsey.com/featured-insights/quote-of-the-day/august-6-2024,,"## McKinsey quote of the day

## “You have to manage the short, medium, and long term simultaneously. If you have the right strategy and you’re investing for the future, it positions you well to do that.”

John Engel, chairman, president, and CEO of Wesco International, on modifying his leadership approach during a period of rapid change and volatility in “Wesco CEO John Engel on beating the odds with a merger of equals”","{""word_count"": 73, ""reading_time_minutes"": 1}",2025-03-14 12:43:09.509149
61,The future of Medicare Advantage,https://www.mckinsey.com/industries/healthcare/our-insights/the-future-of-medicare-advantage,Janet P,"## The future of Medicare Advantage

## TABLE OF CONTENTS

• How Medicare Advantage brokers can rise above market turmoil

• Star power: How Medicare Advantage payers can shine in the new quality-focused landscape

• Payer considerations in 2024 as Medicare Advantage changes

• Sweeping changes to Medicare Advantage: How payers could respond

## How Medicare Advantage brokers can rise above market turmoil

## As the MA market shifts, brokers face beneficiary churn, payers’ vertical integration, and compensation uncertainty. To survive, they’ll need to expand services and professionalize capabilities.

## By Cara Repasky, with Gabe Isaacson

Brokers are vital to the Medicare Advantage (MA) ecosystem, representing 70 percent of MA distribution. Today, though, brokers need to rethink their strategy as they sort through some of the biggest shifts in the MA market in the past two decades. At a time when payers are pulling back on benefits to navigate profitability challenges, brokers find themselves at the forefront of dealing with evolving beneficiary preferences, payers’ strategic shifts, and potential regulatory scrutiny.

These shifts are consolidating the brokerage industry. For example, changes in MA benefits heading into 2025 are leaving many seniors uncertain about their best options, leading to increased switching. This member churn means that, as brokers scramble during the annual enrollment period, customer acquisition costs are soaring. This pressure is pushing some brokers out of the market while sending others looking for acquirers. As acquirers expand, they can demand larger volume-based administrative payments, further cementing their advantage.

Is it game over for smaller brokers? Not quite. But to remain competitive, brokers must pursue new strategies to succeed. This article examines dominant trends among beneficiaries, payers, and regulatory environments and outlines a response that can help brokers.

With members increasingly shopping and switching, brokers need to strategize to remain the agent of record to the beneficiaries they support and prove their value to payers.

## Beneficiaries’ shopping propensity suggests the need for more longitudinal engagement

In recent years, churn among MA members has reached unprecedented rates (up about 70 percent since 2017).1 To the Point, “Medicare Advantage disenrollment rates can help beneficiaries make informed decisions,” blog entry by Janet P. Sutton, Commonwealth Fund, February 22, 2023. With members increasingly shopping and switching, brokers need to strategize to remain the agent of record for the beneficiaries they support and prove their value to payers. Brokers now need to keep in mind that even beneficiaries who are satisfied with their current plans are exhibiting a shopper’s mentality and seeking the latest benefit changes. This is largely due to supplemental benefits becoming increasingly generous, with an array of financial, health, and wellness offerings. All of this adds complexity heading into 2025, where some plans have increased product richness while many others have retrenched or exited entirely.

As baby boomers age, it is unclear if this trend of increasing churn will persist. Historically, older MA members have churned less frequently (7 to 8 percent for those 75 years and over versus 11 to 15 percent for those 65 to 74 years).2US Centers for Medicare & Medicaid Services Virtual Research Data Center 2021 claims and enrollment data. However, the newest generation of seniors has “aged in” amid this period of substantial supplemental benefit growth.

Given rising churn and the possibility of sustained switching behaviors, brokers should focus on longitudinal member engagement. They should expand client interactions and ensure year-round member engagement to ensure client satisfaction and improve renewal success. More broadly, they will need to be attuned to their clients’ needs to personalize guidance based on evolving health needs. But for that, they would need to rigorously track engagement, which could also help them prove their value to payers and, in turn, make higher compensation viable. This approach enhances the member experience and positions brokers as trusted advisers committed to their clients’ long-term health and well-being.

But not all brokers are created equally when it comes to beneficiary churn. While e-brokers drive high volumes, they are known for enrolling a larger proportion of members into special needs plans (SNPs) and dual-eligible special needs plans (D-SNPs), resulting in higher churn rates. The other type of broker—field marketing organizations (FMOs), or field brokers—generally deliver a smaller proportion of D-SNPs but stronger retention. E-brokers and FMOs are both caught in the disconnect between the need for retention and payers’ imperatives to grow the D-SNP cohort, which provides superior margin performance for payers.

But this market has evolved in recent years. E-brokers now enroll more members than either FMOs or payers—more than 40 percent of beneficiaries that enroll annually—according to McKinsey analysis that shows this increase from pre-COVID-19 to 2023. However, FMOs are larger operations than e-brokers and remain crucial partners to MA payers. In recent years, though, the FMO space has experienced a number of rollups. As a result, the brokerage landscape overall is now led by a small subset of large institutions, mirroring the consolidation and growth of the largest payers.

Many brokers are moving beyond their traditional sales focus to instead be sophisticated B2B partners with a better understanding of payers’ incentives while also focusing on supporting beneficiaries.

## Payers’ compressed margins create opportunities to be sophisticated B2B partners

Grappling with unprecedented headwinds, many payers—including national payers, which have been profitable in MA in recent years—are asserting a posture of margin over membership growth; some are even intimating at changes that might trigger membership losses in the coming year. In particular, payers are looking beyond pure payer revenues and continuing to pursue vertical integration, which has two key implications for brokers.

First, payers’ economics vary considerably by micromarket; they’re now pursuing growth in some areas but not in others. This will push many brokers beyond their traditional sales focus to instead become sophisticated B2B partners with a better understanding of payers’ incentives, while also prioritizing support for beneficiaries.

Now, as brokerage leaders increasingly interface with seasoned payer executives, they face expectations to elevate their performance standards.

Second, payers may seek broker acquisitions to both manage administrative costs and gain additional payer-agnostic assets. Brokers will need to contemplate if remaining independent leaves them better equipped to grow and serve beneficiaries compared with close integration with a payer.

Brokerages are at an evolutionary stage. Many originated from modest beginnings, yet their commercial evolution has outpaced their organizational maturity. Now, as brokerage leaders increasingly interface with seasoned payer executives, they face expectations to elevate their performance standards.

## Potential for rules that set compensation guardrails may necessitate new approaches

Less oriented around membership growth, many payers leaned into a proposed rule from the US Centers for Medicare & Medicaid Services (CMS) that would have reformed historical models of broker compensation.3“Code of federal regulations parts 417, 422, 423, and 460,” Centers for Medicare & Medicaid Services, April 23, 2024.  That rule is now stayed,4See American for Beneficiary Choice v. United States Department of Health and Human Services, Civil Action 4:24-cv-00446-O, N.D. Tex. July 3, 2024.   but considering payers continue to face margin pressures that could strain sustainability, broker compensation has become a strategic question: Will payers adjust or reduce historical broker commission levels as a means of reducing administrative costs? Recently, many payers have taken steps toward this, indicating that they will not pay commissions for new products that may be unprofitable. Payers choose to keep these products to retain legacy membership and mitigate disruption, but they eschew paying further commissions that drive growth in select unprofitable products.

Stepping back: in the 2025 Medicare Final Rule, CMS proposed a redefinition of brokers’ compensation. This rule, stayed by a Texas district court in July 2024, highlights the scrutiny on broker channels and aligns with recent governmental actions to crack down on bad actors. Historically, broker compensation entailed CMS-regulated enrollment and renewal commissions to the agent plus a bundled fee to the brokerage for all services provided during enrollment. These administrative fees, also known as overrides, are paid on a per-enrollment basis and are based on the fair market value (FMV) of those services. The proposal aimed to restrict overrides by eliminating fees for enrollment-related services, though leaving opportunity for other, non-enrollment-related services to be compensated at an FMV.

If pursued again and successfully implemented, these changes may require brokerages to separate enrollment-related services from others such as compliance, marketing, and commissions management. Furthermore, longitudinal engagement—a critical part of brokers’ adjustment to beneficiary churn—would also fall outside of enrollment.

Amid uncertainty about potential regulation, brokers can explore other approaches. This could include vending out marketing and sales or enrollment technology to payers, monetizing actionable information learned during the sales process (like drug, doctor, benefit preferences), and lump-sum payments for lead generation. Brokerages also have an opportunity to equip their agents with a full product portfolio inclusive of life insurance, final expense, Affordable Care Act plans, and more.

Brokers must now prepare for the long haul given the ongoing confluence of beneficiary, payer, and regulatory shifts. These trends force a need for brokers to upgrade their capabilities, expand their best practices, and commit to higher standards to meet evolving demands and expectations. The bar is rising: traditional lead generation and renewal efforts are being supplanted by payers’ proprietary lead sources, generative AI, automated screening, and technology-enabled distribution. The success of many brokerages has been on the back of a start-up mentality and enduring entrepreneurship. This mentality must persist, but capabilities also must expand.

Cara Repasky is a partner in McKinsey’s Pittsburgh office, where Gabe Isaacson is an associate partner.

This article was edited by Querida Anderson, a senior editor in the New York office.

## Star power: How Medicare Advantage payers can shine in the new quality-focused landscape

## An increased emphasis on clinical and health equity measures, while staying strong on member experience, is critical to secure 4+ stars and to bolster the overall Medicare Advantage strategy.

As Medicare Advantage (MA) payers continue to be buffeted by regulatory and market changes that could dampen margins, payer leaders should not lose sight of the importance of investing now to stabilize their businesses for the long run. A critical area of focus for leaders should be the Medicare Advantage Star Ratings program. While 4+ star performance is becoming table stakes, plans that emphasize achieving better Star-program performance tend to have an advantage.

## About the authors

This article is a collaborative effort by Cara Repasky, Anna Buchholtz, Ava Clarke, Sonja Pedersen-Green, and Will Lyle, representing views from McKinsey’s Healthcare Practice.

The Centers for Medicare & Medicaid Services (CMS) introduced Star Ratings in 2007 to improve the quality of care for members, with the expectation that the ratings would evolve over time. To date, CMS continues to refine the program to encourage plans toward targeted new priorities. But MA payers often get caught up in the complexity and number of changes that have been made to the Star Ratings program through the years. Some have debated the program’s value,1 To the Point, “Medicare Advantage disenrollment rates can help beneficiaries make informed decisions,” blog entry by Janet P. Sutton, Commonwealth Fund, February 22, 2023. deeming the rating system challenging to implement well given the frequency of the changes, and questioning the effectiveness of the Star measures to improve clinical outcomes.

MA payers should, however, stay on top of improving their plans to align with the latest Star Rating measures (see sidebar, “Upcoming changes to Star Ratings”) to be able to obtain a 4+ rating. If they don’t, they may find it hard to maintain a margin-positive business, and also stand to lose payments and rebates tied to the Quality Bonus Program.

## Upcoming changes to Star Ratings

The Medicare Advantage Star Ratings program was introduced to “help Medicare consumers compare the quality of Medicare health and drug plans being offered so they are empowered to make the best healthcare decisions for them,” according to the Centers for Medicare & Medicaid Services (CMS). The program consists of a series of measures that were designed to be adjusted, added to, or removed over time to continuously tailor the incentives to focus payers on improving their plans’ performance. The program has improved the quality of care that MA members receive since the program’s introduction in 2007.

It is imperative for payers to prepare for upcoming changes to measurements in the Star program, per CMS’s 2025 final rule announcement issued in April:

• While the overall weight of clinical measures will continue to be 43 percent, four new clinical measures will be introduced in rating year 2026 (RY2026), each with a weighting of 1.0: concurrent use of opioids and benzodiazepines, polypharmacy use of multiple anticholinergic medications in older adults, polypharmacy use of multiple central nervous system active medications in older adults, and care for older adults  (functional status assessment).

• The Health Equity Index will be introduced in RY2027 for those eligible for the low-income subsidy, members of dual-eligible special needs plans, and disabled members. It can provide a boost of up to 0.4 stars and replaces the reward factor.

• Two previously retired health outcome survey measures—improving or maintaining physical health and improving or maintaining mental health—will be brought back with a weighting of 1.0 and will account for 8 percent of the overall weighting.1“Medicare Health Outcomes Survey (HOS) outcome measures moved to display for 2022 and 2023 Star Ratings,” CMS, August 5, 2021.

• Weighting for measures related to patient experience, complaints, and access will be reduced from 4.0 to 2.0 for RY2026.2“Medicare Program: Contract Year 2024 policy and technical changes to the Medicare Advantage Program, Medicare Prescription Drug Benefit Program, Medicare Cost Plan Program, and Programs of All-Inclusive Care for the Elderly,” Federal Register, April 12, 2023. These measures will shift from 58 to 41 percent of the overall rating. Measures from the consumer assessment of healthcare providers’ and systems’ family of surveys, specifically, will represent 22 percent of the overall rating in RY2026, down from 32 percent in RY2025.

Our analysis shows that the Star program has increased the prevalence of cancer screenings, improved medication adherence, and helped close the gap for other preventative measures like flu shots and diabetic eye exams. Over the past decade, roughly 90 percent of the program’s raw scores have improved (Exhibit 1); for those that did not improve, this was likely because of heightened competition and increased formulary complexity. Payers’ focus on improving these scores has triggered better performance on metrics CMS deems to correlate with quality of care.2US Centers for Medicare & Medicaid Services Virtual Research Data Center 2021 claims and enrollment data.

The Star program also influences how members select plans. In the 2023 McKinsey Medicare Shopping Survey, 50 percent of respondents noted that a plan’s ratings were among the top features they considered, with 24 percent saying it was the most important aspect. In our 2020 survey, only 5 percent of respondents said it was the most important factor. As a result, 76 percent of MA members now enroll in 4+ Star plans, up ten percentage points since 2015.3“Code of federal regulations parts 417, 422, 423, and 460,” Centers for Medicare & Medicaid Services, April 23, 2024.  Yet despite this steady increase, 2022 represented a high-water mark. With the removal of the COVID-19 era’s temporary provisions that made it easier to perform well on the program, payers may need to rethink their approach to Star Ratings.

Now more than ever, payer leaders should consider how to integrate Star Ratings tactics into their broader MA strategy. MA margins will likely continue to be pressured by regulatory and market-level headwinds affecting both expected CMS reimbursements and members’ healthcare costs. All of this crystalizes the importance for payers to make Star improvements even more central to their MA strategy. The Star program is interlinked with other MA priorities, such as promoting higher-quality, lower-cost care and decreasing administrative spend, since higher utilization is likely based on demographic changes. Ultimately, plans with stronger ratings can reinvest their higher CMS rebates into additional plan benefits in a self-reinforcing cycle.

So what can Star program leaders do to prepare for upcoming challenges? They could start by creating a blueprint that includes building better relationships with providers, enhancing member engagement to address care gaps, and identifying members with social risk factors (SRFs), all while maintaining a focus on providing a high-quality member experience.

## Winning in clinical measures

The Star Rating pendulum is swinging away from measures linked to operations and member experience surveys and toward a combination of measures relating to healthcare effectiveness and Health Outcomes Surveys (HOS), as well as pharmacy measures.4See American for Beneficiary Choice v. United States Department of Health and Human Services, Civil Action 4:24-cv-00446-O, N.D. Tex. July 3, 2024.   Clinical activities will thus most likely replace member experience as the main arena for plans vying for a 4+ rating. This suggests that leaders should focus on building better provider partnerships and improving member engagement in their own care.

## Provider engagement plans

Strong provider collaborations can improve a plan’s performance on the Star program’s clinical measures while also enhancing members’ experience with providers. Payers can start by offering incentives to prioritized providers through service-level agreements and bonus payments to improve their performance on clinical measures and member experience. Partnering with providers who perform better overall—particularly when it comes to performance on healthcare effectiveness data and information set (HEDIS) details, pharmacy measures, and the consumer assessment of healthcare providers and systems (CAHPS) family of surveys—can be linked to a 0.5 to 1.5 percent reduction in medical loss ratio (most likely resulting from behavioral changes tied to provider incentive programs), according to a McKinsey analysis of plans with a high percentage of members in value-based contracts.

Additionally, payers can focus more on furthering value-based care through more meaningful risk-based arrangements with providers—that is, ensuring risk arrangements exceed 50 percent upside and 50 percent downside with no downside caps or shifting to full capitation. Payers should consider both increasing the number of providers in such contracts and advancing these relationships along the spectrum of risk—from pure fee-for-service to full-capitation contracts.

Payers can also strengthen provider relationships by developing digital provider-enablement tools that offer near-real-time member data. These capabilities will become increasingly critical as clinical Star measures become more time-bound (for example, requiring member-level follow-ups within 30 days after an event).

## Member engagement plans

Members themselves play a key role in managing their health. Digital self-service tools are increasingly available to help members understand their care gaps and plan benefits. However, it’s insufficient to expect members to fully understand and address their healthcare on their own. Member outreach is imperative, and personalizing targeted messages can help ensure necessary actions are taken. Subsequently, tracking how such outreach initiatives affect results is important for reallocating resources away from low-ROI methods.

Finally, as payers conduct outreach, the focus should be on recommending that members consider higher-quality yet lower-cost care. Given the broader margin pressures expected in MA, leaders should think about member experience in the context of medical-cost optimization. More coordinated and accessible care goes hand in hand with better member experiences and can lower total costs.

## Maximizing Health Equity Index performance

The year marks the first time in which CMS will collect data to benchmark performance for the Health Equity Index (HEI). This means that to maximize performance in rating year 2027 (RY2027), payers need to prioritize identifying—and engaging—members with HEI-defined SRFs now.

Two of the important demographics to home in on will be members of dual-eligible special needs plans (D-SNPs) and those eligible for the low-income subsidy (LIS). The D-SNP population, in particular, will be key: our analysis shows that plans with higher D-SNP membership have seen their HEDIS performance decrease over the past two years (Exhibit 2).

Improving HEDIS scores is important, as their performance will have a greater effect on overall Star Ratings given that the newly introduced HEI is expected to comprise select HEDIS and pharmacy measures.

While identifying D-SNP and disabled members from member profiles should be relatively easy, identifying LIS-eligible members could require more effort. CMS estimates up to three million seniors could benefit from this program but are not currently enrolled.5Report to the Congress: Medicare and the Health Care Delivery System, MedPAC, June 2020. To find likely LIS-eligible members, payers can consider claims, socioeconomic data, geospatial data, as well as information from screenings and surveys related to social needs and wellness, among other data types. Beyond current MA members, payers can also zero in on their own commercial or individual plan members who will age into Medicare in the near term.

Connecting with this segment early on can give payers a head start on improving performance for future members.

Once members who meet the SRF criteria are identified, they should be quickly engaged. Since most members are not aware of the LIS program, clear education on its benefits, including individualized assistance, might be needed. Payers should also have a strategy to connect members with SRFs with required clinical and social services, as well as enroll them into tailored care management programs.

Identifying and engaging members with SRFs could be inconsequential, however, for payers that do not in parallel invest in creating innovative product benefit designs for this population. They should expand offerings to include programs targeted at behavioral and social determinants of health, as well as improve benefits that focus on chronic conditions, for example, through value-based insurance design and supplemental benefits for the chronically ill. Payers should also build structures to deliver such a suite of wraparound services—for example, partnerships with community groups, religious institutions, housing organizations, and food security and nutrition assistance programs.

Addressing geographic challenges, such as those that rural and tribal communities face, should be another area of focus and can include the use of expanded networks, transportation support, and mobile-healthcare services. Payers should also collaborate with Medicaid managed-care organizations, supplemental benefit teams and providers, and population health and health equity teams, as well as offer analytics to coordinate care with these partners.

## Maintaining high-quality member experience

Although member experience measures will decline in weighting in RY2026, these measures still make up a considerable portion of the aggregate Star score. High performance in these competitive measures will continue to be critical to achieving a 4+ Star Rating for the foreseeable future. With a narrow margin for error, payers would be well served to not lose their focus on member experience, particularly those metrics on which plans have historically performed very well, such as foreign-language interpreter, teletypewriter availability, and timely reviews of appeals.

## Improving efficiency with automation and digital technology

Investing in automation and other digital technologies such as generative AI is key to improving member experience. For example, automated prior authorization, customer self-service AI chatbots, targeted member messaging, and automated outreach could help plans’ Star performance.

Such tools can also have the added benefit of helping reduce costs, especially administrative expenses. Our analysis indicates that in 2025, MA payers could face administrative and medical cost increases of $50     per member per month (PMPM), driven by increased healthcare utilization and administrative spend, and $30 PMPM revenue impact due to rate declines (Exhibit 3). Administrative efficiencies gained from improved digital tools will help offset these increases and the investments needed to fully integrate Star Rating improvements into the overall MA strategy.

MA payers may find themselves in the middle of a balancing act: they need to ramp up focus on clinical measures and HEI-related member outreach without ceding ground on member experience measures to achieve a 4+ star rating. This year has already laid bare the extent to which increased costs related to higher utilization can dampen growth. MA payers that adapt quickly and thoroughly to the Star program’s latest changes can position themselves as leaders in spurring a shift to high-quality care that lowers costs in the long run. Given the increasing headwinds pressuring Medicare Advantage margins, strong Star performance will be critical for payers to ensure the sustainability of their plans and overall MA strategy.

Cara Repasky is a partner in McKinsey’s Pittsburgh office; Anna Buchholtz is a solution manager in the Washington, DC, office; Ava Clarke is a capabilities and insights specialist in the Greater Boston office; and Sonja Pedersen-Green is an associate partner in the Minneapolis office, where Will Lyle   is a consultant.

This article was edited by Querida Anderson, a senior editor in the New York office.

## Payer considerations in 2024 as Medicare Advantage changes

## This year US health insurers have to navigate strong crosscurrents from demographic shifts, regulatory changes, and member preferences. How they react now can have an impact for years to come.

## By Gabe Isaacson, Dan Jamieson, Sonja Pedersen-Green, and Cara Repasky

The undeniable story of early 2024 for US health insurers has been the sustained economic pressures that Medicare Advantage (MA) payers are experiencing. This was borne out in 2023 year-end financial results, with several MA payers pointing to inpatient and outpatient care utilization being higher than expected, consequently increasing the medical-loss ratio.

Looking ahead, the financial pressure on payers could worsen. In its 2025 advance notice for new payment rates, the US Centers for Medicare & Medicaid Services (CMS) notes that there will be an aggregate revenue growth (3.7 percent)6“Medicare 2024 Part C & D Star Ratings technical notes,” CMS, March 13, 2024. when the increase (3.86 percent) driven by the risk score trend is included. Payers’ estimates of this number, however, vary widely.

Taken together, these headwinds only exacerbate the imperative for MA payers to contain costs. Savings will need to come from both medical costs and value-based care, as well as administrative expenses and product design changes. Yet none of this lessens the need to invest sufficiently to achieve growth expectations and Star-rating aspirations.

Cost-containment imperatives don’t lessen the need for MA payers to invest sufficiently to achieve growth expectations and Star-rating aspirations.

Higher utilization in 2023 was likely spurred by delayed care caused by the COVID-19 pandemic and other acute triggers in excess of historical trends. As the extent and longevity of these acute triggers are uncertain, payers can continue to monitor the research. But in the longer term, they can also continue to focus on how the aging of the Medicare population is likely to continue driving utilization, indicating that this could be a new normal. Similarly, some other seemingly gradual changes could nonetheless be disruptive this year.

Besides planning for demographic shifts, payers will need to navigate changes to Star ratings and rethink product designs and distribution channels. All of these factors are expected to complicate growth and revenue. As we consider the decisions that payers will need to contemplate, five key trends are coming into clear focus for the year ahead: the need for a product reset, an aging population, Star-rating pressures, opportunities in special needs plans (SNPs), and broker channel constraints.

## Product reset

The cost-containment imperative for MA payers means that a focus on ROI in product design is already emerging as an undercurrent in 2024 and is expected to be a priority in the 2025 bid cycle. Regulatory changes are putting pressure on top-line revenue and may seemingly warrant retrenchment, but instead we suggest that payers make calculated trade-offs and reevaluate their portfolios. In recent years, with more cash on hand, the focus has been on increasing product richness—for example, through new and more generous benefits, increasingly in cash and cash-equivalent forms—to drive growth.

However, as CMS starts to ask more questions on benefit utilization to assess efficiencies,7Based on analysis of CMS Part C and D program performance data. we expect to see a more triangulated focus on designing benefits for not just growth but also retention (for example, ease of use and vendor stability) and member outcomes (for example, proactive engagement in seeking care and flex card allowance focused on medical coverage rather than broader retail access). Even with possible new reporting requirements and nascent recommendations regarding standardization, supplemental benefits are expected to go from being nice to have to an offering that provides meaningful strategic upside. With the number of plan options increasing every year, the market may have reached a saturation point, leading to benefit designs that evolve from a buffet to a curated menu.

Payers were clearly grappling with these choices in the 2024 pricing cycle. Some pulled back in select markets and aligned investment to risk-bearing providers, whereas others employed a broader stance to deliver richness across markets in pursuit of a nationwide approach to membership.8“Contract Year 2025 Medicare Advantage and Part D Final Rule (CMS-4205-F),” CMS fact sheet, April 4, 2024. In 2024 and beyond, payers may see more value in having a concise narrative for distribution partners and beneficiaries rather than the “all things to all people” approach of recent years.

In 2024 and beyond, payers may see more value in having a concise narrative for distribution partners and beneficiaries rather than the ‘all things to all people’ approach of recent years.

A critical question for this year is whether the market has reached a tipping point in benefit generosity focused on growth and will shift to an environment in which payers are more intentional about ROI through member retention and improved health.

## Aging population

Nearly half of the MA-eligible population will be aged 75 or older by 2030, up from roughly 40 percent at the present time.9“Medicare Advantage and Medicare Prescription Drug Programs to remain stable in 2024,” CMS press release, September 26, 2023. This increase, along with labor-shortage concerns, has triggered rising qualms about a potential crisis in eldercare. Healthcare worker vacancies reached 710,000 in May 2023, and the educational pipeline indicates that the gap is likely to expand in the next decade. This makes 2024 a pivotal year to put in place solutions to rebuild the depleted workforce of doctors, nurses, certified nursing assistants, home health aides, nursing home workers, and other integral supporters of eldercare.

Besides the foundational solutions needed to address workforce challenges, we expect to see a shift toward next-generation care models to better help the higher-need aging population access the right care at the right time at the right cost. These models often use technology and data to personalize care through, for example, wearables, remote monitoring, telehealth, and sophisticated data platforms. This responsibility falls heavily on payers—not only those that already own many of these services, but also those that shoulder the responsibility of engaging members to navigate this complex web.

Of crucial concern are whether the emerging crisis will prompt those payers that aren’t already vertically integrated to begin down this path, whether it will encourage those that are vertically integrated to continue with M&A and investments in healthcare delivery, and if the next decade of investment will vary from the primary care–centric investments to date.

## Star-rating pressures

Another year brings another set of changes to Star ratings for payers to adapt to. For one, implementation of Tukey method guardrails for rating year 2024 will raise the bar on the Star program. The new provision nixes performance outliers from calculations, which in turn contributes to more challenging cut points. Also in the current rating cycle, plans will face the deweighting of member experience measures, which will place relatively more emphasis on clinical and pharmacy metrics.10“2025 Medicare Advantage and Part D advance notice fact sheet,” CMS, January 31, 2024. Payers will need to focus on member and provider engagement through both omnichannel outreach and an on-the-ground presence, an area that has traditionally seen lower investment. And it could well be that clinical and pharmacy metrics, even when properly collected, won’t affect Star ratings as positively as member experience measures have.

Looking ahead, another important change to the Star program is that a health equity index will replace the reward factor, which benefited plans with high and consistent performance across various measures. The index, though, will do more for plans with high performance on a subset of measures for their low-income-subsidy, dual-eligible, and disabled populations. For payers with fewer of these members or less experience in serving these populations, building out these capabilities will be a multiyear effort. We expect to see payers invest in these populations through both traditional care and addressing social determinants of health.

A vital matter is whether payers can adjust to the new guidelines and reverse the downward trend in Star ratings over the past couple of years.

## Opportunities in SNPs

The market for SNPs, driven by both demographic and regulatory trends, will continue to be an area of increased focus. As top-line MA population growth begins to slow, payers are continuing to seek out pockets of growth, and chronic-condition SNPs may be an emerging opportunity. They grew faster in last year’s enrollment period than dual-eligible SNPs (D-SNPs) did for the top three payers.

D-SNPs, however, remain the largest of the SNPs. Recent years have seen substantial growth in their population, with payer entry and investment to match. This isn’t lost on state governments. While not a nationwide phenomenon, more states continue to move into highly integrated and fully integrated models for the D-SNPs. New models are expected in 2026 for Illinois, Michigan, and Rhode Island, and many more states are likely to be close behind. Recent surveys point to 17 additional states that are considering pursuing new D-SNP contracting strategies.11David Kopans and Sua Yoon, “CMS upends Medicare Advantage supplemental benefits data reporting for payers,” DLA Piper, February 27, 2024.

McKinsey analysis indicates that while MA should remain a high-growth profit pool overall, the dual-eligible cohort is expected to see EBITDA increase by more than 10 percent by 2027.12McKinsey analysis of CMS landscape files. This means that payers are now grappling with the increasing imperative to invest further in Medicaid capabilities and partnerships, including through connecting with community partners and social organizations, to remain viable in this market.

A central issue is whether payers will make the needed proactive moves to prepare—whether the state they work within forces it or not—to build the capabilities necessary to remain viable for the D-SNP population.

## Broker channel constraints

Payers and brokers have been abuzz since CMS’s November 2023 announcement “proposing to redefine ‘compensation’ to set a clear, fixed amount that agents and brokers can be paid regardless of the plan the beneficiary enrolls in.”13McKinsey analysis of US Census Bureau data. With customer acquisition costs widely pushing north of $2,000 across the country, these compensation caps could—if implemented as proposed—have a meaningful impact on the financial solvency of the largest field-marketing organizations and brokerages.14“The impact of Stars 2024: An interview with industry leader Mick Twomey,” blog entry, AdhereHealth, October 20, 2023.

Although the compensation cap won’t affect those naturally aging into Medicare from commercial plans, it will affect other groups, as brokers have developed superior marketing and sales capabilities for them. To date, payers have used broker channels for their efficiency and high-volume capabilities, but the expected pressure on the broker business raises questions of sustainability and competitiveness.

To date, payers have used broker channels for their efficiency and high-volume capabilities, but the expected pressure on the broker business raises questions of sustainability and competitiveness.

A fundamental query is whether the new compensation caps will be a forcing mechanism for payers to bring more distribution into internal systems by enhancing and scaling their own marketing and sales capabilities.

Although 2024 has just begun, we already see some MA payers adjusting their outlook for the rest of the year. The sustained increase in utilization is only adding upward pressure on cost structures, while the CMS 2025 advance notice is putting downward pressure on revenue. We expect that the trends discussed in this article will deepen disruptions for MA payers. The next few months and the next round of financial results will be telling about which payers have anticipated these changes successfully, setting them up for success for years to come.

Gabe Isaacson is an associate partner in McKinsey’s Pittsburgh office, where Cara Repasky is a partner; Dan Jamieson is a partner in the Chicago office; and Sonja Pedersen-Green is an associate partner in the Minneapolis office.

The authors wish to thank Emily Pender for her contributions to this article.

This article was edited by Querida Anderson, a senior editor in the New York office.

## Sweeping changes to Medicare Advantage: How payers could respond

## The Medicare Advantage program will look meaningfully different in the years ahead. Payers will need to consider transformational moves in the near term to improve their ability to compete in the long term.

## About the authors

The Medicare ecosystem is facing a series of simultaneous challenges, disruptions, and opportunities that add up to one certainty: this market will look meaningfully different in the years ahead. Medicare Advantage (MA) is projected to be the line of business that drives the most profit for payers in 2026,15Alice Burns, Maiss Mohamed, and Maria T. Peña, “Medicaid arrangements to coordinate Medicare and Medicaid for dual-eligible individuals,” KFF, April 27, 2023. even while headwinds are emerging in the Medicare program. The Centers for Medicare & Medicaid Services (CMS) is projecting the Medicare trust fund will run out of money in 2031,16Neha Patel and Shubham Singhal, “What to expect in US healthcare in 2024 and beyond,” McKinsey, January 25, 2024. although investors continue to pour billions into acquisitions of payers, care delivery partners, and related healthcare services and technology providers across the Medicare value chain. Additionally, market penetration of Medicare Advantage (MA) remains hugely variable nationwide, with only about 12 percent of beneficiaries in MA plans in some states but about 60 percent in others.17“Contract year 2025 policy and technical changes to the Medicare Advantage Plan Program, Medicare Prescription Drug Benefit Program, Medicare Cost Plan Program, and Programs of All-Inclusive Care for the Elderly, and Health Information Technology Standards,” CMS, November 6, 2023. Meaningful disruptions—in demographics, regulations, and member preferences—compound the uncertainty, making it difficult for payers and other Medicare participants to chart a path forward. By making transformational moves in the near term, payers can improve their ability to compete in the years to come.

The strategic decisions private Medicare payers make now will determine their ability to have competitive capabilities and position themselves to succeed as the market changes. Some large payers and investors have already begun placing strategic bets to capture future growth (for example, buying up primary-care centers whose patients are enrolled in MA plans), despite the climate of uncertainty. By closely monitoring the ongoing shifts in Medicare, continually adjusting their priorities, and building new capabilities, payers can position themselves to succeed.

## Disruptive trends are shaking up the Medicare landscape

Payers are considering strategies to better address the aging population, a succession of pending regulatory changes, and shifts in member preferences for benefits and engagement.

## Demographic shifts

The demographic profile of Medicare beneficiaries and eligible individuals is skewing older. From 2020 to 2030, seniors aged 75 to 79, 80 to 84, and 85 and older are projected to grow as a proportion of all seniors. This is a shift from the 2015–20 period, when growth was more heavily in the cohort aged 65 to 74.18Based on McKinsey analysis of earning filings for publicly traded brokerages.

For many of these aging and higher-need members, today’s popular plans (for example, those with zero or negative premiums, rich supplemental benefits, or leaner core medical coverage) may no longer be the best fit. To retain members, payers may need to counsel them to switch to products that better match their evolving health needs, although some members are likely to resist, at least initially.

Medicare beneficiaries aged 85 and older average more than twice the monthly medical costs of those aged 65 to 69 and are more than three times as likely to have at least one hierarchical condition category.19Neha Patel and Shubham Singhal, “What to expect in US healthcare in 2023 and beyond,” McKinsey, January 9, 2023. This creates a substantial increase in clinical burden that will require payers to develop new capabilities in care management, social determinants of health (SDoH), and health equity—in line with CMS’s priorities. In the meantime, payers will continue to advance their capabilities as risk-bearing entities operating under capitated models. Specifically, where diagnosed conditions are most acute, payers could pursue specialist-centric risk arrangements. As needs intensify and mobility declines, payers could also develop intensive, home-based care models.

Along with the aging Medicare population, MA membership growth is slowing. We estimate that annual growth in MA membership will slow from more than 8 percent in 2022 to about 3 percent in 2031. As growth slows in historically strong and currently penetrated (primarily urban) markets, payers will seek to build the networks and capabilities to grow in historically less penetrated markets, such as those with large rural populations (Exhibit 1).

## Regulatory environment

The most sweeping set of regulatory changes to the Medicare Advantage program since the Medicare Modernization Act of 2003 will go into effect in the next three years, affecting rates, risk adjustment, Star ratings, and Part D. To adjust, these changes necessitate a nimble response from payers.

MA rates. The 1.12 percent effective MA rate decrease—the change in the amount paid per enrollee per year to payers by CMS—marks the first decline since 2015 (Exhibit 2).202023 annual report of the Boards of Trustees of the federal Hospital Insurance and federal Supplementary Medical Insurance trust funds, CMS, March 31, 2023. This translates to a loss to payers of an average of $150 per member per year.21For example, MA penetration in Michigan is about 59 percent and in Wyoming is about 13 percent. For more, see MA State/County Penetration 2023 06, CMS, June 2023.

Risk adjustment. CMS announced changes to MA risk adjustment following careful analysis, including observed higher-than-expected risk scores compared with fee-for-service (FFS).22McKinsey analysis of US Census data. CMS has refreshed the risk adjustment model to bring it more in line with FFS, driving MA rates down by 2.16 percent, on average.23McKinsey analysis of 2021 Medicare Fee-for-Service data. Risk adjustment remains a high-priority topic for payers as they respond to CMS’s Risk Adjustment Data Validation (RADV) Final Rule, which is expected to enable CMS to recoup $4.7 billion over the next ten years.24This rate excludes the CMS-estimated 4.4 percent rate increase from MA risk score trend.

Star ratings. For calendar year 2024, CMS reduced payment rates by 1.24 percent in response to a decline in average MA Star ratings, which resulted largely from expiring COVID-19 provisions and scheduled measure adjustments.25The 1.12 percent effective rate decrease equates to a roughly $4.7 billion loss in payment to MA plans, or about $150 per member considering 2023 MA membership. For more, see “Fact sheet: 2021 Medicare Advantage and Part D rate announcement,” CMS, March 31, 2023. Star ratings reached a record high in rating year 2022, with 90 percent of members in plans rated with four or more Stars; that number has fallen to 72 percent in 2023.26Report to the Congress: Medicare payment policy, Medicare Payment Advisory Commission, March 2022. Payers will likely face further headwinds from Stars technical changes—for example, removal of contract performance outliers using the Tukey method and revisions to disaster provisions—and the introduction of the health equity index (HEI). Starting with 2027 Star ratings, the new HEI will reward contracts for high measure-level scores with low-income subsidy, dual eligible, and disabled enrollees.27“Fact sheet: 2021 Medicare Advantage and Part D rate announcement,” March 31, 2023.

According to a simulation of the removal of the current reward factor and addition of the proposed new HEI reward, 1.7 percent (seven) of MA prescription-drug contracts gained a half star on the overall rating, while 13.4 percent (54) of contracts lost a half star on the overall rating.28“Medicare Advantage Risk Adjustment Data Validation final rule (CMS-4185-F2),” CMS, January 30, 2023; McKinsey analysis of historical audit results. Historically, payers have been able to respond to technical adjustments, the addition or expiration of certain metrics, and other changes to the Stars program, but the magnitude of these changes will be their biggest test yet.

Part D. As a result of CMS changes to Part D plans, payers will be prohibited from collecting back-end payments from pharmacies via direct and indirect remuneration (DIR) fees and will be required to assume greater responsibility for catastrophic drug coverage. Payers will lose more than $11 billion in plan revenue from lost DIR fees, equivalent to 74 percent of revenue from member premiums in 2021 (Exhibit 3).29“Fact sheet: 2021 Medicare Advantage and Part D rate announcement,” March 31, 2023. Additionally, reinsurance payments are currently the largest and fastest-growing source of payer revenues. In 2025, however, government coverage for reinsurance will drop by three-quarters, from 80 percent of catastrophic costs to 20 percent, leading to dramatic decreases in reinsurance payments to payers.30“2023 Medicare Advantage and Part D Star ratings,” CMS, October 6, 2022; “Fact sheet – 2022 Part C and D Star ratings,” CMS, October 8, 2021.

## Shifting member preferences

Members’ preferences for engagement with MA plans are fundamentally changing—in line with the seamless, omnichannel, and customer-centric experiences they now routinely enjoy with B2C companies such as retailers and technology providers. Most prominently, this change manifests in their rising preferences for digital engagement.31“2024 Medicare Advantage and Part D final rule (CMS-4201-F),” CMS, April 5, 2023. This appears first in the extent to which beneficiaries increasingly rely on e-brokers when shopping for MA plans. Of the more than seven million beneficiaries who enrolled in a new MA plan in 2022, more than one-third (about two million) used an e-broker, highlighting a meaningful shift to digital channels compared with even five years ago.32Medicare program; contract year 2024 policy and technical changes to the Medicare Advantage program, Medicare Prescription Drug Benefit program, Medicare cost plan program, Medicare Parts A, B, C, and D overpayment provisions of the Affordable Care Act and Programs of All-Inclusive Care for the Elderly; health information technology standards and implement specifications, Federal Register, December 27, 2022.

Beyond shopping, our recent survey data indicates that more than two-thirds of members reported using technology in the onboarding journey to understand benefit coverage, manage prescription drugs, and navigate physician networks.33Adam J. Fein, The 2023 economic report on U.S. pharmacies and pharmacy benefit managers, Drug Channels Institute, March 2023; 2022 annual report of the Boards of Trustees of the federal Hospital Insurance and federal Supplementary Medical Insurance trust funds, CMS, June 2, 2022. More broadly, delivering a distinctive omnichannel experience will be critical in retention of members and performing well on Stars ratings. The quality of members’ experiences will be a core component of competitive differentiation in the future.

## How payers can respond to the changing Medicare landscape

Payers can address changes in Medicare with near-term, targeted interventions and simultaneously carry out transformative initiatives. In the near term, they could consider the following:

• Pursuing sizable growth opportunities in underpenetrated populations (such as high- and low-income rural areas) with renewed focus and creativity to build products and networks—potentially augmented by virtual care—that will appeal to members traditionally less inclined to enroll in MA and historically presented with fewer plan options.

• Actively engaging in the evolving marketing and sales ecosystem—by diversifying their portfolio of partners to include more field brokers and e-brokers—to enable payers to reach more eligible individuals in their preferred (increasingly digital) channels. By supplementing their captive internal-distribution channels, which rely heavily on standard mailers and other traditional methods, they could also broaden their reach into, for example, communities with a higher proportion of minority residents or residents of relatively low socioeconomic status.

• Prioritizing investment in the Stars program to meet evolving beneficiary needs and address Stars performance and, therefore, revenue headwinds. Investment in Stars could be targeted to address SDoH needs, close clinical care gaps, and improve clinical outcomes for an increasingly aging population with more acute care needs, allowing payers to deliver a best-in-class member experience.

• Expanding digital engagement (such as through applications, text, and chatbots) to meet changing member preferences, and develop wraparound support services to increase member uptake and proficiency.

Additionally, a series of transformative initiatives could best position payers to navigate the future Medicare ecosystem.

Serve members with efficiency. For payers facing substantial margin pressure, administrative costs, which commonly exceed $100 per member per month (PMPM),34Inflation Reduction Act of 2022, Pub. L. No. 117-169, 136 Stat. 1818, 2022. are increasingly unsustainable. Plans can consider entirely new ways of managing administrative costs and running their budgets without sacrificing service quality. Although attaining economies of scale can create cost efficiencies, the distributed nature of MA membership creates challenges. Many single-state payers can boast a strong market presence yet have only tens of thousands of members. For most payers, reducing administrative costs will require investment in nonscale performance levers.

Typically, increasing cost efficiencies would require a meaningful investment in automation, data-backed decision making, and continuous reallocation of resources. Specific actions to consider include the following:

• embarking on true zero-based budgeting,35Gabe Isaacson, Marina Ivanenko, and Cara Repasky, “Digital engagement now typifies the Medicare Advantage experience,” McKinsey, March 9, 2023. targeting an administrative cost of less than $80 to $100 PMPM so that it could better withstand any changes in top-line revenue

• expanding reliance on shared technology platforms and services to manage costs while also investing strategically in products and capabilities

• investing now in innovative technologies that will soon become standard, including, for example, chatbots to assist members with support and requests (such as generative AI) and self-serve portals with tools to help members find the best plan for them

Deliver seamless shopping, enrollment, and onboarding experiences. Demographic changes will result in fewer seniors enrolling in MA, expanding opportunities to reach new and existing members. Payers could create and deliver an integrated experience from shopping to enrolling and onboarding to attract and retain members. In a 2022 survey of MA members, nearly half indicated they had shopped around to assess product options in the year prior,36McKinsey analysis of earnings reports for SelectQuote (about 617,000 beneficiaries in 2022), eHealth (about 322,000 in 2022), and GoHealth (about 830,000 in 2022). Triangulated with expert interviews for private and broader market (more than 400,000 beneficiaries in 2022). highlighting the imperative for easily navigable websites and distinctive benefits positioning.

To achieve their growth targets, payers will also likely expand their reliance on brokers and other third-party partners. Success will hinge on having clearly defined member journeys and integrated internal and external channels (for example, call centers and onboarding). Multidirectional, real-time data sharing paired with efforts by payers to educate and enable brokers would allow the integrated distribution unit to optimally attract and retain members in a lower-growth environment.

Know each member and personalize engagement. Knowing members as individuals is becoming crucial to meeting their shopping preferences, implementing best-fit engagement channels, managing disease states, ensuring access to quality care, and supporting evolving care needs.

Although payers have vast repositories of data, their databases (for example, for customer-relationship-management and care-management tracking) have traditionally been siloed. Payers have also typically defaulted to standard reporting and struggled to perform ad hoc analytical queries to understand the full scope of member engagement. And they have relied extensively on third-party Stars vendors who engage in sporadic calling campaigns to engage members in their healthcare journeys.

Instead, payers could consider differentiating themselves in their engagement with members by meeting the standards set by leading retail and e-commerce players. This might entail establishing a singular view of each member over the span of their Medicare journey and using unique member identifiers to track data points and touchpoints across channels such as brokers, care managers, and physicians. With a holistic view of each member at their fingertips, customer service representatives could provide better support. Payers could develop AI-enabled predictive capabilities to provide personalized engagement plans and smart interventions. Ultimately, this improved transparency could unleash a ripple effect of better care, improved health outcomes, and an elevated experience for each member.

Convene and enable a redefined care-delivery landscape. The payer’s role in the care domain has expanded over time from utilization management to care management and, increasingly, care delivery. Some payers are carving out a leadership role as a convener of a care delivery ecosystem (encompassing the set of care models, physicians, capabilities, and services that surround a patient) while leaving care provisioning to clinicians. They are investing in enablement partnerships and acquisitions while working hand in hand with physicians to improve outcomes for Medicare members in meaningful risk-sharing arrangements.

Payers could accelerate this trend by assessing the clinical needs of their membership and mapping them to the care delivery landscape in their geography. For example, payers that have members with substantial clinical needs (for example, large populations with chronic kidney disease or special-needs plans for chronic conditions) might invest in or partner with specialists or advanced in-home care delivery partners. Payers with a large rural population could consider supplementing their care delivery footprint to address care gaps (for example, through virtual-care models).

Many payers would benefit from simultaneously pursuing multiple strategies, particularly as acuity in the Medicare population accelerates. Important considerations include aligning their incentives with those of physicians and patients and protecting physician independence in clinical decision making.

Payers could also use member data and conduct advanced analytics to match members with effective care models and enable physicians to deliver the highest quality of care.

A mature care delivery ecosystem would meet every member where they are through a combination of value-based care models (with physicians who can deliver against them), next-generation models (for example, rural-focused care), in-home primary and specialty care, and advanced care models.

Reimagine the product portfolio in line with MA membership needs. Payers often grapple with variable economics across the product portfolio. Newer members are typically enrolled in the most generous products with, for example, expansive dental and vision benefits, flex cards that cover not only over-the-counter medications but also food and wellness, and Part B givebacks (in which payers cover a set monthly amount toward a member’s premium).

These newer products are also the most economically challenging for payers. But although they would struggle to sustainably offer, for example, a $100 Part B giveback benefit, legacy members paying higher premiums (at least for now) effectively subsidize these offerings, resulting in an overall profitable membership mix. This trend, encouraged by many distribution partners, is unsustainable for payers, as evidenced by a number of previously high-growth MA plans that are now retrenching, rolling back benefits, and potentially causing meaningful disruptions in healthcare for tens of thousands of members.

The trend also doesn’t bode well for members as they age and their needs evolve. While members are relatively young and healthy, preferred provider organization (PPO) plans with $0 premiums and rich supplemental benefits but lighter core medical benefits can be a fit. These members, unconcerned with a higher maximum out-of-pocket cost, see supplemental benefits flowing directly to their personal bottom line—an especially appealing proposition at a time of high inflation and broader economic uncertainty. However, as the MA membership skews older, likely correlating with increasing medical needs, plans with richer medical benefits and lower maximum out-of-pocket costs may make more sense.

Payers can start now to evolve their product offerings and messaging to serve these members, including by rationalizing the supplemental benefit portfolio and reinvesting in core medical benefits that matter most to members’ health. In parallel, they can devise ways to counsel members to ensure they are continually enrolled in the right plan for their needs, perhaps over decades.

Given members’ increasing proclivity to shop, a proactive stance by payers will be rewarded. Payers could consider strategically engaging brokers, for example, to enable intrapayer plan movements. Although some payers and distributors have already begun to do this on an ad hoc basis (by, for example, proactively moving members to plans within their portfolios that have better Star ratings), taking a more strategic approach could help retain members within the payer’s ecosystem.

The MA market has been on an upward trajectory for years, with a continual stream of investor dollars chasing double-digit growth rates annually, enabling a thriving ecosystem of payers, care delivery partners, and services and technology companies. The variety of disruptions emerging, however, means that the winning strategies of the past five years are unlikely to be sufficient to meet members’ evolving needs and preferences. Success in the future will be determined by bold moves made now.

Gabe Isaacson is an associate partner in McKinsey’s Pittsburgh office, where Cara Repasky is a partner; Dan Jamieson is a partner in the Chicago office, where Emily Pender is a consultant; and Sonja Pedersen-Green is an associate partner in the Minneapolis office.

## How relevant and useful is this article for you?

## Related Articles

## Digital engagement now typifies the Medicare Advantage experience

## Harnessing AI to reshape consumer experiences in healthcare

## Medicare Advantage Star ratings may decline with new methodology","{""publication_date"": ""December 12, 2024"", ""authors"": [""Janet P""], ""word_count"": 9449, ""reading_time_minutes"": 47}",2025-03-14 12:43:16.822892
63,Improving military aircraft sustainment to strengthen Europe’s defense,https://www.mckinsey.com/industries/aerospace-and-defense/our-insights/improving-military-aircraft-sustainment-to-strengthen-europes-defense,,"## Improving military aircraft sustainment to strengthen Europe’s defense

In response to the changing geopolitical environment, European NATO countries have increased defense budgets, a significant share of which are expected to go to new equipment.1“Defense expenditure of NATO countries (2014–2024),” NATO Public Diplomacy Division, June 2024; “EDA defense data 2023–2024,” The European Defense Agency, December 4, 2024. As munition stocks grow and existing equipment ages, mission readiness—the ability to deploy military assets for their intended use—is an increasingly important priority for countries. This, in turn, is likely to boost demand for maintenance, repair, and overhaul (MRO) services. But it will be no simple matter for industry stakeholders to meet this growing demand in an era of tightening operations and maintenance budgets, supply chain constraints, and talent shortages.

## Our analysis

In the fourth quarter of 2024, we surveyed 30 experienced military MRO professionals to explore opportunities to improve MRO for European NATO countries in the air domain. While these findings likely also apply to other military sectors, we focused our survey and analysis on aviation.

The respondents—the majority of whom operate in Europe—represent manufacturers and OEMs, MRO providers, suppliers of subsystems and spare parts, and representatives of the government customer. Military aircraft MRO is typically provided by an ecosystem of players across the private sector and government-related entities, including in-house capabilities of the armed forces, privately-owned companies, and, in some cases, commercial providers servicing aircraft operated by defense organizations.

In this article, we build on a proprietary survey of military MRO experts in the air domain to explore how MRO providers can improve their operations to generate a mutually beneficial environment for MROs, OEMs, and military operators (see sidebar, “Our analysis”). We also consider how MRO providers who do not currently operate in this space could broaden their service offerings, not only to capture additional value but also to contribute to the defense industrial capacity in Europe.

## Increasing equipment stocks: What does this mean for MRO partners?

Since the invasion of Ukraine in 2022, European NATO countries have announced increases in defense budgets amounting to an additional cumulative €700 billion to €800 billion by 2028—an increase of more than 60 percent compared to their pre-2022 baseline.2“Innovation and efficiency: Increasing Europe’s defense capabilities,” McKinsey, February 28, 2924. The largest share of this additional budget is likely to be allocated to equipment acquisitions to help replenish Europe’s low stocks. Countries are already making new purchases—for example, in the air domain, Germany purchased 35 F-35 aircraft for approximately $8.5 billion in 2022.3“Special fund: Bundeswehr can buy 35 F-35A for around 8.3 billion euros,” Federal Ministry of Defense (Germany), December 14, 2022.

Across the 15 European countries with the largest air forces, 26 percent of all in-service aircraft were purchased before 1990.4“Fleets analyzer,” Cirium Aviation Analytics, January 2025. With aging equipment in service for longer, it requires significantly more MRO services. Adding to this challenge is an expected increase in the complexity of fleets as new aircraft transition in, along with a shortage of trained personnel in the aerospace and defense industry.5David Vergun, “DOD addresses recruiting shortfall challenges,” US Department of Defense, December 13, 2023. As countries seek to maximize the return on their defense spending, increasing the availability of military air platforms in a cost-effective way will become crucial.

However, our survey data indicates that turnaround times in military MRO still lag behind those for commercial aircraft. By taking a proactive stance in the changing geopolitical environment, MRO providers, whether they already serve military platforms or not, could meet growing customer demand and thereby contribute to European security.6For more information, see Cindy Levy, Matt Watters, and Shubham Singhal, “A proactive approach to navigating geopolitics is essential to thrive,” McKinsey, November 12, 2024. Both new players and existing military operators could improve their efficiency through strengthening processes and adopting digital solutions—thereby enhancing operations.

## The effect of aging equipment and decreasing MRO budgets

More than half of the industry experts surveyed expect aging and heavily used aircraft to be the top drivers of future MRO demand growth as older platforms will require more intensive—and expensive—MRO (relative to the original platform cost) as they approach the end of their intended lifespan.

However, while European NATO countries are allocating a greater share of the budget to equipment acquisitions, the operations and maintenance (O&M) budget for existing equipment is relatively stable, increasing by only one percentage point.

From 2015 to 2020, European NATO countries’ O&M spend was about $1.4 for every dollar spent on equipment; in the 2023 to 2028 period, this ratio is expected to be closer to $1.0 for every dollar spent on equipment, despite the average aircraft age already having increased from 23.0 years in 2014 to 25.8 years in 2024.7“Fleets analyzer,” Cirium Aviation Analytics, January 2025. Improving mission readiness with this lower ratio would only be feasible if required maintenance for new aircraft is significantly lower during their lifecycle, or maintenance experiences a step-change in efficiency.

## Commercial MRO capabilities could be applied to military

A comparison between military and commercial MROs shows considerable performance differences, indicating that military MRO providers could look to their counterparts to potentially increase their effectiveness and efficiency.8This refers to privately owned military MROs and commercial MROs doing MRO for military aircraft.

According to the air-domain MRO experts we surveyed, military aircraft spend an average of 40 to 50 days per year undergoing scheduled maintenance, compared to 25 to 35 days for commercial aircraft—with some cases exceeding this average significantly. An additional 30 to 40 days a year are spent on unscheduled maintenance in comparison to commercial aircrafts’ 10 to 20 days. MRO turnaround times for military aircraft often exceed the planned number of days: Our experts surveyed estimate that the planned turnaround time for the C-Check equivalent for military platforms is exceeded, on average, by 10 to 40 percent.9The C-Check requires an aviation maintenance technician to perform a deep inspection of the majority of the aircraft’s parts. Aviation maintenance technicians will perform certain tasks during C-Checks, such as examining structures (load-bearing components on the fuselage and wings) and functions for corrosion and damage, checking the operation of the DC bus tie control unit, or lubricating all fittings and cables. Data include all types of military aircraft, that is, rotary and fixed wing, combat and noncombat, and drones. However, it should be noted that in addition to differences originating from the bespoke nature of military equipment, such as the complexity of cabin maintenance or the challenges associated with defense-specific equipment, there are also obvious mission-related differences that make a direct comparison between commercial airline operations and defense aircraft missions challenging.

However, lessons from commercial MROs can still be incorporated into military MRO planning to maximize availability. These include taking full advantage of an aircraft’s downtime, reducing turnaround times of standard checks, and improving on-time-performance (OTP) of checks:

• MRO providers could optimize work packages to balance green time and ground time. This means comparing scenarios of performing tasks prematurely (giving away green time but bundling MRO activities) versus adding additional ground events (maximizing green time but reducing aircraft uptime).10Green time describes the remaining operational life of an aircraft (or engine or component) prior to any required overhaul, while ground time describes the time the aircraft is unavailable for service, that is, unproductive aircraft time.

• MRO providers could increase productivity to reduce turnaround times of standard checks. They could learn from best practice commercial MRO providers to increase density (the number of work package hours performed per hour) and enhance labor productivity which is typically analyzed by looking at the “hands on metal” (HoM) of the qualified technicians.11HoM reflects how much of the technicians’ available time in a shift they can spend on value-adding work at the aircraft instead of preparing work, searching for materials or tools, filling out documentation, et cetera. Based on expert interviews, we learned that productivity in defense is often more than 20 percent lower than in commercial settings. HoM could be improved by increasing operational steering.

• The experience and process standards of commercial MRO providers could help military MROs improve the OTP of their checks by focusing on aircraft leaving a check at the planned time. An OTP of over 90 percent is considered best in class.12Based on expert interviews.

In recent years, the commercial aviation market has seen even more volatility and unpredictability. Many commercial MROs have, therefore, gained relevant expertise to address these challenges, namely, supply chain disruptions, increasing costs of spare parts and raw materials, and a competitive talent market. However, these issues are becoming increasingly relevant for the military MRO sector as well and thus present an opportunity for commercial MRO providers to step into this space. By expanding their business into defense, commercial MRO providers could turn their expertise into a value-generating, competitive advantage.13Cindy Levy, Matt Watters, and Shubham Singhal, “A proactive approach to navigating geopolitics is essential to thrive,” McKinsey, November 12, 2024.

## How MRO providers could improve efficiency

The experts in our survey identified four root causes as having the greatest impact on effectiveness and efficiency in military MRO (Exhibit 1). These, and potential measures to address them, are:

## Spare part availability

The most cited reason for impeded efficiency is spare part availability, often affected by supply chain disruptions or insufficient inventory planning. To overcome this challenge, MRO providers could include flexibility in collaboration agreements, with an improved split between partners. Collaboration with other MROs could improve their data platforms to establish an “early warning system,” achieved by monitoring supply chains (such as tracking change requests and procurement anomalies to identify issues) while also training staff in scenario and risk analysis.

## Additional service provider involvement

Another cause of inefficiency cited is when additional technical expertise needs to be pulled in during maintenance from the airframe or engine OEMs—for example, when advice is needed on heavy structural findings. To ensure shorter waiting times and limited disruption, MRO providers may reassess their working relationships with OEMs. In best cases, response times and service levels are contractually agreed with the OEM during the initial purchasing process.

## Unexpected findings

In maintenance, unexpected findings are common and can lead to inefficiencies. These include increased waiting and process times due to additional coordination requirements (say, with the customer); unexpected demand for resources, such as spare parts or materials, critical capabilities, or machine availability; and the postponement of relevant nonsafety concerns, leading to an accumulation of issues and schedule overruns, for example, in base maintenance. Improving practices for managing unscheduled maintenance can improve these inefficiencies. Commercial MROs have established best practices and technologies: They use stochastic models and predictive maintenance linked to inventory management, which can reduce waiting times and increase equipment turnaround times. Military MRO providers could adopt similar solutions.

## Lack of talent

The aerospace and defense industry is struggling with a workforce shortage, largely due to an aging workforce and recruitment challenges.14Aviation talent forecast, CAE, 2023; Brooke Weddle, Giulietta Poltroniere, Hugues Lavandier, and Andy Voelker, “The talent gap: The value at stake for global aerospace and defense,” McKinsey, July 17, 2024. Many commercial MROs have recognized these talent challenges, taken steps to overcome them, and could advise military MROs on talent strategies, as well as explore collaborative setups. For example, commercial MROs have designed recruiting programs to attract new talent by improving their employee value propositions, enhancing monetary and qualitative conditions to attract suitable candidates, and sourcing talent from new locations. Similarly, they have addressed retention challenges through improved career journeys, offering clear development paths and new capabilities, and incentivizing long-term loyalty. However, it should be noted that commercial MROs are more flexible in crafting talent paths and adjusting salaries and nonmonetary perks compared to military MRO providers.

By applying the suggested levers to improve military MRO, European NATO countries could potentially reduce the investment needed in new aircraft and increase the speed at which they reach their defense capability goals. For example, in a hypothetical calculation, increasing equipment availability by 10 percent would be equivalent to gaining 40 additional aircraft.

## The role of digital in improving MRO efficiency

Given the potential of new technologies to improve operational efficiency and effectiveness across all industries, we asked the MRO experts for their perspectives on digital solutions in military aircraft MRO. (For further information on gen AI in aircraft MRO, see “The generative AI opportunity in airline maintenance.”)

They considered predictive maintenance to be the most impactful technology (Exhibit 2). Since AI collects and analyzes asset condition data to identify patterns and algorithms that can predict when failures may occur, predictive maintenance can help maximize asset operability for military MRO providers and allow components to be replaced or repaired before they fail.

Half of the respondents whose organizations have adopted digital reported that revenues increased by over 5 percent and engineering productivity by over 10 percent. More than a quarter of respondents indicated they have realized around a 10 to 20 percent reduction in maintenance costs, enabled through digital.

## Improved military MRO could benefit industry stakeholders

Enhancing military MRO capabilities could be a mutually beneficial opportunity for industry stakeholders, including MRO providers, OEMs, and operators or customers, such as ministries of defense (MoDs).

MRO providers: Based on our survey, we learned that air forces have reduced their in-house MRO spend by approximately 5 percent over the past ten years, with both OEMs and commercial MRO providers benefitting. Commercial providers could further expand their market share by broadening their service offerings for the military market and applying advanced capabilities—securing new and potentially countercyclical revenue streams and even opportunities to design and test new solutions or products. Market-entry strategies could be tailored around specific aircraft platforms where MRO providers have the deepest capabilities or for countries that have sufficient fleet size and MRO budget and are open to engaging with new entrants. Actively competing for this business, however, may require commercial MRO providers to consider partnerships with another market incumbent, a joint venture, or M&A activities.

OEMs: Airframe, component, and engine OEMs are already providing MRO services to operators but could consider strengthening their capabilities as described above. Depending on the service contract, this may improve profitability or competitiveness, particularly considering new market entrants or the expansion of commercial MRO providers. OEMs benefit from capitalizing on proprietary aircraft and engine data, which are required to train predictive and preventive maintenance solutions. Partnerships with commercial MRO providers could accelerate capability buildup or unlock capacity expansion.

Both MROs and OEMs: They could build new cornerstone capabilities that are expected to grow in demand over the next decade (for example, heavy vertical lift or air-to-air fueling). They could improve their coverage of types of systems—such as unmanned aerial vehicles and onboard avionic systems with advanced capabilities—which would require more efficient MRO services than currently predicted for sophisticated platforms. Additionally, they could develop solutions to provide services at decentralized, movable, and concealed hubs for armed forces that may need to adapt to new threats. This would mean deploying OEM personnel at a base that is neither a home nor a frontline one, enabling maintenance operations to be concentrated across platforms, thus increasing efficiency.

Operators: Some operators have already improved their MRO capabilities or achieved cost reductions through increased competition. Operators could further incentivize capability buildup through availability-based contracts (moving from cost-plus to performance-based) or transfer some control of their maintenance personnel and infrastructure to OEMs or MROs to free up capacity or optimize costs.

With the changing geopolitical landscape, European NATO countries are looking to rapidly increase their defense capabilities—effective MRO is a cost-efficient way to improve the availability of mission-ready systems. In the face of decreased military O&M budgets, MRO providers in the military air domain, as well as new providers, could capture this opportunity by taking steps to improve their operational efficiency. That could optimize fleets, reduce costs, and contribute to Europe’s security.

## How relevant and useful is this article for you?

## About the author(s)

Christian Langer is a partner in McKinsey’s Hamburg office; Daniel Riefer is a partner in the Munich office; Giacomo Gatto is a partner in the London office; and Katharina Wagner is an associate partner in the Berlin office.

The authors wish to thank Florian-Marco Fengel and Tobias Otto for their contributions to this article.

## Explore a career with us","{""publication_date"": ""February 12, 2025"", ""word_count"": 2719, ""reading_time_minutes"": 14}",2025-03-19 16:33:57.328276
62,Finding the sweet spot in product-portfolio management,https://www.mckinsey.com/capabilities/operations/our-insights/finding-the-sweet-spot-in-product-portfolio-management,"the long economic expansion, many businesses have strongly grown their product portfolios","## Finding the sweet spot in product-portfolio management

Managing a product portfolio is a tricky business at the best of times. There’s a constant tension between product development and its desire to create new things, operations and its focus on costs and complexities, and sales with its need to cater to customer needs in expanding the top line. Buoyed by the long economic expansion, many businesses have strongly grown their product portfolios. Increasing profits gave companies comfortable investment cushions, and ongoing digitization and automation fueled flexibility and economies of scale.

Some companies have felt the challenges associated with an expanding portfolio for a while; for others, the COVID 19 crisis has become a breaking point. When polled about their planned portfolio activities, about 40 percent of senior executives attending a virtual event on product development said they were already working to reduce their product portfolios, and 44 percent planned to reallocate their R&D budgets to new products (Exhibit 1).

## Most Popular Insights

## How relevant and useful is this article for you?

## Most Popular Insights

• The state of AI: How organizations are rewiring to capture value

• Superagency in the workplace: Empowering people to unlock AI’s full potential

• Everyday habits: How CEOs navigate their six core responsibilities

• Women in the Workplace 2024: The 10th-anniversary report

The Volvo group offers a good example of the benefits of actively managing a portfolio. In 2011, the Scandinavia-based automotive player decided to phase out its five- and six-cylinder engines and replace them with four- and three-cylinder engines based on a unified, modular engine architecture. The intent was to become a leader in lowering carbon emissions, but the change also helped streamline production by replacing eight separate engine architectures on three platforms.

In another example, a machinery company went from actively selling about 800 product variants to selling about 25. By providing a better customer experience and shorter lead times, the vastly reduced portfolio increased sales by 5 percent while also achieving significant operational savings.

A third example comes from a consumer-product company, where focusing solely on increasing revenue came at the expense of profitability. Over a three-year period, the number of SKUs it offered increased by more than 50 percent, which reduced sales per SKU by more than 30 percent and margins by about 10 percent. A simplification program that comprised portfolio optimization, product design, and commercial-network alignment reduced the company’s product portfolio by 25 percent while improving gross profit by 3 percent.

By leveraging the insights gained from the crisis and adding the right tools and processes, companies can actively shape a simpler, more effective product portfolio that can both reduce the burden of risk management now and better serve customers once the crisis eases.

## Distinguishing good complexity from bad

## The good and bad of complexity

Examples of good complexity:

• A left-hand-drive configuration or additional type-approval for a vehicle that is otherwise identical unlocks a new market

• A shorter strap for an otherwise identical watch reaches a new target population

• A well-modularized paper machine that lets customers exchange printing modules while keeping all the paper-generating components identical responds to customer request while reducing development cost and time-to-delivery

• A deodorant that won’t mark black or white fabric addresses a hitherto unserved customer need

Examples of bad complexity:

• Marketing four different types of air-conditioning systems for products sold mainly in cold regions misaligns the portfolio to customers’ purchase criteria

• Maintaining a large legacy portfolio to accommodate occasional sales to a single major customer overestimates the relationship value of legacy products

• Continuing a range of single-speed motors when a new variable-speed motor design could replace the entire portfolio undervalues innovation

• Allowing customers to combine individual product features when five predefined configurations would likely satisfy most customers overindexes on choice versus simplicity

The goal of portfolio management is not simply to reduce complexity as much as possible—that would be easy. It is rather about differentiating good complexity, which generates more customer value than it costs (because customers are actually willing to pay for the variance), from bad complexity, which adds complexity without contributing significant customer value (see sidebar, “The good and bad of complexity”).

Some variance and complexity is important for every product portfolio. It helps distribute risks and, when combined with a smart modularization effort, can increase scale effects on a large number of components while also providing customers with choice. However, too much variance and complexity can create their own risks while raising overall costs, such as by generating additional compliance requirements that absorb more management attention than anticipated—or spurring further R&D efforts to maintain the products over their lifecycle.

## How portfolios grow…and grow…and grow

Organizations don’t deliberately increase complexity. Instead, two different mechanisms automatically increase complexity and product variance in the pursuit of growth and additional customer value.

Incremental growth. The first kind of portfolio growth is incremental, taking place as companies develop and adjust existing product features. A company sees an opportunity to sell items or services that are fundamentally like what it’s already selling, but with small variations: an additional size for a mobile phone, or a new-generation engine with lower fuel consumption. Managers might see an opening to capture small, additional markets that have specific requirements yet promise low incremental investment and cost, such as homeowners who lack the space for a conventional undercounter dishwasher but will buy a small countertop model. Underlying this growth is the common assumption that higher coverage of markets and consumer niches—and therefore additional revenue—will more than offset additional cost.

Disruptive growth. The second kind of portfolio growth, disruptive, happens when companies add entirely new technology to existing product lines, or set up completely new product lines. A company might replace internal combustion engines with electronic drivetrains, or meat in frozen meals with plant-based substitutes. For the past several years, one of the most frequent sources of disruptive portfolio growth has been the addition of software to traditional hardware products. Underlying this trend is the assumption that manufacturers can dramatically increase customer value by embedding software— together with competitive pressure as other players eye similar moves.

Both mechanisms have dramatically increased portfolio growth (Exhibit 2). A globally growing economy, burgeoning revenues and profits, and speedy consumer development in emerging countries have created explosive complexity and variance in multiple industries. For example, an automaker’s recent analysis found that premium automotive OEMs’ model offerings almost doubled between 2005 and 2020. An industrial-components company found that over the course of 15 years, the number of base models for a single product line grew 20-fold.

To counter spiraling complexity, companies can establish effective portfolio management—and with it, an ongoing practice of pruning their portfolios.

## Would you like to learn more about our Operations Practice?

## Under innovation pressure

Both traditional and breakout industries face rising pressure from shorter, more disruptive innovation cycles in the wake of technology advances. The resulting compression exacerbates the conflict between maintaining a current portfolio and delivering the innovative, high-margin products that are the lifeblood of any business. There are three main implications.

First, the tech industry increasingly sets consumer expectations, whether by annually upgraded mobile phones or social-media applications that are tweaked almost every week. Yet for companies offering physical products, rapid development limits the extent to which they can test new products and product features against their core customers’ needs. With software accounting for a rising proportion of product value, the mismatch between physical-product updates and the digital world is causing research and development operations to rethink the ways they create.

That leads to the second major implication. Companies are taking a page from the tech sector by adapting agile software-development methodologies to product development. They are focusing on minimum-viable-product design practices and constant, iterative improvement, rather than spending years developing a perfect product that could be outdated before it can be launched.

Third, more and more products must integrate with other platforms and systems, in order to include features that both consumers and industry see as standard. In the automotive sector, for example, the major consumer-technology companies have been competing intensely to extend their ecosystems to the daily drive. But this level of integration requires the participation of more stakeholders in the product-development process, with major process and structural changes in R&D so that it can cope with approaching challenges around innovation. By understanding the current portfolio’s costs and market coverage, companies are better able to create a structured approach to developing new offerings.

Electric-vehicle manufacturers are already successfully deploying software-based solutions to typical hardware issues. Traditionally, automakers that wanted to offer additional power for a higher price had little alternative but to change the drivetrain physically—by installing a turbocharger, for example, or offering a higher-capacity engine. Now it’s possible to offer different power profiles—at different prices—for the same battery configuration, including under a pay-per-use model for range extension.

## Finding the right complexity balance

There is no single, successful approach to product-portfolio management. But some companies are already coping with these challenges by applying advanced analytics, adapting processes and roles, debiasing decision-making, and putting the customer at the center of product-portfolio development.

## Rationalizing portfolios through advanced analytics

The use of advanced analytics in a portfolio-management context is especially well-suited to quantify technological distinction within the product portfolio—in other words, how a given product’s components compare to those in the rest of the portfolio. Two applications of this approach illustrate the potential benefits in overcoming limitations endemic to traditional product-portfolio rationalization.

Focus on low performance, not necessarily low sales. The first scenario addresses the all-too-common disappointment that results from focusing only on culling the lowest-selling products—especially across many different product families. Despite the time and effort spent, internal complexity may barely budge. The underlying reason? What truly drives complexity isn’t simply the number of product variants, but the number of components an organization must develop, source, assemble, and maintain to support those variants. If the pruned products have better-selling counterparts that use a majority of the same components, the complexity remains even as revenue disappears (Exhibit 3).

This is exactly the sort of problem modern network-optimization algorithms were designed for. These algorithms analyze component reuse across products, and identify the optimum combination of products to be pruned in order to release the most components while minimizing foregone sales (Exhibit 4). The result identifies and optimizes products with poor cost-performance ratios, rather than just products with low sales.

Companies can customize this exercise by allocating true complexity costs to sets of components, counting not just direct costs, such as inventory and related capital costs, but also harder-to-quantify expenses, such as associated R&D spend and production-line investments. This approach has helped a commercial-vehicle manufacturer reduce the number of components it deploys by 20 percent while affecting just 5 percent of sales—some of which were converted to other products. It also helped an engineered-products company realize that its base offerings could be bundled into just three key platform types, vastly simplifying the firm’s internal complexity while preserving customer options.

Get granular at the component level. The second application optimizes at the individual-component level. The sheer number of components, together with the often-manual process of entering and classifying component data, creates significant challenges when an organization wants to identify components that are similar, but not identical.

Machine-learning algorithms are ideally suited to this challenge, especially when trained over many months on comparable data. They are not only able to identify clusters of similar components, but can also use component similarity to highlight unexplained pricing discrepancies and point out more-competitive suppliers.

One automotive supplier company, for example, created unified data pools by combining line-item spending with bill-of-material, material-master, supplier, and engineering data from different systems. Ultimately, the company uncovered clusters of similar parts with very dissimilar prices. In some cases, the most expensive were double the price of the least expensive. In other cases, the algorithms identified identical parts sourced from different suppliers for significantly different prices—which was not visible before because of classification differences.

## Mastering complexity with the consumer-first product portfolio

## Rethinking product-related decision-making

Even with the best advanced analytics, machine learning, and related technologies, portfolio choices still have a strong human factor. Human involvement means human biases are a major risk, of which many people are not even aware.

Stability bias values ventures that don’t rock the boat or change direction. It happens when companies continue projects in which they’ve already heavily invested, rather than pursuing newer, riskier options that come with much greater potential advantages.

How to overcome it: Pooling riskier ventures in a separate unit is one way a firm can overcome stability bias.

Interest bias thrives in situations where different parts of a company argue for different projects. Perhaps engineers prefer technically advanced products (without considering customer demand), while sales pushes ideas that help them fill quotas (without keeping the cost of development in mind).

How to overcome it: Agreeing on decision-making criteria ahead of time can help combat interest bias.

Pattern-recognition bias lets past events drive current decisions. If a particular kind of product failed ten years ago, it’s not worth trying now.

How to overcome it: Have a formalized process to evaluate previous experiences, including relevant context. What kind of product was it? Did an external shock drive failure?

Companies that excel usually facilitate the flow of information between functions and departments. They have dedicated product-portfolio managers who are closely connected with system architects and product owners. They use predefined criteria to guide their product portfolio development. That reduces the risk that biased, individual perceptions will drive decision-making.

## Incorporate customer-centric insights

A good example of reviewing an old decision comes from a recreational-vehicle (RV) manufacturer, whose larger models had included the same basic components for many years. The company sensed that its customers’ lifestyles were changing, but it was reluctant to make significant changes to its designs.

The crucial factor in overcoming this form of bias was to develop a single source of truth for customer and market research, through a mix of quantitative and qualitative research methods. Ethnographic research methods—interacting with consumers in their own environment—proved especially effective in light of limits on available market data. That research revealed that that the built-in kitchens traditional RVs provided were going unused. Instead, RV owners relied on outdoor grills. The company therefore developed a slide-out kitchen that was a hit with customers and increased RV sales.

Businesses can foster these sorts of insights in-house as well, by bringing engineers much closer to customer interactions or even establishing dedicated roles for this, as many agile teams do. Either method works to build a bridge between the products’ creators and their ultimate users. Manufacturers have long been responsive to product reviews and testing organizations, but new technology’s ability to provide instantaneous feedback means they can hear from the customers in real time. And, as software comprises more of a product’s functionality, companies can respond much more rapidly as well, to improve products even after their sale.

Companies have more need than ever to rebalance their product portfolios so that complexity creates value rather than destroying it. They also have more tools at their disposal, with more power to create the right products that serve their customers’ needs. Now is the time to get started.

## How relevant and useful is this article for you?

## About the author(s)

Dominic Distel is an associate partner in McKinsey’s Munich office, where Moritz Krause is a consultant; Eric Hannon is a partner in the Frankfurt office; Alexander Krieg is a partner in the Stuttgart office.

The authors wish to thank Ella Burroughes, Stephanie Pratsch, and Vendla Sandström for their contributions to this article.

## Explore a career with us

## Related Articles

## Indirect procurement: Insource? Outsource? Or both?

## The present-focused, future-ready R&D organization

## Mastering complexity with the consumer-first product portfolio","{""publication_date"": ""December 4, 2020"", ""authors"": [""the long economic expansion"", ""many businesses have strongly grown their product portfolios""], ""word_count"": 2647, ""reading_time_minutes"": 13}",2025-03-19 16:33:57.540333
